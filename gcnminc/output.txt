 .text
.section .AMDGPU.runtime_metadata
.byte 1
.short 256
.section .AMDGPU.config
.text
.globl get_slot_ptr
.p2align 8
.type get_slot_ptr,@function
get_slot_ptr:
.amd_kernel_code_t
max_scratch_backing_memory_byte_size = 0
.dx10clamp
enable_ordered_append_gds = 0
private_element_size = 1
workitem_private_segment_byte_size = 0
workgroup_group_segment_byte_size = 0
gds_segment_byte_size = 0
workgroup_fbarrier_count = 0
wavefront_sgpr_count = 10
workitem_vgpr_count = 1
group_segment_alignment = 4
private_segment_alignment = 4
.end_amd_kernel_code_t
s_load_dword s0, s[8:9], 0x38
s_waitcnt lgkmcnt(0)
s_cmp_lt_u32 s0, 6
s_endpgm
.section .AMDGPU.csdata
.section .AMDGPU.config
.text
.globl get_xi_ptr
.p2align 8
.type get_xi_ptr,@function
get_xi_ptr:
.amd_kernel_code_t
max_scratch_backing_memory_byte_size = 0
.dx10clamp
enable_ordered_append_gds = 0
private_element_size = 1
workitem_private_segment_byte_size = 0
workgroup_group_segment_byte_size = 0
gds_segment_byte_size = 0
workgroup_fbarrier_count = 0
wavefront_sgpr_count = 10
workitem_vgpr_count = 1
group_segment_alignment = 4
private_segment_alignment = 4
.end_amd_kernel_code_t
s_load_dword s0, s[8:9], 0x38
s_waitcnt lgkmcnt(0)
s_cmp_lt_u32 s0, 6
s_endpgm
.section .AMDGPU.csdata
.section .AMDGPU.config
.text
.globl get_ref_ptr
.p2align 8
.type get_ref_ptr,@function
get_ref_ptr:
.amd_kernel_code_t
max_scratch_backing_memory_byte_size = 0
.dx10clamp
enable_ordered_append_gds = 0
private_element_size = 1
workitem_private_segment_byte_size = 0
workgroup_group_segment_byte_size = 0
gds_segment_byte_size = 0
workgroup_fbarrier_count = 0
wavefront_sgpr_count = 10
workitem_vgpr_count = 1
group_segment_alignment = 4
private_segment_alignment = 4
.end_amd_kernel_code_t
s_load_dword s0, s[8:9], 0x38
s_waitcnt lgkmcnt(0)
s_or_b32 s1, s0, 1
s_cmp_eq_i32 s1, 1
s_cbranch_scc1 BB2_4
s_cmp_eq_i32 s1, 3
s_cbranch_scc1 BB2_4
s_cmp_eq_i32 s1, 5
s_cbranch_scc1 BB2_4
s_cmp_eq_i32 s0, 6
BB2_4:
s_endpgm
.section .AMDGPU.csdata
.section .AMDGPU.config
.text
.globl get_row
.p2align 8
.type get_row,@function
get_row:
.amd_kernel_code_t
max_scratch_backing_memory_byte_size = 0
.dx10clamp
enable_ordered_append_gds = 0
private_element_size = 1
workitem_private_segment_byte_size = 0
workgroup_group_segment_byte_size = 0
gds_segment_byte_size = 0
workgroup_fbarrier_count = 0
wavefront_sgpr_count = 12
workitem_vgpr_count = 1
group_segment_alignment = 4
private_segment_alignment = 4
.end_amd_kernel_code_t
s_load_dword s0, s[8:9], 0x30
s_waitcnt lgkmcnt(0)
s_and_b32 s0, 1, s0
v_cmp_eq_i32 s[0:1], 1, s0
s_and_b64 vcc, exec, s[0:1]
s_cbranch_vccnz BB3_2
s_endpgm
BB3_2:
s_endpgm
.section .AMDGPU.csdata
.section .AMDGPU.config
.text
.globl get_row_counters_index
.p2align 8
.type get_row_counters_index,@function
get_row_counters_index:
.amd_kernel_code_t
max_scratch_backing_memory_byte_size = 0
.dx10clamp
enable_ordered_append_gds = 0
private_element_size = 1
workitem_private_segment_byte_size = 0
workgroup_group_segment_byte_size = 0
gds_segment_byte_size = 0
workgroup_fbarrier_count = 0
wavefront_sgpr_count = 102
workitem_vgpr_count = 2
group_segment_alignment = 4
private_segment_alignment = 4
.end_amd_kernel_code_t
s_load_dword s0, s[8:9], 0x38
s_load_dword s1, s[8:9], 0x30
s_load_dword s2, s[8:9], 0x34
s_waitcnt lgkmcnt(0)
s_mul_i32 s3, s0, 0x55555555
s_lshr_b32 s4, s0, 1
s_add_i32 s3, s3, s4
s_lshr_b32 s4, s0, 3
s_sub_i32 s3, s3, s4
s_lshr_b32 s3, s3, 30
s_sub_i32 s0, s0, s3
s_mul_i32 s0, s0, 0xaaaaaaab
v_mov_b32 v0, s0
v_mov_b32 v1, s1
buffer_store_dword v0, v1, s[96:99], s101 offen
s_waitcnt vmcnt(0) expcnt(0)
v_mul_u32_u24 v0, 10, s3
v_mov_b32 v1, s2
buffer_store_dword v0, v1, s[96:99], s101 offen
s_endpgm
.section .AMDGPU.csdata
.section .AMDGPU.config
.text
.globl get_nr_slots
.p2align 8
.type get_nr_slots,@function
get_nr_slots:
.amd_kernel_code_t
max_scratch_backing_memory_byte_size = 0
.dx10clamp
enable_ordered_append_gds = 0
private_element_size = 1
workitem_private_segment_byte_size = 0
workgroup_group_segment_byte_size = 0
gds_segment_byte_size = 0
workgroup_fbarrier_count = 0
wavefront_sgpr_count = 1
workitem_vgpr_count = 1
group_segment_alignment = 4
private_segment_alignment = 4
.end_amd_kernel_code_t
s_endpgm
.section .AMDGPU.csdata
.section .AMDGPU.config
.text
.globl get_nr_slots_local
.p2align 8
.type get_nr_slots_local,@function
get_nr_slots_local:
.amd_kernel_code_t
max_scratch_backing_memory_byte_size = 0
.dx10clamp
enable_ordered_append_gds = 0
private_element_size = 1
workitem_private_segment_byte_size = 0
workgroup_group_segment_byte_size = 0
gds_segment_byte_size = 0
workgroup_fbarrier_count = 0
wavefront_sgpr_count = 1
workitem_vgpr_count = 1
group_segment_alignment = 4
private_segment_alignment = 4
.end_amd_kernel_code_t
s_endpgm
.section .AMDGPU.csdata
.section .AMDGPU.config
.text
.globl inc_row_counter
.p2align 8
.type inc_row_counter,@function
inc_row_counter:
.amd_kernel_code_t
max_scratch_backing_memory_byte_size = 0
.dx10clamp
enable_ordered_append_gds = 0
private_element_size = 1
workitem_private_segment_byte_size = 0
workgroup_group_segment_byte_size = 0
gds_segment_byte_size = 0
workgroup_fbarrier_count = 0
wavefront_sgpr_count = 16
workitem_vgpr_count = 3
group_segment_alignment = 4
private_segment_alignment = 4
.end_amd_kernel_code_t
s_load_dword s2, s[8:9], 0x40
s_load_dwordx2 s[0:1], s[8:9], 0x38
s_waitcnt lgkmcnt(0)
s_mul_i32 s3, s2, 0x55555555
s_lshr_b32 s4, s2, 1
s_add_i32 s3, s3, s4
s_lshr_b32 s4, s2, 3
s_sub_i32 s3, s3, s4
s_lshr_b32 s3, s3, 30
s_sub_i32 s2, s2, s3
s_mul_i32 s2, s2, 0xaaaaaaab
v_mul_u32_u24 v2, 10, s3
s_ashr_i32 s3, s2, 31
s_lshl_b64 s[2:3], s[2:3], 2
s_add_u32 s0, s0, s2
v_and_b32 v2, 30, v2
s_addc_u32 s1, s1, s3
v_mov_b32 v1, s1
v_mov_b32 v0, s0
v_lshlrev_b32 v2, v2, 1
flat_atomic_add v[0:1], v2
s_endpgm
.section .AMDGPU.csdata
.section .AMDGPU.config
.text
.globl inc_local_row_counter
.p2align 8
.type inc_local_row_counter,@function
inc_local_row_counter:
.amd_kernel_code_t
max_scratch_backing_memory_byte_size = 0
.dx10clamp
enable_ordered_append_gds = 0
private_element_size = 1
workitem_private_segment_byte_size = 0
workgroup_group_segment_byte_size = 0
gds_segment_byte_size = 0
workgroup_fbarrier_count = 0
wavefront_sgpr_count = 10
workitem_vgpr_count = 2
group_segment_alignment = 4
private_segment_alignment = 4
.end_amd_kernel_code_t
s_load_dword s0, s[8:9], 0x38
s_load_dword s1, s[8:9], 0x34
s_mov_b32 m0, -1
s_waitcnt lgkmcnt(0)
s_mul_i32 s2, s0, 0x55555555
s_lshr_b32 s3, s0, 1
s_add_i32 s2, s2, s3
s_lshr_b32 s3, s0, 3
s_sub_i32 s2, s2, s3
s_lshr_b32 s2, s2, 30
s_sub_i32 s0, s0, s2
v_mul_u32_u24 v0, 10, s2
s_mul_i32 s0, s0, 0xaaaaaaac
v_and_b32 v0, 30, v0
s_add_i32 s0, s1, s0
v_lshlrev_b32 v0, v0, 1
v_mov_b32 v1, s0
ds_add_u32 v1, v0
s_endpgm
.section .AMDGPU.csdata
.section .AMDGPU.config
.text
.globl kernel_init_ht
.p2align 8
.type kernel_init_ht,@function
.amdgpu_hsa_kernel kernel_init_ht
kernel_init_ht:
.amd_kernel_code_t
max_scratch_backing_memory_byte_size = 0
.dx10clamp
enable_ordered_append_gds = 0
private_element_size = 1
workitem_private_segment_byte_size = 0
workgroup_group_segment_byte_size = 0
gds_segment_byte_size = 0
workgroup_fbarrier_count = 0
wavefront_sgpr_count = 19
workitem_vgpr_count = 5
group_segment_alignment = 4
private_segment_alignment = 4
.end_amd_kernel_code_t
s_load_dword s0, s[4:5], 0x4
s_load_dword s1, s[8:9], 0x4
s_waitcnt lgkmcnt(0)
s_and_b32 s0, s0, 0xffff
s_mul_i32 s0, s0, s12
v_add_i32 v0, vcc, s0, v0
v_sub_i32 v1, vcc, 0, v0
v_cmp_eq_i32_e32 vcc, s1, v1
v_mov_b32 v1, s1
s_and_saveexec_b64 s[0:1], vcc
s_xor_b64 s[0:1], exec, s[0:1]
s_cbranch_execz BB9_2
s_load_dwordx2 s[2:3], s[8:9], 0x60
s_load_dwordx2 s[6:7], s[8:9], 0x58
s_load_dwordx2 s[4:5], s[8:9], 0x50
v_mov_b32 v1, 0
s_waitcnt lgkmcnt(0)
s_add_u32 s10, s2, 4
s_addc_u32 s11, s3, 0
v_mov_b32 v3, s11
v_mov_b32 v2, s10
flat_store_dword v[2:3], v1
s_waitcnt vmcnt(0) lgkmcnt(0)
v_mov_b32 v2, s2
v_mov_b32 v3, s3
flat_store_dword v[2:3], v1
s_waitcnt vmcnt(0) lgkmcnt(0)
v_mov_b32 v2, s6
v_mov_b32 v3, s7
flat_store_dword v[2:3], v1
s_waitcnt vmcnt(0) lgkmcnt(0)
v_mov_b32 v3, s4
v_mov_b32 v2, v1
v_mov_b32 v4, s5
flat_store_dwordx2 v[3:4], v[1:2]
s_load_dword s2, s[8:9], 0x4
s_waitcnt vmcnt(0) lgkmcnt(0)
v_mov_b32 v1, s2
BB9_2:
s_or_b64 exec, exec, s[0:1]
v_add_i32 v0, vcc, v1, v0
v_mov_b32 v1, 0x556
v_cmp_gt_u32_e32 vcc, v1, v0
s_and_saveexec_b64 s[0:1], vcc
s_xor_b64 s[0:1], exec, s[0:1]
s_load_dwordx2 s[2:3], s[8:9], 0x48
v_ashrrev_i32 v1, 31, v0
v_lshlrev_b64 v[0:1], 2, v[0:1]
s_waitcnt lgkmcnt(0)
v_add_i32 v2, vcc, s2, v0
v_mov_b32 v0, s3
v_addc_u32 v3, vcc, v1, v0, vcc
v_mov_b32 v0, 0
flat_store_dword v[2:3], v0
s_waitcnt vmcnt(0) lgkmcnt(0)
BB9_4:
s_or_b64 exec, exec, s[0:1]
s_endpgm
.section .AMDGPU.csdata
.section .AMDGPU.runtime_metadata
.byte 4
.byte 6
.long 14
.ascii "kernel_init_ht"
.byte 7
.byte 9
.long 4
.byte 10
.long 4
.byte 11
.long 4
.ascii "uint"
.byte 13
.byte 0
.byte 14
.short 7
.byte 16
.byte 0
.byte 8
.byte 7
.byte 9
.long 4
.byte 10
.long 4
.byte 11
.long 4
.ascii "uint"
.byte 13
.byte 0
.byte 14
.short 7
.byte 16
.byte 0
.byte 8
.byte 7
.byte 9
.long 8
.byte 10
.long 8
.byte 11
.long 5
.ascii "uint*"
.byte 13
.byte 1
.byte 14
.short 7
.byte 16
.byte 0
.byte 15
.byte 1
.byte 8
.byte 7
.byte 9
.long 8
.byte 10
.long 8
.byte 11
.long 5
.ascii "uint*"
.byte 13
.byte 1
.byte 14
.short 7
.byte 16
.byte 0
.byte 15
.byte 1
.byte 8
.byte 7
.byte 9
.long 8
.byte 10
.long 8
.byte 11
.long 5
.ascii "uint*"
.byte 13
.byte 1
.byte 14
.short 7
.byte 16
.byte 0
.byte 15
.byte 1
.byte 8
.byte 7
.byte 9
.long 8
.byte 10
.long 8
.byte 11
.long 7
.ascii "sols_t*"
.byte 13
.byte 1
.byte 14
.short 0
.byte 16
.byte 0
.byte 15
.byte 1
.byte 8
.byte 7
.byte 9
.long 8
.byte 10
.long 8
.byte 11
.long 17
.ascii "potential_sols_t*"
.byte 13
.byte 1
.byte 14
.short 0
.byte 16
.byte 0
.byte 15
.byte 1
.byte 8
.byte 7
.byte 9
.long 8
.byte 10
.long 8
.byte 11
.long 5
.ascii "uint*"
.byte 13
.byte 1
.byte 14
.short 7
.byte 16
.byte 0
.byte 15
.byte 1
.byte 8
.byte 5
.section .AMDGPU.config
.text
.globl kernel_round0
.p2align 8
.type kernel_round0,@function
.amdgpu_hsa_kernel kernel_round0
kernel_round0:
.amd_kernel_code_t
max_scratch_backing_memory_byte_size = 0
.dx10clamp
enable_ordered_append_gds = 0
private_element_size = 1
workitem_private_segment_byte_size = 0
workgroup_group_segment_byte_size = 0
gds_segment_byte_size = 0
workgroup_fbarrier_count = 0
wavefront_sgpr_count = 52
workitem_vgpr_count = 40
group_segment_alignment = 4
private_segment_alignment = 4
.end_amd_kernel_code_t
s_load_dwordx2 s[18:19], s[8:9], 0x38
s_load_dword s2, s[4:5], 0x4
s_load_dword s3, s[8:9], 0x4
s_mov_b32 s21, 0x510e527f
s_mov_b32 s20, 0xade68241
s_waitcnt lgkmcnt(0)
s_load_dwordx2 s[6:7], s[18:19], 0x20
s_load_dwordx2 s[24:25], s[18:19], 0x0
s_and_b32 s2, s2, 0xffff
s_mul_i32 s2, s2, s12
v_add_i32 v0, vcc, s2, v0
v_add_i32 v0, vcc, s3, v0
s_load_dwordx2 s[14:15], s[18:19], 0x18
s_load_dwordx2 s[12:13], s[18:19], 0x8
s_load_dwordx2 s[10:11], s[18:19], 0x10
s_load_dwordx2 s[4:5], s[18:19], 0x28
s_load_dwordx2 s[2:3], s[18:19], 0x30
s_load_dwordx2 s[26:27], s[18:19], 0x38
s_waitcnt lgkmcnt(0)
s_add_u32 s18, s6, s24
s_addc_u32 s19, s7, s25
s_xor_b64 s[20:21], s[18:19], s[20:21]
s_mov_b32 s16, 0
s_mov_b32 s17, s20
s_mov_b32 s20, s21
s_mov_b32 s21, s16
s_or_b64 s[20:21], s[16:17], s[20:21]
s_add_u32 s22, s20, 0xf3bcc908
s_addc_u32 s23, s21, 0x6a09e667
v_mov_b32 v1, 0
s_xor_b64 s[28:29], s[22:23], s[6:7]
s_lshl_b32 s17, s28, 8
s_lshr_b64 s[28:29], s[28:29], 24
v_add_i32 v1, vcc, s18, v1
v_mov_b32 v2, s19
s_or_b64 s[28:29], s[16:17], s[28:29]
v_addc_u32 v2, vcc, v2, v0, vcc
v_add_i32 v5, vcc, s28, v1
v_mov_b32 v1, s29
v_addc_u32 v6, vcc, v1, v2, vcc
s_add_u32 s18, s4, s12
v_xor_b32 v1, s20, v5
v_xor_b32 v2, s21, v6
s_addc_u32 s19, s5, s13
s_mov_b32 s21, 0x9b05688c
s_mov_b32 s20, 0x2b3e6c1f
s_xor_b64 s[20:21], s[18:19], s[20:21]
s_mov_b32 s17, s20
s_mov_b32 s20, s21
s_mov_b32 s21, s16
s_or_b64 s[20:21], s[16:17], s[20:21]
s_add_u32 s30, s20, 0x84caa73b
v_lshlrev_b32 v3, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v7, 0, v1
s_addc_u32 s31, s21, 0xbb67ae85
v_add_i32 v9, vcc, s22, v7
v_mov_b32 v1, s23
s_xor_b64 s[22:23], s[30:31], s[4:5]
s_lshl_b32 s17, s22, 8
s_lshr_b64 s[22:23], s[22:23], 24
v_or_b32 v8, v2, v3
s_or_b64 s[32:33], s[16:17], s[22:23]
v_addc_u32 v10, vcc, v1, v8, vcc
v_xor_b32 v1, s28, v9
s_add_u32 s28, s18, s32
v_xor_b32 v2, s29, v10
s_addc_u32 s29, s19, s33
s_xor_b64 s[18:19], s[28:29], s[20:21]
s_lshl_b32 s17, s18, 16
s_lshr_b64 s[18:19], s[18:19], 16
s_or_b64 s[22:23], s[16:17], s[18:19]
s_add_u32 s18, s22, s30
s_addc_u32 s19, s23, s31
s_xor_b64 s[20:21], s[18:19], s[32:33]
s_lshl_b64 s[30:31], s[20:21], 1
s_lshr_b32 s20, s21, 31
s_mov_b32 s21, s16
s_or_b64 s[32:33], s[30:31], s[20:21]
s_add_u32 s20, s2, s10
s_addc_u32 s21, s3, s11
s_mov_b32 s31, 0xe07c2654
s_mov_b32 s30, 0x4be4294
s_xor_b64 s[30:31], s[20:21], s[30:31]
s_mov_b32 s17, s30
s_mov_b32 s30, s31
s_mov_b32 s31, s16
s_or_b64 s[34:35], s[16:17], s[30:31]
s_add_u32 s36, s34, 0xfe94f82b
s_addc_u32 s37, s35, 0x3c6ef372
s_xor_b64 s[30:31], s[36:37], s[2:3]
s_lshl_b32 s17, s30, 8
s_lshr_b64 s[30:31], s[30:31], 24
s_or_b64 s[38:39], s[16:17], s[30:31]
s_add_u32 s30, s20, s38
s_addc_u32 s31, s21, s39
s_xor_b64 s[20:21], s[30:31], s[34:35]
s_lshl_b32 s17, s20, 16
s_lshr_b64 s[20:21], s[20:21], 16
s_or_b64 s[20:21], s[16:17], s[20:21]
s_add_u32 s34, s20, s36
s_addc_u32 s35, s21, s37
s_xor_b64 s[36:37], s[34:35], s[38:39]
s_lshl_b64 s[38:39], s[36:37], 1
s_lshr_b32 s36, s37, 31
s_mov_b32 s37, s16
s_or_b64 s[36:37], s[38:39], s[36:37]
s_add_u32 s38, s26, s14
s_addc_u32 s39, s27, s15
s_mov_b32 s41, 0x5be0cd19
s_mov_b32 s40, 0x137e2179
s_xor_b64 s[40:41], s[38:39], s[40:41]
s_mov_b32 s17, s40
s_mov_b32 s40, s41
s_mov_b32 s41, s16
s_or_b64 s[40:41], s[16:17], s[40:41]
s_add_u32 s42, s40, 0x5f1d36f1
s_addc_u32 s43, s41, 0xa54ff53a
s_xor_b64 s[26:27], s[42:43], s[26:27]
s_lshl_b32 s17, s26, 8
s_lshr_b64 s[26:27], s[26:27], 24
s_or_b64 s[44:45], s[16:17], s[26:27]
s_add_u32 s26, s44, s38
s_addc_u32 s27, s45, s39
v_lshlrev_b64 v[3:4], 1, v[1:2]
v_lshrrev_b32 v1, 31, v2
s_xor_b64 s[38:39], s[26:27], s[40:41]
v_or_b32 v11, v1, v3
s_lshl_b32 s17, s38, 16
s_lshr_b64 s[38:39], s[38:39], 16
v_add_i32 v3, vcc, s32, v5
v_mov_b32 v1, s33
s_or_b64 s[38:39], s[16:17], s[38:39]
v_or_b32 v12, 0, v4
v_addc_u32 v4, vcc, v1, v6, vcc
v_xor_b32 v2, s39, v4
v_xor_b32 v1, s38, v3
v_or_b32 v5, 0, v2
v_or_b32 v6, 0, v1
v_add_i32 v13, vcc, s34, v5
v_mov_b32 v1, s35
v_addc_u32 v14, vcc, v1, v6, vcc
v_xor_b32 v1, s32, v13
v_xor_b32 v2, s33, v14
v_lshlrev_b32 v15, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v16, 0, v1
v_add_i32 v17, vcc, v16, v3
v_or_b32 v15, v2, v15
s_add_u32 s40, s38, s42
v_addc_u32 v18, vcc, v4, v15, vcc
s_addc_u32 s41, s39, s43
v_xor_b32 v1, v5, v17
v_xor_b32 v2, v6, v18
s_xor_b64 s[42:43], s[40:41], s[44:45]
v_lshlrev_b32 v3, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
s_lshl_b64 s[44:45], s[42:43], 1
s_lshr_b32 s42, s43, 31
s_mov_b32 s43, s16
v_or_b32 v5, 0, v1
s_or_b64 s[42:43], s[44:45], s[42:43]
v_add_i32 v13, vcc, v13, v5
v_or_b32 v6, v2, v3
s_add_u32 s17, s36, s28
v_addc_u32 v14, vcc, v6, v14, vcc
v_xor_b32 v1, v16, v13
v_xor_b32 v2, v15, v14
s_addc_u32 s28, s37, s29
v_lshlrev_b64 v[3:4], 1, v[1:2]
v_lshrrev_b32 v1, 31, v2
v_xor_b32 v2, s28, v8
v_or_b32 v15, v1, v3
v_xor_b32 v1, s17, v7
v_or_b32 v3, 0, v2
v_or_b32 v16, 0, v4
v_or_b32 v4, 0, v1
v_add_i32 v7, vcc, s40, v3
v_mov_b32 v1, s41
v_addc_u32 v8, vcc, v1, v4, vcc
v_xor_b32 v1, s36, v7
v_xor_b32 v2, s37, v8
v_lshlrev_b32 v19, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v20, 0, v1
v_mov_b32 v1, s28
v_or_b32 v19, v2, v19
v_add_i32 v21, vcc, s17, v20
v_addc_u32 v22, vcc, v1, v19, vcc
v_xor_b32 v1, v3, v21
v_xor_b32 v2, v4, v22
v_lshlrev_b32 v3, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
s_add_u32 s28, s30, s42
v_or_b32 v23, 0, v1
s_addc_u32 s29, s31, s43
v_add_i32 v7, vcc, v7, v23
v_or_b32 v24, v2, v3
v_addc_u32 v8, vcc, v24, v8, vcc
s_xor_b64 s[22:23], s[28:29], s[22:23]
s_mov_b32 s17, s22
s_mov_b32 s22, s23
s_mov_b32 s23, s16
v_xor_b32 v1, v20, v7
v_xor_b32 v2, v19, v8
v_lshlrev_b64 v[3:4], 1, v[1:2]
s_or_b64 s[22:23], s[16:17], s[22:23]
v_lshrrev_b32 v1, 31, v2
v_or_b32 v3, v1, v3
v_add_i32 v9, vcc, s22, v9
v_mov_b32 v1, s23
v_addc_u32 v10, vcc, v10, v1, vcc
v_xor_b32 v1, s42, v9
v_xor_b32 v2, s43, v10
v_lshlrev_b32 v19, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v20, 0, v1
v_or_b32 v19, v2, v19
v_add_i32 v25, vcc, s28, v20
v_mov_b32 v1, s29
v_addc_u32 v26, vcc, v19, v1, vcc
v_xor_b32 v1, s22, v25
v_xor_b32 v2, s23, v26
v_lshlrev_b32 v27, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v28, 0, v1
v_add_i32 v9, vcc, v28, v9
v_or_b32 v27, v2, v27
v_addc_u32 v10, vcc, v27, v10, vcc
v_xor_b32 v2, v19, v10
v_xor_b32 v1, v20, v9
v_lshrrev_b32 v19, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_or_b32 v19, v19, v1
v_add_i32 v29, vcc, s26, v11
v_mov_b32 v1, s27
v_addc_u32 v30, vcc, v12, v1, vcc
v_xor_b32 v1, s21, v30
v_or_b32 v31, 0, v1
v_xor_b32 v1, s20, v29
v_or_b32 v32, 0, v1
v_add_i32 v33, vcc, s18, v31
v_mov_b32 v1, s19
v_addc_u32 v34, vcc, v1, v32, vcc
v_xor_b32 v1, v11, v33
v_or_b32 v20, 0, v2
v_xor_b32 v2, v12, v34
v_lshlrev_b32 v11, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v12, 0, v1
v_add_i32 v29, vcc, v29, v12
v_or_b32 v11, v2, v11
v_addc_u32 v30, vcc, v11, v30, vcc
v_xor_b32 v1, v31, v29
v_xor_b32 v2, v32, v30
v_lshlrev_b32 v31, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v32, 0, v1
v_add_i32 v33, vcc, v33, v32
v_or_b32 v31, v2, v31
v_addc_u32 v34, vcc, v31, v34, vcc
v_xor_b32 v2, v11, v34
v_xor_b32 v1, v12, v33
v_lshrrev_b32 v11, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_or_b32 v1, v11, v1
v_add_i32 v11, vcc, v1, v17
v_or_b32 v2, 0, v2
v_addc_u32 v12, vcc, v2, v18, vcc
v_xor_b32 v18, v12, v24
v_xor_b32 v17, v11, v23
v_or_b32 v18, 0, v18
v_add_i32 v9, vcc, v9, v18
v_or_b32 v17, 0, v17
v_addc_u32 v10, vcc, v17, v10, vcc
v_xor_b32 v1, v1, v9
v_xor_b32 v2, v2, v10
v_lshlrev_b32 v23, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v24, 0, v1
v_add_i32 v11, vcc, v24, v11
v_or_b32 v23, v2, v23
v_addc_u32 v12, vcc, v12, v23, vcc
v_xor_b32 v1, v18, v11
v_xor_b32 v2, v17, v12
v_lshlrev_b32 v17, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v18, 0, v1
v_add_i32 v9, vcc, v9, v18
v_or_b32 v17, v2, v17
v_addc_u32 v10, vcc, v17, v10, vcc
v_xor_b32 v2, v23, v10
v_add_i32 v21, vcc, v21, v15
v_xor_b32 v1, v24, v9
v_lshrrev_b32 v23, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_addc_u32 v22, vcc, v16, v22, vcc
v_or_b32 v24, 0, v2
v_xor_b32 v2, v27, v22
v_or_b32 v23, v23, v1
v_xor_b32 v1, v28, v21
v_or_b32 v27, 0, v2
v_or_b32 v28, 0, v1
v_add_i32 v33, vcc, v33, v27
v_addc_u32 v34, vcc, v28, v34, vcc
v_xor_b32 v1, v15, v33
v_xor_b32 v2, v16, v34
v_lshlrev_b32 v15, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v16, 0, v1
v_add_i32 v21, vcc, v21, v16
v_or_b32 v15, v2, v15
v_addc_u32 v22, vcc, v22, v15, vcc
v_xor_b32 v1, v27, v21
v_xor_b32 v2, v28, v22
v_lshlrev_b32 v27, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v28, 0, v1
v_add_i32 v33, vcc, v33, v28
v_or_b32 v27, v2, v27
v_addc_u32 v34, vcc, v27, v34, vcc
v_xor_b32 v2, v15, v34
v_or_b32 v4, 0, v4
v_add_i32 v25, vcc, v25, v3
v_xor_b32 v1, v16, v33
v_lshrrev_b32 v15, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_addc_u32 v26, vcc, v4, v26, vcc
v_or_b32 v16, 0, v2
v_xor_b32 v2, v26, v31
v_or_b32 v15, v15, v1
v_xor_b32 v1, v25, v32
v_or_b32 v31, 0, v2
v_or_b32 v32, 0, v1
v_add_i32 v13, vcc, v31, v13
v_addc_u32 v14, vcc, v32, v14, vcc
v_xor_b32 v1, v3, v13
v_xor_b32 v2, v4, v14
v_lshlrev_b32 v3, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v4, 0, v1
v_add_i32 v25, vcc, v25, v4
v_or_b32 v3, v2, v3
v_addc_u32 v26, vcc, v26, v3, vcc
v_xor_b32 v1, v31, v25
v_xor_b32 v2, v32, v26
v_lshlrev_b32 v31, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v32, 0, v1
v_add_i32 v13, vcc, v32, v13
v_or_b32 v31, v2, v31
v_addc_u32 v14, vcc, v31, v14, vcc
v_xor_b32 v2, v3, v14
v_add_i32 v29, vcc, v29, v19
v_xor_b32 v1, v4, v13
v_lshrrev_b32 v3, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_addc_u32 v30, vcc, v20, v30, vcc
v_or_b32 v4, 0, v2
v_xor_b32 v2, v30, v6
v_or_b32 v3, v3, v1
v_xor_b32 v1, v29, v5
v_or_b32 v5, 0, v2
v_or_b32 v6, 0, v1
v_add_i32 v7, vcc, v7, v5
v_addc_u32 v8, vcc, v6, v8, vcc
v_xor_b32 v1, v19, v7
v_xor_b32 v2, v20, v8
v_lshlrev_b32 v19, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v20, 0, v1
v_add_i32 v29, vcc, v29, v20
v_or_b32 v19, v2, v19
v_addc_u32 v30, vcc, v19, v30, vcc
v_xor_b32 v1, v5, v29
v_xor_b32 v2, v6, v30
v_lshlrev_b32 v5, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v6, 0, v1
v_add_i32 v7, vcc, v7, v6
v_or_b32 v5, v2, v5
v_addc_u32 v8, vcc, v5, v8, vcc
v_xor_b32 v2, v19, v8
v_xor_b32 v1, v20, v7
v_lshrrev_b32 v19, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_or_b32 v19, v19, v1
v_add_i32 v1, vcc, 0, v11
v_or_b32 v20, 0, v2
v_addc_u32 v2, vcc, v12, v0, vcc
v_add_i32 v11, vcc, v15, v1
v_addc_u32 v12, vcc, v2, v16, vcc
v_xor_b32 v2, v5, v12
v_xor_b32 v1, v6, v11
v_or_b32 v5, 0, v2
v_or_b32 v6, 0, v1
v_add_i32 v13, vcc, v13, v5
v_addc_u32 v14, vcc, v6, v14, vcc
v_xor_b32 v1, v15, v13
v_xor_b32 v2, v16, v14
v_lshlrev_b32 v15, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v16, 0, v1
v_add_i32 v11, vcc, v16, v11
v_or_b32 v15, v2, v15
v_addc_u32 v12, vcc, v12, v15, vcc
v_xor_b32 v1, v5, v11
v_xor_b32 v2, v6, v12
v_lshlrev_b32 v5, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v6, 0, v1
v_add_i32 v13, vcc, v13, v6
v_or_b32 v5, v2, v5
v_addc_u32 v14, vcc, v5, v14, vcc
v_xor_b32 v2, v15, v14
v_add_i32 v21, vcc, v21, v3
v_xor_b32 v1, v16, v13
v_lshrrev_b32 v15, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_addc_u32 v22, vcc, v4, v22, vcc
v_or_b32 v16, 0, v2
v_xor_b32 v2, v17, v22
v_or_b32 v15, v15, v1
v_xor_b32 v1, v18, v21
v_or_b32 v17, 0, v2
v_or_b32 v18, 0, v1
v_add_i32 v7, vcc, v7, v17
v_addc_u32 v8, vcc, v18, v8, vcc
v_xor_b32 v1, v3, v7
v_xor_b32 v2, v4, v8
v_lshlrev_b32 v3, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v4, 0, v1
v_add_i32 v21, vcc, v21, v4
v_or_b32 v3, v2, v3
v_addc_u32 v22, vcc, v3, v22, vcc
v_xor_b32 v1, v17, v21
v_xor_b32 v2, v18, v22
v_lshlrev_b32 v17, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v18, 0, v1
v_add_i32 v7, vcc, v7, v18
v_or_b32 v17, v2, v17
v_addc_u32 v8, vcc, v17, v8, vcc
v_xor_b32 v2, v3, v8
v_add_i32 v25, vcc, v25, v19
v_xor_b32 v1, v4, v7
v_lshrrev_b32 v3, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_addc_u32 v26, vcc, v26, v20, vcc
v_or_b32 v4, 0, v2
v_xor_b32 v2, v27, v26
v_or_b32 v3, v3, v1
v_xor_b32 v1, v28, v25
v_or_b32 v27, 0, v2
v_or_b32 v28, 0, v1
v_add_i32 v9, vcc, v27, v9
v_addc_u32 v10, vcc, v28, v10, vcc
v_xor_b32 v1, v19, v9
v_xor_b32 v2, v20, v10
v_lshlrev_b32 v19, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v20, 0, v1
v_add_i32 v25, vcc, v25, v20
v_or_b32 v19, v2, v19
v_addc_u32 v26, vcc, v26, v19, vcc
v_xor_b32 v1, v27, v25
v_xor_b32 v2, v28, v26
v_lshlrev_b32 v27, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v28, 0, v1
v_add_i32 v9, vcc, v28, v9
v_or_b32 v27, v2, v27
v_addc_u32 v10, vcc, v27, v10, vcc
v_xor_b32 v2, v19, v10
v_add_i32 v29, vcc, v29, v23
v_xor_b32 v1, v20, v9
v_lshrrev_b32 v19, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_addc_u32 v30, vcc, v30, v24, vcc
v_or_b32 v20, 0, v2
v_xor_b32 v2, v31, v30
v_or_b32 v19, v19, v1
v_xor_b32 v1, v32, v29
v_or_b32 v31, 0, v2
v_or_b32 v32, 0, v1
v_add_i32 v33, vcc, v33, v31
v_addc_u32 v34, vcc, v32, v34, vcc
v_xor_b32 v1, v23, v33
v_xor_b32 v2, v24, v34
v_lshlrev_b32 v23, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v24, 0, v1
v_add_i32 v29, vcc, v29, v24
v_or_b32 v23, v2, v23
v_addc_u32 v30, vcc, v23, v30, vcc
v_xor_b32 v1, v31, v29
v_xor_b32 v2, v32, v30
v_lshlrev_b32 v31, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v32, 0, v1
v_add_i32 v33, vcc, v33, v32
v_or_b32 v31, v2, v31
v_addc_u32 v34, vcc, v31, v34, vcc
v_xor_b32 v2, v23, v34
v_xor_b32 v1, v24, v33
v_lshrrev_b32 v23, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_or_b32 v1, v23, v1
v_add_i32 v11, vcc, v1, v11
v_or_b32 v2, 0, v2
v_addc_u32 v12, vcc, v2, v12, vcc
v_xor_b32 v17, v12, v17
v_xor_b32 v18, v11, v18
v_or_b32 v17, 0, v17
v_add_i32 v9, vcc, v9, v17
v_or_b32 v18, 0, v18
v_addc_u32 v10, vcc, v18, v10, vcc
v_xor_b32 v1, v1, v9
v_xor_b32 v2, v2, v10
v_lshlrev_b32 v23, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v24, 0, v1
v_add_i32 v11, vcc, v24, v11
v_or_b32 v23, v2, v23
v_addc_u32 v12, vcc, v12, v23, vcc
v_xor_b32 v1, v17, v11
v_xor_b32 v2, v18, v12
v_lshlrev_b32 v17, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v18, 0, v1
v_add_i32 v9, vcc, v9, v18
v_or_b32 v17, v2, v17
v_addc_u32 v10, vcc, v17, v10, vcc
v_xor_b32 v2, v23, v10
v_add_i32 v21, vcc, v21, v15
v_xor_b32 v1, v24, v9
v_lshrrev_b32 v23, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_addc_u32 v22, vcc, v16, v22, vcc
v_or_b32 v24, 0, v2
v_xor_b32 v2, v27, v22
v_or_b32 v23, v23, v1
v_xor_b32 v1, v28, v21
v_or_b32 v27, 0, v2
v_or_b32 v28, 0, v1
v_add_i32 v33, vcc, v33, v27
v_addc_u32 v34, vcc, v28, v34, vcc
v_xor_b32 v1, v15, v33
v_xor_b32 v2, v16, v34
v_lshlrev_b32 v15, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v16, 0, v1
v_add_i32 v21, vcc, v21, v16
v_or_b32 v15, v2, v15
v_addc_u32 v22, vcc, v22, v15, vcc
v_xor_b32 v1, v27, v21
v_xor_b32 v2, v28, v22
v_lshlrev_b32 v27, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v28, 0, v1
v_add_i32 v33, vcc, v33, v28
v_or_b32 v27, v2, v27
v_addc_u32 v34, vcc, v27, v34, vcc
v_xor_b32 v2, v15, v34
v_add_i32 v25, vcc, v25, v3
v_xor_b32 v1, v16, v33
v_lshrrev_b32 v15, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_addc_u32 v26, vcc, v4, v26, vcc
v_or_b32 v16, 0, v2
v_xor_b32 v2, v26, v31
v_or_b32 v15, v15, v1
v_xor_b32 v1, v25, v32
v_or_b32 v31, 0, v2
v_or_b32 v32, 0, v1
v_add_i32 v13, vcc, v31, v13
v_addc_u32 v14, vcc, v32, v14, vcc
v_xor_b32 v1, v3, v13
v_xor_b32 v2, v4, v14
v_lshlrev_b32 v3, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v4, 0, v1
v_add_i32 v25, vcc, v25, v4
v_or_b32 v3, v2, v3
v_addc_u32 v26, vcc, v26, v3, vcc
v_xor_b32 v1, v31, v25
v_xor_b32 v2, v32, v26
v_lshlrev_b32 v31, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v32, 0, v1
v_add_i32 v13, vcc, v32, v13
v_or_b32 v31, v2, v31
v_addc_u32 v14, vcc, v31, v14, vcc
v_xor_b32 v2, v3, v14
v_add_i32 v29, vcc, v29, v19
v_xor_b32 v1, v4, v13
v_lshrrev_b32 v3, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_addc_u32 v30, vcc, v20, v30, vcc
v_or_b32 v4, 0, v2
v_xor_b32 v2, v30, v5
v_or_b32 v3, v3, v1
v_xor_b32 v1, v29, v6
v_or_b32 v5, 0, v2
v_or_b32 v6, 0, v1
v_add_i32 v7, vcc, v7, v5
v_addc_u32 v8, vcc, v6, v8, vcc
v_xor_b32 v1, v19, v7
v_xor_b32 v2, v20, v8
v_lshlrev_b32 v19, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v20, 0, v1
v_add_i32 v29, vcc, v29, v20
v_or_b32 v19, v2, v19
v_addc_u32 v30, vcc, v19, v30, vcc
v_xor_b32 v1, v5, v29
v_xor_b32 v2, v6, v30
v_lshlrev_b32 v5, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v6, 0, v1
v_add_i32 v7, vcc, v7, v6
v_or_b32 v5, v2, v5
v_addc_u32 v8, vcc, v5, v8, vcc
v_xor_b32 v2, v19, v8
v_add_i32 v11, vcc, v15, v11
v_xor_b32 v1, v20, v7
v_lshrrev_b32 v19, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_addc_u32 v12, vcc, v12, v16, vcc
v_or_b32 v20, 0, v2
v_xor_b32 v2, v5, v12
v_or_b32 v19, v19, v1
v_xor_b32 v1, v6, v11
v_or_b32 v5, 0, v2
v_or_b32 v6, 0, v1
v_add_i32 v13, vcc, v13, v5
v_addc_u32 v14, vcc, v6, v14, vcc
v_xor_b32 v1, v15, v13
v_xor_b32 v2, v16, v14
v_lshlrev_b32 v15, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v16, 0, v1
v_add_i32 v11, vcc, v16, v11
v_or_b32 v15, v2, v15
v_addc_u32 v12, vcc, v12, v15, vcc
v_xor_b32 v1, v5, v11
v_xor_b32 v2, v6, v12
v_lshlrev_b32 v5, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v6, 0, v1
v_add_i32 v13, vcc, v13, v6
v_or_b32 v5, v2, v5
v_addc_u32 v14, vcc, v5, v14, vcc
v_xor_b32 v2, v15, v14
v_add_i32 v21, vcc, v21, v3
v_xor_b32 v1, v16, v13
v_lshrrev_b32 v15, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_addc_u32 v22, vcc, v4, v22, vcc
v_or_b32 v16, 0, v2
v_xor_b32 v2, v17, v22
v_or_b32 v15, v15, v1
v_xor_b32 v1, v18, v21
v_or_b32 v17, 0, v2
v_or_b32 v18, 0, v1
v_add_i32 v7, vcc, v7, v17
v_addc_u32 v8, vcc, v18, v8, vcc
v_xor_b32 v1, v3, v7
v_xor_b32 v2, v4, v8
v_lshlrev_b32 v3, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v4, 0, v1
v_add_i32 v21, vcc, v21, v4
v_or_b32 v3, v2, v3
v_addc_u32 v22, vcc, v3, v22, vcc
v_xor_b32 v1, v17, v21
v_xor_b32 v2, v18, v22
v_lshlrev_b32 v17, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v18, 0, v1
v_add_i32 v7, vcc, v7, v18
v_or_b32 v17, v2, v17
v_addc_u32 v8, vcc, v17, v8, vcc
v_xor_b32 v2, v3, v8
v_add_i32 v25, vcc, v25, v19
v_xor_b32 v1, v4, v7
v_lshrrev_b32 v3, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_addc_u32 v26, vcc, v26, v20, vcc
v_or_b32 v4, 0, v2
v_xor_b32 v2, v27, v26
v_or_b32 v3, v3, v1
v_xor_b32 v1, v28, v25
v_or_b32 v27, 0, v2
v_or_b32 v28, 0, v1
v_add_i32 v9, vcc, v27, v9
v_addc_u32 v10, vcc, v28, v10, vcc
v_xor_b32 v1, v19, v9
v_xor_b32 v2, v20, v10
v_lshlrev_b32 v19, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v20, 0, v1
v_add_i32 v1, vcc, 0, v25
v_or_b32 v19, v2, v19
v_addc_u32 v2, vcc, v26, v0, vcc
v_add_i32 v25, vcc, v20, v1
v_addc_u32 v26, vcc, v2, v19, vcc
v_xor_b32 v1, v27, v25
v_xor_b32 v2, v28, v26
v_lshlrev_b32 v27, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v28, 0, v1
v_add_i32 v9, vcc, v9, v28
v_or_b32 v27, v2, v27
v_addc_u32 v10, vcc, v27, v10, vcc
v_xor_b32 v2, v19, v10
v_add_i32 v29, vcc, v29, v23
v_xor_b32 v1, v20, v9
v_lshrrev_b32 v19, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_addc_u32 v30, vcc, v30, v24, vcc
v_or_b32 v20, 0, v2
v_xor_b32 v2, v31, v30
v_or_b32 v19, v19, v1
v_xor_b32 v1, v32, v29
v_or_b32 v31, 0, v2
v_or_b32 v32, 0, v1
v_add_i32 v33, vcc, v33, v31
v_addc_u32 v34, vcc, v32, v34, vcc
v_xor_b32 v1, v23, v33
v_xor_b32 v2, v24, v34
v_lshlrev_b32 v23, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v24, 0, v1
v_add_i32 v29, vcc, v29, v24
v_or_b32 v23, v2, v23
v_addc_u32 v30, vcc, v23, v30, vcc
v_xor_b32 v1, v31, v29
v_xor_b32 v2, v32, v30
v_lshlrev_b32 v31, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v32, 0, v1
v_add_i32 v33, vcc, v33, v32
v_or_b32 v31, v2, v31
v_addc_u32 v34, vcc, v31, v34, vcc
v_xor_b32 v2, v23, v34
v_xor_b32 v1, v24, v33
v_lshrrev_b32 v23, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_or_b32 v1, v23, v1
v_add_i32 v11, vcc, v1, v11
v_or_b32 v2, 0, v2
v_addc_u32 v12, vcc, v2, v12, vcc
v_xor_b32 v17, v12, v17
v_xor_b32 v18, v11, v18
v_or_b32 v17, 0, v17
v_add_i32 v9, vcc, v17, v9
v_or_b32 v18, 0, v18
v_addc_u32 v10, vcc, v18, v10, vcc
v_xor_b32 v1, v1, v9
v_xor_b32 v2, v2, v10
v_lshlrev_b32 v23, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v24, 0, v1
v_add_i32 v11, vcc, v11, v24
v_or_b32 v23, v2, v23
v_addc_u32 v12, vcc, v12, v23, vcc
v_xor_b32 v1, v17, v11
v_xor_b32 v2, v18, v12
v_lshlrev_b32 v17, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v18, 0, v1
v_add_i32 v9, vcc, v18, v9
v_or_b32 v17, v2, v17
v_addc_u32 v10, vcc, v17, v10, vcc
v_xor_b32 v2, v23, v10
v_add_i32 v21, vcc, v21, v15
v_xor_b32 v1, v24, v9
v_lshrrev_b32 v23, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_addc_u32 v22, vcc, v16, v22, vcc
v_or_b32 v24, 0, v2
v_xor_b32 v2, v27, v22
v_or_b32 v23, v23, v1
v_xor_b32 v1, v28, v21
v_or_b32 v27, 0, v2
v_or_b32 v28, 0, v1
v_add_i32 v33, vcc, v33, v27
v_addc_u32 v34, vcc, v28, v34, vcc
v_xor_b32 v1, v15, v33
v_xor_b32 v2, v16, v34
v_lshlrev_b32 v15, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v16, 0, v1
v_add_i32 v1, vcc, 0, v21
v_or_b32 v15, v2, v15
v_addc_u32 v2, vcc, v22, v0, vcc
v_add_i32 v21, vcc, v16, v1
v_addc_u32 v22, vcc, v2, v15, vcc
v_xor_b32 v1, v27, v21
v_xor_b32 v2, v28, v22
v_lshlrev_b32 v27, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v28, 0, v1
v_add_i32 v33, vcc, v33, v28
v_or_b32 v27, v2, v27
v_addc_u32 v34, vcc, v27, v34, vcc
v_xor_b32 v2, v15, v34
v_add_i32 v25, vcc, v3, v25
v_xor_b32 v1, v16, v33
v_lshrrev_b32 v15, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_addc_u32 v26, vcc, v4, v26, vcc
v_or_b32 v16, 0, v2
v_xor_b32 v2, v26, v31
v_or_b32 v15, v15, v1
v_xor_b32 v1, v25, v32
v_or_b32 v31, 0, v2
v_or_b32 v32, 0, v1
v_add_i32 v13, vcc, v13, v31
v_addc_u32 v14, vcc, v32, v14, vcc
v_xor_b32 v1, v3, v13
v_xor_b32 v2, v4, v14
v_lshlrev_b32 v3, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v4, 0, v1
v_add_i32 v25, vcc, v4, v25
v_or_b32 v3, v2, v3
v_addc_u32 v26, vcc, v26, v3, vcc
v_xor_b32 v1, v31, v25
v_xor_b32 v2, v32, v26
v_lshlrev_b32 v31, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v32, 0, v1
v_add_i32 v13, vcc, v13, v32
v_or_b32 v31, v2, v31
v_addc_u32 v14, vcc, v31, v14, vcc
v_xor_b32 v2, v3, v14
v_add_i32 v29, vcc, v29, v19
v_xor_b32 v1, v4, v13
v_lshrrev_b32 v3, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_addc_u32 v30, vcc, v20, v30, vcc
v_or_b32 v4, 0, v2
v_xor_b32 v2, v30, v5
v_or_b32 v3, v3, v1
v_xor_b32 v1, v29, v6
v_or_b32 v5, 0, v2
v_or_b32 v6, 0, v1
v_add_i32 v7, vcc, v7, v5
v_addc_u32 v8, vcc, v6, v8, vcc
v_xor_b32 v1, v19, v7
v_xor_b32 v2, v20, v8
v_lshlrev_b32 v19, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v20, 0, v1
v_add_i32 v29, vcc, v29, v20
v_or_b32 v19, v2, v19
v_addc_u32 v30, vcc, v19, v30, vcc
v_xor_b32 v1, v5, v29
v_xor_b32 v2, v6, v30
v_lshlrev_b32 v5, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v6, 0, v1
v_add_i32 v7, vcc, v7, v6
v_or_b32 v5, v2, v5
v_addc_u32 v8, vcc, v5, v8, vcc
v_xor_b32 v2, v19, v8
v_add_i32 v11, vcc, v11, v15
v_xor_b32 v1, v20, v7
v_lshrrev_b32 v19, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_addc_u32 v12, vcc, v12, v16, vcc
v_or_b32 v20, 0, v2
v_xor_b32 v2, v5, v12
v_or_b32 v19, v19, v1
v_xor_b32 v1, v6, v11
v_or_b32 v5, 0, v2
v_or_b32 v6, 0, v1
v_add_i32 v13, vcc, v13, v5
v_addc_u32 v14, vcc, v6, v14, vcc
v_xor_b32 v1, v15, v13
v_xor_b32 v2, v16, v14
v_lshlrev_b32 v15, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v16, 0, v1
v_add_i32 v11, vcc, v11, v16
v_or_b32 v15, v2, v15
v_addc_u32 v12, vcc, v12, v15, vcc
v_xor_b32 v1, v5, v11
v_xor_b32 v2, v6, v12
v_lshlrev_b32 v5, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v6, 0, v1
v_add_i32 v13, vcc, v13, v6
v_or_b32 v5, v2, v5
v_addc_u32 v14, vcc, v5, v14, vcc
v_xor_b32 v2, v15, v14
v_add_i32 v21, vcc, v3, v21
v_xor_b32 v1, v16, v13
v_lshrrev_b32 v15, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_addc_u32 v22, vcc, v4, v22, vcc
v_or_b32 v16, 0, v2
v_xor_b32 v2, v17, v22
v_or_b32 v15, v15, v1
v_xor_b32 v1, v18, v21
v_or_b32 v17, 0, v2
v_or_b32 v18, 0, v1
v_add_i32 v7, vcc, v7, v17
v_addc_u32 v8, vcc, v18, v8, vcc
v_xor_b32 v1, v3, v7
v_xor_b32 v2, v4, v8
v_lshlrev_b32 v3, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v4, 0, v1
v_add_i32 v21, vcc, v4, v21
v_or_b32 v3, v2, v3
v_addc_u32 v22, vcc, v3, v22, vcc
v_xor_b32 v1, v17, v21
v_xor_b32 v2, v18, v22
v_lshlrev_b32 v17, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v18, 0, v1
v_add_i32 v7, vcc, v7, v18
v_or_b32 v17, v2, v17
v_addc_u32 v8, vcc, v17, v8, vcc
v_xor_b32 v2, v3, v8
v_add_i32 v25, vcc, v19, v25
v_xor_b32 v1, v4, v7
v_lshrrev_b32 v3, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_addc_u32 v26, vcc, v26, v20, vcc
v_or_b32 v4, 0, v2
v_xor_b32 v2, v27, v26
v_or_b32 v3, v3, v1
v_xor_b32 v1, v28, v25
v_or_b32 v27, 0, v2
v_or_b32 v28, 0, v1
v_add_i32 v9, vcc, v9, v27
v_addc_u32 v10, vcc, v28, v10, vcc
v_xor_b32 v1, v19, v9
v_xor_b32 v2, v20, v10
v_lshlrev_b32 v19, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v20, 0, v1
v_add_i32 v25, vcc, v25, v20
v_or_b32 v19, v2, v19
v_addc_u32 v26, vcc, v26, v19, vcc
v_xor_b32 v1, v27, v25
v_xor_b32 v2, v28, v26
v_lshlrev_b32 v27, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v28, 0, v1
v_add_i32 v9, vcc, v9, v28
v_or_b32 v27, v2, v27
v_addc_u32 v10, vcc, v27, v10, vcc
v_xor_b32 v2, v19, v10
v_add_i32 v29, vcc, v29, v23
v_xor_b32 v1, v20, v9
v_lshrrev_b32 v19, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_addc_u32 v30, vcc, v30, v24, vcc
v_or_b32 v20, 0, v2
v_xor_b32 v2, v31, v30
v_or_b32 v19, v19, v1
v_xor_b32 v1, v32, v29
v_or_b32 v31, 0, v2
v_or_b32 v32, 0, v1
v_add_i32 v33, vcc, v31, v33
v_addc_u32 v34, vcc, v32, v34, vcc
v_xor_b32 v1, v23, v33
v_xor_b32 v2, v24, v34
v_lshlrev_b32 v23, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v24, 0, v1
v_add_i32 v29, vcc, v29, v24
v_or_b32 v23, v2, v23
v_addc_u32 v30, vcc, v23, v30, vcc
v_xor_b32 v1, v31, v29
v_xor_b32 v2, v32, v30
v_lshlrev_b32 v31, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v32, 0, v1
v_add_i32 v33, vcc, v32, v33
v_or_b32 v31, v2, v31
v_addc_u32 v34, vcc, v31, v34, vcc
v_xor_b32 v2, v23, v34
v_xor_b32 v1, v24, v33
v_lshrrev_b32 v23, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_or_b32 v1, v23, v1
v_add_i32 v11, vcc, v11, v1
v_or_b32 v2, 0, v2
v_addc_u32 v12, vcc, v2, v12, vcc
v_xor_b32 v17, v12, v17
v_xor_b32 v18, v11, v18
v_or_b32 v17, 0, v17
v_add_i32 v9, vcc, v9, v17
v_or_b32 v18, 0, v18
v_addc_u32 v10, vcc, v18, v10, vcc
v_xor_b32 v1, v1, v9
v_xor_b32 v2, v2, v10
v_lshlrev_b32 v23, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v24, 0, v1
v_add_i32 v11, vcc, v11, v24
v_or_b32 v23, v2, v23
v_addc_u32 v12, vcc, v12, v23, vcc
v_xor_b32 v1, v17, v11
v_xor_b32 v2, v18, v12
v_lshlrev_b32 v17, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v18, 0, v1
v_add_i32 v9, vcc, v9, v18
v_or_b32 v17, v2, v17
v_addc_u32 v10, vcc, v17, v10, vcc
v_xor_b32 v2, v23, v10
v_add_i32 v21, vcc, v15, v21
v_xor_b32 v1, v24, v9
v_lshrrev_b32 v23, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_addc_u32 v22, vcc, v16, v22, vcc
v_or_b32 v24, 0, v2
v_xor_b32 v2, v27, v22
v_or_b32 v23, v23, v1
v_xor_b32 v1, v28, v21
v_or_b32 v27, 0, v2
v_or_b32 v28, 0, v1
v_add_i32 v33, vcc, v33, v27
v_addc_u32 v34, vcc, v28, v34, vcc
v_xor_b32 v1, v15, v33
v_xor_b32 v2, v16, v34
v_lshlrev_b32 v15, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v16, 0, v1
v_add_i32 v21, vcc, v16, v21
v_or_b32 v15, v2, v15
v_addc_u32 v22, vcc, v22, v15, vcc
v_xor_b32 v1, v27, v21
v_xor_b32 v2, v28, v22
v_lshlrev_b32 v27, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v28, 0, v1
v_add_i32 v33, vcc, v33, v28
v_or_b32 v27, v2, v27
v_addc_u32 v34, vcc, v27, v34, vcc
v_xor_b32 v2, v15, v34
v_add_i32 v25, vcc, v25, v3
v_xor_b32 v1, v16, v33
v_lshrrev_b32 v15, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_addc_u32 v26, vcc, v4, v26, vcc
v_or_b32 v16, 0, v2
v_xor_b32 v2, v26, v31
v_or_b32 v15, v15, v1
v_xor_b32 v1, v25, v32
v_or_b32 v31, 0, v2
v_or_b32 v32, 0, v1
v_add_i32 v13, vcc, v13, v31
v_addc_u32 v14, vcc, v32, v14, vcc
v_xor_b32 v1, v3, v13
v_xor_b32 v2, v4, v14
v_lshlrev_b32 v3, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v4, 0, v1
v_add_i32 v25, vcc, v25, v4
v_or_b32 v3, v2, v3
v_addc_u32 v26, vcc, v26, v3, vcc
v_xor_b32 v1, v31, v25
v_xor_b32 v2, v32, v26
v_lshlrev_b32 v31, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v32, 0, v1
v_add_i32 v13, vcc, v13, v32
v_or_b32 v31, v2, v31
v_addc_u32 v14, vcc, v31, v14, vcc
v_xor_b32 v2, v3, v14
v_add_i32 v29, vcc, v29, v19
v_xor_b32 v1, v4, v13
v_lshrrev_b32 v3, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_addc_u32 v30, vcc, v20, v30, vcc
v_or_b32 v4, 0, v2
v_xor_b32 v2, v30, v5
v_or_b32 v3, v3, v1
v_xor_b32 v1, v29, v6
v_or_b32 v5, 0, v2
v_or_b32 v6, 0, v1
v_add_i32 v7, vcc, v5, v7
v_addc_u32 v8, vcc, v6, v8, vcc
v_xor_b32 v1, v19, v7
v_xor_b32 v2, v20, v8
v_lshlrev_b32 v19, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v20, 0, v1
v_add_i32 v29, vcc, v29, v20
v_or_b32 v19, v2, v19
v_addc_u32 v30, vcc, v19, v30, vcc
v_xor_b32 v1, v5, v29
v_xor_b32 v2, v6, v30
v_lshlrev_b32 v5, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v6, 0, v1
v_add_i32 v7, vcc, v6, v7
v_or_b32 v5, v2, v5
v_addc_u32 v8, vcc, v5, v8, vcc
v_xor_b32 v2, v19, v8
v_add_i32 v11, vcc, v11, v15
v_xor_b32 v1, v20, v7
v_lshrrev_b32 v19, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_addc_u32 v12, vcc, v12, v16, vcc
v_or_b32 v20, 0, v2
v_xor_b32 v2, v5, v12
v_or_b32 v19, v19, v1
v_xor_b32 v1, v6, v11
v_or_b32 v5, 0, v2
v_or_b32 v6, 0, v1
v_add_i32 v13, vcc, v13, v5
v_addc_u32 v14, vcc, v6, v14, vcc
v_xor_b32 v1, v15, v13
v_xor_b32 v2, v16, v14
v_lshlrev_b32 v15, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v16, 0, v1
v_add_i32 v1, vcc, 0, v11
v_or_b32 v15, v2, v15
v_addc_u32 v2, vcc, v12, v0, vcc
v_add_i32 v11, vcc, v16, v1
v_addc_u32 v12, vcc, v2, v15, vcc
v_xor_b32 v1, v5, v11
v_xor_b32 v2, v6, v12
v_lshlrev_b32 v5, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v6, 0, v1
v_add_i32 v13, vcc, v13, v6
v_or_b32 v5, v2, v5
v_addc_u32 v14, vcc, v5, v14, vcc
v_xor_b32 v2, v15, v14
v_add_i32 v21, vcc, v3, v21
v_xor_b32 v1, v16, v13
v_lshrrev_b32 v15, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_addc_u32 v22, vcc, v4, v22, vcc
v_or_b32 v16, 0, v2
v_xor_b32 v2, v17, v22
v_or_b32 v15, v15, v1
v_xor_b32 v1, v18, v21
v_or_b32 v17, 0, v2
v_or_b32 v18, 0, v1
v_add_i32 v7, vcc, v7, v17
v_addc_u32 v8, vcc, v18, v8, vcc
v_xor_b32 v1, v3, v7
v_xor_b32 v2, v4, v8
v_lshlrev_b32 v3, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v4, 0, v1
v_add_i32 v21, vcc, v4, v21
v_or_b32 v3, v2, v3
v_addc_u32 v22, vcc, v3, v22, vcc
v_xor_b32 v1, v17, v21
v_xor_b32 v2, v18, v22
v_lshlrev_b32 v17, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v18, 0, v1
v_add_i32 v7, vcc, v7, v18
v_or_b32 v17, v2, v17
v_addc_u32 v8, vcc, v17, v8, vcc
v_xor_b32 v2, v3, v8
v_add_i32 v25, vcc, v25, v19
v_xor_b32 v1, v4, v7
v_lshrrev_b32 v3, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_addc_u32 v26, vcc, v26, v20, vcc
v_or_b32 v4, 0, v2
v_xor_b32 v2, v27, v26
v_or_b32 v3, v3, v1
v_xor_b32 v1, v28, v25
v_or_b32 v27, 0, v2
v_or_b32 v28, 0, v1
v_add_i32 v9, vcc, v9, v27
v_addc_u32 v10, vcc, v28, v10, vcc
v_xor_b32 v1, v19, v9
v_xor_b32 v2, v20, v10
v_lshlrev_b32 v19, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v20, 0, v1
v_add_i32 v25, vcc, v25, v20
v_or_b32 v19, v2, v19
v_addc_u32 v26, vcc, v26, v19, vcc
v_xor_b32 v1, v27, v25
v_xor_b32 v2, v28, v26
v_lshlrev_b32 v27, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v28, 0, v1
v_add_i32 v9, vcc, v9, v28
v_or_b32 v27, v2, v27
v_addc_u32 v10, vcc, v27, v10, vcc
v_xor_b32 v2, v19, v10
v_add_i32 v29, vcc, v29, v23
v_xor_b32 v1, v20, v9
v_lshrrev_b32 v19, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_addc_u32 v30, vcc, v30, v24, vcc
v_or_b32 v20, 0, v2
v_xor_b32 v2, v31, v30
v_or_b32 v19, v19, v1
v_xor_b32 v1, v32, v29
v_or_b32 v31, 0, v2
v_or_b32 v32, 0, v1
v_add_i32 v33, vcc, v31, v33
v_addc_u32 v34, vcc, v32, v34, vcc
v_xor_b32 v1, v23, v33
v_xor_b32 v2, v24, v34
v_lshlrev_b32 v23, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v24, 0, v1
v_add_i32 v29, vcc, v29, v24
v_or_b32 v23, v2, v23
v_addc_u32 v30, vcc, v23, v30, vcc
v_xor_b32 v1, v31, v29
v_xor_b32 v2, v32, v30
v_lshlrev_b32 v31, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v32, 0, v1
v_add_i32 v33, vcc, v32, v33
v_or_b32 v31, v2, v31
v_addc_u32 v34, vcc, v31, v34, vcc
v_xor_b32 v2, v23, v34
v_xor_b32 v1, v24, v33
v_lshrrev_b32 v23, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_or_b32 v1, v23, v1
v_add_i32 v11, vcc, v1, v11
v_or_b32 v2, 0, v2
v_addc_u32 v12, vcc, v2, v12, vcc
v_xor_b32 v17, v12, v17
v_xor_b32 v18, v11, v18
v_or_b32 v17, 0, v17
v_add_i32 v9, vcc, v9, v17
v_or_b32 v18, 0, v18
v_addc_u32 v10, vcc, v18, v10, vcc
v_xor_b32 v1, v1, v9
v_xor_b32 v2, v2, v10
v_lshlrev_b32 v23, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v24, 0, v1
v_add_i32 v11, vcc, v24, v11
v_or_b32 v23, v2, v23
v_addc_u32 v12, vcc, v12, v23, vcc
v_xor_b32 v1, v17, v11
v_xor_b32 v2, v18, v12
v_lshlrev_b32 v17, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v18, 0, v1
v_add_i32 v9, vcc, v9, v18
v_or_b32 v17, v2, v17
v_addc_u32 v10, vcc, v17, v10, vcc
v_xor_b32 v2, v23, v10
v_add_i32 v21, vcc, v21, v15
v_xor_b32 v1, v24, v9
v_lshrrev_b32 v23, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_addc_u32 v22, vcc, v16, v22, vcc
v_or_b32 v24, 0, v2
v_xor_b32 v2, v27, v22
v_or_b32 v23, v23, v1
v_xor_b32 v1, v28, v21
v_or_b32 v27, 0, v2
v_or_b32 v28, 0, v1
v_add_i32 v33, vcc, v33, v27
v_addc_u32 v34, vcc, v28, v34, vcc
v_xor_b32 v1, v15, v33
v_xor_b32 v2, v16, v34
v_lshlrev_b32 v15, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v16, 0, v1
v_add_i32 v21, vcc, v21, v16
v_or_b32 v15, v2, v15
v_addc_u32 v22, vcc, v22, v15, vcc
v_xor_b32 v1, v27, v21
v_xor_b32 v2, v28, v22
v_lshlrev_b32 v27, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v28, 0, v1
v_add_i32 v33, vcc, v33, v28
v_or_b32 v27, v2, v27
v_addc_u32 v34, vcc, v27, v34, vcc
v_xor_b32 v2, v15, v34
v_add_i32 v25, vcc, v25, v3
v_xor_b32 v1, v16, v33
v_lshrrev_b32 v15, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_addc_u32 v26, vcc, v4, v26, vcc
v_or_b32 v16, 0, v2
v_xor_b32 v2, v26, v31
v_or_b32 v15, v15, v1
v_xor_b32 v1, v25, v32
v_or_b32 v31, 0, v2
v_or_b32 v32, 0, v1
v_add_i32 v13, vcc, v31, v13
v_addc_u32 v14, vcc, v32, v14, vcc
v_xor_b32 v1, v3, v13
v_xor_b32 v2, v4, v14
v_lshlrev_b32 v3, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v4, 0, v1
v_add_i32 v25, vcc, v25, v4
v_or_b32 v3, v2, v3
v_addc_u32 v26, vcc, v26, v3, vcc
v_xor_b32 v1, v31, v25
v_xor_b32 v2, v32, v26
v_lshlrev_b32 v31, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v32, 0, v1
v_add_i32 v13, vcc, v32, v13
v_or_b32 v31, v2, v31
v_addc_u32 v14, vcc, v31, v14, vcc
v_xor_b32 v2, v3, v14
v_add_i32 v29, vcc, v29, v19
v_xor_b32 v1, v4, v13
v_lshrrev_b32 v3, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_addc_u32 v30, vcc, v20, v30, vcc
v_or_b32 v4, 0, v2
v_xor_b32 v2, v30, v5
v_or_b32 v3, v3, v1
v_xor_b32 v1, v29, v6
v_or_b32 v5, 0, v2
v_or_b32 v6, 0, v1
v_add_i32 v7, vcc, v7, v5
v_addc_u32 v8, vcc, v6, v8, vcc
v_xor_b32 v1, v19, v7
v_xor_b32 v2, v20, v8
v_lshlrev_b32 v19, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v20, 0, v1
v_add_i32 v29, vcc, v29, v20
v_or_b32 v19, v2, v19
v_addc_u32 v30, vcc, v19, v30, vcc
v_xor_b32 v1, v5, v29
v_xor_b32 v2, v6, v30
v_lshlrev_b32 v5, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v6, 0, v1
v_add_i32 v7, vcc, v7, v6
v_or_b32 v5, v2, v5
v_addc_u32 v8, vcc, v5, v8, vcc
v_xor_b32 v2, v19, v8
v_add_i32 v11, vcc, v15, v11
v_xor_b32 v1, v20, v7
v_lshrrev_b32 v19, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_addc_u32 v12, vcc, v12, v16, vcc
v_or_b32 v20, 0, v2
v_xor_b32 v2, v5, v12
v_or_b32 v19, v19, v1
v_xor_b32 v1, v6, v11
v_or_b32 v5, 0, v2
v_or_b32 v6, 0, v1
v_add_i32 v13, vcc, v13, v5
v_addc_u32 v14, vcc, v6, v14, vcc
v_xor_b32 v1, v15, v13
v_xor_b32 v2, v16, v14
v_lshlrev_b32 v15, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v16, 0, v1
v_add_i32 v11, vcc, v16, v11
v_or_b32 v15, v2, v15
v_addc_u32 v12, vcc, v12, v15, vcc
v_xor_b32 v1, v5, v11
v_xor_b32 v2, v6, v12
v_lshlrev_b32 v5, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v6, 0, v1
v_add_i32 v13, vcc, v13, v6
v_or_b32 v5, v2, v5
v_addc_u32 v14, vcc, v5, v14, vcc
v_xor_b32 v2, v15, v14
v_add_i32 v21, vcc, v21, v3
v_xor_b32 v1, v16, v13
v_lshrrev_b32 v15, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_addc_u32 v22, vcc, v4, v22, vcc
v_or_b32 v16, 0, v2
v_xor_b32 v2, v17, v22
v_or_b32 v15, v15, v1
v_xor_b32 v1, v18, v21
v_or_b32 v17, 0, v2
v_or_b32 v18, 0, v1
v_add_i32 v7, vcc, v7, v17
v_addc_u32 v8, vcc, v18, v8, vcc
v_xor_b32 v1, v3, v7
v_xor_b32 v2, v4, v8
v_lshlrev_b32 v3, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v4, 0, v1
v_add_i32 v21, vcc, v21, v4
v_or_b32 v3, v2, v3
v_addc_u32 v22, vcc, v3, v22, vcc
v_xor_b32 v1, v17, v21
v_xor_b32 v2, v18, v22
v_lshlrev_b32 v17, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v18, 0, v1
v_add_i32 v7, vcc, v7, v18
v_or_b32 v17, v2, v17
v_addc_u32 v8, vcc, v17, v8, vcc
v_xor_b32 v2, v3, v8
v_add_i32 v25, vcc, v25, v19
v_xor_b32 v1, v4, v7
v_lshrrev_b32 v3, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_addc_u32 v26, vcc, v26, v20, vcc
v_or_b32 v4, 0, v2
v_xor_b32 v2, v27, v26
v_or_b32 v3, v3, v1
v_xor_b32 v1, v28, v25
v_or_b32 v27, 0, v2
v_or_b32 v28, 0, v1
v_add_i32 v9, vcc, v27, v9
v_addc_u32 v10, vcc, v28, v10, vcc
v_xor_b32 v1, v19, v9
v_xor_b32 v2, v20, v10
v_lshlrev_b32 v19, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v20, 0, v1
v_add_i32 v25, vcc, v25, v20
v_or_b32 v19, v2, v19
v_addc_u32 v26, vcc, v26, v19, vcc
v_xor_b32 v1, v27, v25
v_xor_b32 v2, v28, v26
v_lshlrev_b32 v27, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v28, 0, v1
v_add_i32 v9, vcc, v28, v9
v_or_b32 v27, v2, v27
v_addc_u32 v10, vcc, v27, v10, vcc
v_xor_b32 v2, v19, v10
v_xor_b32 v1, v20, v9
v_lshrrev_b32 v19, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_or_b32 v19, v19, v1
v_add_i32 v1, vcc, 0, v29
v_or_b32 v20, 0, v2
v_addc_u32 v2, vcc, v30, v0, vcc
v_add_i32 v29, vcc, v23, v1
v_addc_u32 v30, vcc, v2, v24, vcc
v_xor_b32 v2, v31, v30
v_xor_b32 v1, v32, v29
v_or_b32 v31, 0, v2
v_or_b32 v32, 0, v1
v_add_i32 v33, vcc, v33, v31
v_addc_u32 v34, vcc, v32, v34, vcc
v_xor_b32 v1, v23, v33
v_xor_b32 v2, v24, v34
v_lshlrev_b32 v23, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v24, 0, v1
v_add_i32 v29, vcc, v24, v29
v_or_b32 v23, v2, v23
v_addc_u32 v30, vcc, v23, v30, vcc
v_xor_b32 v1, v31, v29
v_xor_b32 v2, v32, v30
v_lshlrev_b32 v31, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v32, 0, v1
v_add_i32 v33, vcc, v33, v32
v_or_b32 v31, v2, v31
v_addc_u32 v34, vcc, v31, v34, vcc
v_xor_b32 v2, v23, v34
v_xor_b32 v1, v24, v33
v_lshrrev_b32 v23, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_or_b32 v1, v23, v1
v_add_i32 v11, vcc, v11, v1
v_or_b32 v2, 0, v2
v_addc_u32 v12, vcc, v2, v12, vcc
v_xor_b32 v17, v12, v17
v_xor_b32 v18, v11, v18
v_or_b32 v17, 0, v17
v_add_i32 v9, vcc, v9, v17
v_or_b32 v18, 0, v18
v_addc_u32 v10, vcc, v18, v10, vcc
v_xor_b32 v1, v1, v9
v_xor_b32 v2, v2, v10
v_lshlrev_b32 v23, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v24, 0, v1
v_add_i32 v11, vcc, v11, v24
v_or_b32 v23, v2, v23
v_addc_u32 v12, vcc, v12, v23, vcc
v_xor_b32 v1, v17, v11
v_xor_b32 v2, v18, v12
v_lshlrev_b32 v17, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v18, 0, v1
v_add_i32 v9, vcc, v9, v18
v_or_b32 v17, v2, v17
v_addc_u32 v10, vcc, v17, v10, vcc
v_xor_b32 v2, v23, v10
v_xor_b32 v1, v24, v9
v_lshrrev_b32 v23, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_or_b32 v23, v23, v1
v_add_i32 v1, vcc, v21, v15
v_or_b32 v24, 0, v2
v_addc_u32 v2, vcc, v16, v22, vcc
v_add_i32 v21, vcc, 0, v1
v_addc_u32 v22, vcc, v2, v0, vcc
v_xor_b32 v2, v27, v22
v_xor_b32 v1, v28, v21
v_or_b32 v27, 0, v2
v_or_b32 v28, 0, v1
v_add_i32 v33, vcc, v33, v27
v_addc_u32 v34, vcc, v28, v34, vcc
v_xor_b32 v1, v15, v33
v_xor_b32 v2, v16, v34
v_lshlrev_b32 v15, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v16, 0, v1
v_add_i32 v21, vcc, v16, v21
v_or_b32 v15, v2, v15
v_addc_u32 v22, vcc, v22, v15, vcc
v_xor_b32 v1, v27, v21
v_xor_b32 v2, v28, v22
v_lshlrev_b32 v27, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v28, 0, v1
v_add_i32 v33, vcc, v33, v28
v_or_b32 v27, v2, v27
v_addc_u32 v34, vcc, v27, v34, vcc
v_xor_b32 v2, v15, v34
v_add_i32 v25, vcc, v25, v3
v_xor_b32 v1, v16, v33
v_lshrrev_b32 v15, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_addc_u32 v26, vcc, v4, v26, vcc
v_or_b32 v16, 0, v2
v_xor_b32 v2, v26, v31
v_or_b32 v15, v15, v1
v_xor_b32 v1, v25, v32
v_or_b32 v31, 0, v2
v_or_b32 v32, 0, v1
v_add_i32 v13, vcc, v13, v31
v_addc_u32 v14, vcc, v32, v14, vcc
v_xor_b32 v1, v3, v13
v_xor_b32 v2, v4, v14
v_lshlrev_b32 v3, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v4, 0, v1
v_add_i32 v25, vcc, v25, v4
v_or_b32 v3, v2, v3
v_addc_u32 v26, vcc, v26, v3, vcc
v_xor_b32 v1, v31, v25
v_xor_b32 v2, v32, v26
v_lshlrev_b32 v31, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v32, 0, v1
v_add_i32 v13, vcc, v13, v32
v_or_b32 v31, v2, v31
v_addc_u32 v14, vcc, v31, v14, vcc
v_xor_b32 v2, v3, v14
v_add_i32 v29, vcc, v19, v29
v_xor_b32 v1, v4, v13
v_lshrrev_b32 v3, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_addc_u32 v30, vcc, v20, v30, vcc
v_or_b32 v4, 0, v2
v_xor_b32 v2, v30, v5
v_or_b32 v3, v3, v1
v_xor_b32 v1, v29, v6
v_or_b32 v5, 0, v2
v_or_b32 v6, 0, v1
v_add_i32 v7, vcc, v7, v5
v_addc_u32 v8, vcc, v6, v8, vcc
v_xor_b32 v1, v19, v7
v_xor_b32 v2, v20, v8
v_lshlrev_b32 v19, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v20, 0, v1
v_add_i32 v29, vcc, v20, v29
v_or_b32 v19, v2, v19
v_addc_u32 v30, vcc, v19, v30, vcc
v_xor_b32 v1, v5, v29
v_xor_b32 v2, v6, v30
v_lshlrev_b32 v5, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v6, 0, v1
v_add_i32 v7, vcc, v7, v6
v_or_b32 v5, v2, v5
v_addc_u32 v8, vcc, v5, v8, vcc
v_xor_b32 v2, v19, v8
v_add_i32 v11, vcc, v11, v15
v_xor_b32 v1, v20, v7
v_lshrrev_b32 v19, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_addc_u32 v12, vcc, v12, v16, vcc
v_or_b32 v20, 0, v2
v_xor_b32 v2, v5, v12
v_or_b32 v19, v19, v1
v_xor_b32 v1, v6, v11
v_or_b32 v5, 0, v2
v_or_b32 v6, 0, v1
v_add_i32 v13, vcc, v13, v5
v_addc_u32 v14, vcc, v6, v14, vcc
v_xor_b32 v1, v15, v13
v_xor_b32 v2, v16, v14
v_lshlrev_b32 v15, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v16, 0, v1
v_add_i32 v11, vcc, v11, v16
v_or_b32 v15, v2, v15
v_addc_u32 v12, vcc, v12, v15, vcc
v_xor_b32 v1, v5, v11
v_xor_b32 v2, v6, v12
v_lshlrev_b32 v5, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v6, 0, v1
v_add_i32 v13, vcc, v13, v6
v_or_b32 v5, v2, v5
v_addc_u32 v14, vcc, v5, v14, vcc
v_xor_b32 v2, v15, v14
v_add_i32 v21, vcc, v3, v21
v_xor_b32 v1, v16, v13
v_lshrrev_b32 v15, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_addc_u32 v22, vcc, v4, v22, vcc
v_or_b32 v16, 0, v2
v_xor_b32 v2, v17, v22
v_or_b32 v15, v15, v1
v_xor_b32 v1, v18, v21
v_or_b32 v17, 0, v2
v_or_b32 v18, 0, v1
v_add_i32 v7, vcc, v7, v17
v_addc_u32 v8, vcc, v18, v8, vcc
v_xor_b32 v1, v3, v7
v_xor_b32 v2, v4, v8
v_lshlrev_b32 v3, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v4, 0, v1
v_add_i32 v21, vcc, v4, v21
v_or_b32 v3, v2, v3
v_addc_u32 v22, vcc, v3, v22, vcc
v_xor_b32 v1, v17, v21
v_xor_b32 v2, v18, v22
v_lshlrev_b32 v17, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v18, 0, v1
v_add_i32 v7, vcc, v7, v18
v_or_b32 v17, v2, v17
v_addc_u32 v8, vcc, v17, v8, vcc
v_xor_b32 v2, v3, v8
v_add_i32 v25, vcc, v25, v19
v_xor_b32 v1, v4, v7
v_lshrrev_b32 v3, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_addc_u32 v26, vcc, v26, v20, vcc
v_or_b32 v4, 0, v2
v_xor_b32 v2, v27, v26
v_or_b32 v3, v3, v1
v_xor_b32 v1, v28, v25
v_or_b32 v27, 0, v2
v_or_b32 v28, 0, v1
v_add_i32 v9, vcc, v9, v27
v_addc_u32 v10, vcc, v28, v10, vcc
v_xor_b32 v1, v19, v9
v_xor_b32 v2, v20, v10
v_lshlrev_b32 v19, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v20, 0, v1
v_add_i32 v25, vcc, v25, v20
v_or_b32 v19, v2, v19
v_addc_u32 v26, vcc, v26, v19, vcc
v_xor_b32 v1, v27, v25
v_xor_b32 v2, v28, v26
v_lshlrev_b32 v27, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v28, 0, v1
v_add_i32 v9, vcc, v9, v28
v_or_b32 v27, v2, v27
v_addc_u32 v10, vcc, v27, v10, vcc
v_xor_b32 v2, v19, v10
v_add_i32 v29, vcc, v23, v29
v_xor_b32 v1, v20, v9
v_lshrrev_b32 v19, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_addc_u32 v30, vcc, v30, v24, vcc
v_or_b32 v20, 0, v2
v_xor_b32 v2, v31, v30
v_or_b32 v19, v19, v1
v_xor_b32 v1, v32, v29
v_or_b32 v31, 0, v2
v_or_b32 v32, 0, v1
v_add_i32 v33, vcc, v31, v33
v_addc_u32 v34, vcc, v32, v34, vcc
v_xor_b32 v1, v23, v33
v_xor_b32 v2, v24, v34
v_lshlrev_b32 v23, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v24, 0, v1
v_add_i32 v29, vcc, v29, v24
v_or_b32 v23, v2, v23
v_addc_u32 v30, vcc, v23, v30, vcc
v_xor_b32 v1, v31, v29
v_xor_b32 v2, v32, v30
v_lshlrev_b32 v31, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v32, 0, v1
v_add_i32 v33, vcc, v32, v33
v_or_b32 v31, v2, v31
v_addc_u32 v34, vcc, v31, v34, vcc
v_xor_b32 v2, v23, v34
v_xor_b32 v1, v24, v33
v_lshrrev_b32 v23, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_or_b32 v1, v23, v1
v_add_i32 v11, vcc, v11, v1
v_or_b32 v2, 0, v2
v_addc_u32 v12, vcc, v2, v12, vcc
v_xor_b32 v17, v12, v17
v_xor_b32 v18, v11, v18
v_or_b32 v17, 0, v17
v_add_i32 v9, vcc, v9, v17
v_or_b32 v18, 0, v18
v_addc_u32 v10, vcc, v18, v10, vcc
v_xor_b32 v1, v1, v9
v_xor_b32 v2, v2, v10
v_lshlrev_b32 v23, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v24, 0, v1
v_add_i32 v11, vcc, v11, v24
v_or_b32 v23, v2, v23
v_addc_u32 v12, vcc, v12, v23, vcc
v_xor_b32 v1, v17, v11
v_xor_b32 v2, v18, v12
v_lshlrev_b32 v17, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v18, 0, v1
v_add_i32 v9, vcc, v9, v18
v_or_b32 v17, v2, v17
v_addc_u32 v10, vcc, v17, v10, vcc
v_xor_b32 v2, v23, v10
v_add_i32 v21, vcc, v15, v21
v_xor_b32 v1, v24, v9
v_lshrrev_b32 v23, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_addc_u32 v22, vcc, v16, v22, vcc
v_or_b32 v24, 0, v2
v_xor_b32 v2, v27, v22
v_or_b32 v23, v23, v1
v_xor_b32 v1, v28, v21
v_or_b32 v27, 0, v2
v_or_b32 v28, 0, v1
v_add_i32 v33, vcc, v33, v27
v_addc_u32 v34, vcc, v28, v34, vcc
v_xor_b32 v1, v15, v33
v_xor_b32 v2, v16, v34
v_lshlrev_b32 v15, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v16, 0, v1
v_add_i32 v21, vcc, v16, v21
v_or_b32 v15, v2, v15
v_addc_u32 v22, vcc, v22, v15, vcc
v_xor_b32 v1, v27, v21
v_xor_b32 v2, v28, v22
v_lshlrev_b32 v27, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v28, 0, v1
v_add_i32 v33, vcc, v33, v28
v_or_b32 v27, v2, v27
v_addc_u32 v34, vcc, v27, v34, vcc
v_xor_b32 v2, v15, v34
v_add_i32 v25, vcc, v25, v3
v_xor_b32 v1, v16, v33
v_lshrrev_b32 v15, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_addc_u32 v26, vcc, v4, v26, vcc
v_or_b32 v16, 0, v2
v_xor_b32 v2, v26, v31
v_or_b32 v15, v15, v1
v_xor_b32 v1, v25, v32
v_or_b32 v31, 0, v2
v_or_b32 v32, 0, v1
v_add_i32 v13, vcc, v13, v31
v_addc_u32 v14, vcc, v32, v14, vcc
v_xor_b32 v1, v3, v13
v_xor_b32 v2, v4, v14
v_lshlrev_b32 v3, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v4, 0, v1
v_add_i32 v1, vcc, 0, v25
v_or_b32 v3, v2, v3
v_addc_u32 v2, vcc, v0, v26, vcc
v_add_i32 v25, vcc, v4, v1
v_addc_u32 v26, vcc, v2, v3, vcc
v_xor_b32 v1, v31, v25
v_xor_b32 v2, v32, v26
v_lshlrev_b32 v31, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v32, 0, v1
v_add_i32 v13, vcc, v13, v32
v_or_b32 v31, v2, v31
v_addc_u32 v14, vcc, v31, v14, vcc
v_xor_b32 v2, v3, v14
v_add_i32 v29, vcc, v29, v19
v_xor_b32 v1, v4, v13
v_lshrrev_b32 v3, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_addc_u32 v30, vcc, v20, v30, vcc
v_or_b32 v4, 0, v2
v_xor_b32 v2, v30, v5
v_or_b32 v3, v3, v1
v_xor_b32 v1, v29, v6
v_or_b32 v5, 0, v2
v_or_b32 v6, 0, v1
v_add_i32 v7, vcc, v5, v7
v_addc_u32 v8, vcc, v6, v8, vcc
v_xor_b32 v1, v19, v7
v_xor_b32 v2, v20, v8
v_lshlrev_b32 v19, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v20, 0, v1
v_add_i32 v29, vcc, v29, v20
v_or_b32 v19, v2, v19
v_addc_u32 v30, vcc, v19, v30, vcc
v_xor_b32 v1, v5, v29
v_xor_b32 v2, v6, v30
v_lshlrev_b32 v5, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v6, 0, v1
v_add_i32 v7, vcc, v6, v7
v_or_b32 v5, v2, v5
v_addc_u32 v8, vcc, v5, v8, vcc
v_xor_b32 v2, v19, v8
v_add_i32 v11, vcc, v11, v15
v_xor_b32 v1, v20, v7
v_lshrrev_b32 v19, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_addc_u32 v12, vcc, v12, v16, vcc
v_or_b32 v20, 0, v2
v_xor_b32 v2, v5, v12
v_or_b32 v19, v19, v1
v_xor_b32 v1, v6, v11
v_or_b32 v5, 0, v2
v_or_b32 v6, 0, v1
v_add_i32 v13, vcc, v5, v13
v_addc_u32 v14, vcc, v6, v14, vcc
v_xor_b32 v1, v15, v13
v_xor_b32 v2, v16, v14
v_lshlrev_b32 v15, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v16, 0, v1
v_add_i32 v11, vcc, v11, v16
v_or_b32 v15, v2, v15
v_addc_u32 v12, vcc, v12, v15, vcc
v_xor_b32 v1, v5, v11
v_xor_b32 v2, v6, v12
v_lshlrev_b32 v5, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v6, 0, v1
v_add_i32 v13, vcc, v6, v13
v_or_b32 v5, v2, v5
v_addc_u32 v14, vcc, v5, v14, vcc
v_xor_b32 v2, v15, v14
v_add_i32 v21, vcc, v21, v3
v_xor_b32 v1, v16, v13
v_lshrrev_b32 v15, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_addc_u32 v22, vcc, v4, v22, vcc
v_or_b32 v16, 0, v2
v_xor_b32 v2, v17, v22
v_or_b32 v15, v15, v1
v_xor_b32 v1, v18, v21
v_or_b32 v17, 0, v2
v_or_b32 v18, 0, v1
v_add_i32 v7, vcc, v7, v17
v_addc_u32 v8, vcc, v18, v8, vcc
v_xor_b32 v1, v3, v7
v_xor_b32 v2, v4, v8
v_lshlrev_b32 v3, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v4, 0, v1
v_add_i32 v21, vcc, v21, v4
v_or_b32 v3, v2, v3
v_addc_u32 v22, vcc, v3, v22, vcc
v_xor_b32 v1, v17, v21
v_xor_b32 v2, v18, v22
v_lshlrev_b32 v17, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v18, 0, v1
v_add_i32 v7, vcc, v7, v18
v_or_b32 v17, v2, v17
v_addc_u32 v8, vcc, v17, v8, vcc
v_xor_b32 v2, v3, v8
v_add_i32 v25, vcc, v19, v25
v_xor_b32 v1, v4, v7
v_lshrrev_b32 v3, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_addc_u32 v26, vcc, v26, v20, vcc
v_or_b32 v4, 0, v2
v_xor_b32 v2, v27, v26
v_or_b32 v3, v3, v1
v_xor_b32 v1, v28, v25
v_or_b32 v27, 0, v2
v_or_b32 v28, 0, v1
v_add_i32 v9, vcc, v9, v27
v_addc_u32 v10, vcc, v28, v10, vcc
v_xor_b32 v1, v19, v9
v_xor_b32 v2, v20, v10
v_lshlrev_b32 v19, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v20, 0, v1
v_add_i32 v25, vcc, v20, v25
v_or_b32 v19, v2, v19
v_addc_u32 v26, vcc, v26, v19, vcc
v_xor_b32 v1, v27, v25
v_xor_b32 v2, v28, v26
v_lshlrev_b32 v27, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v28, 0, v1
v_add_i32 v9, vcc, v9, v28
v_or_b32 v27, v2, v27
v_addc_u32 v10, vcc, v27, v10, vcc
v_xor_b32 v2, v19, v10
v_add_i32 v29, vcc, v29, v23
v_xor_b32 v1, v20, v9
v_lshrrev_b32 v19, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_addc_u32 v30, vcc, v30, v24, vcc
v_or_b32 v20, 0, v2
v_xor_b32 v2, v31, v30
v_or_b32 v19, v19, v1
v_xor_b32 v1, v32, v29
v_or_b32 v31, 0, v2
v_or_b32 v32, 0, v1
v_add_i32 v33, vcc, v33, v31
v_addc_u32 v34, vcc, v32, v34, vcc
v_xor_b32 v1, v23, v33
v_xor_b32 v2, v24, v34
v_lshlrev_b32 v23, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v24, 0, v1
v_add_i32 v29, vcc, v29, v24
v_or_b32 v23, v2, v23
v_addc_u32 v30, vcc, v23, v30, vcc
v_xor_b32 v1, v31, v29
v_xor_b32 v2, v32, v30
v_lshlrev_b32 v31, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v32, 0, v1
v_add_i32 v33, vcc, v33, v32
v_or_b32 v31, v2, v31
v_addc_u32 v34, vcc, v31, v34, vcc
v_xor_b32 v2, v23, v34
v_xor_b32 v1, v24, v33
v_lshrrev_b32 v23, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_or_b32 v1, v23, v1
v_add_i32 v11, vcc, v11, v1
v_or_b32 v2, 0, v2
v_addc_u32 v12, vcc, v2, v12, vcc
v_xor_b32 v17, v12, v17
v_xor_b32 v18, v11, v18
v_or_b32 v17, 0, v17
v_add_i32 v9, vcc, v17, v9
v_or_b32 v18, 0, v18
v_addc_u32 v10, vcc, v18, v10, vcc
v_xor_b32 v1, v1, v9
v_xor_b32 v2, v2, v10
v_lshlrev_b32 v23, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v24, 0, v1
v_add_i32 v11, vcc, v11, v24
v_or_b32 v23, v2, v23
v_addc_u32 v12, vcc, v12, v23, vcc
v_xor_b32 v1, v17, v11
v_xor_b32 v2, v18, v12
v_lshlrev_b32 v17, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v18, 0, v1
v_add_i32 v9, vcc, v18, v9
v_or_b32 v17, v2, v17
v_addc_u32 v10, vcc, v17, v10, vcc
v_xor_b32 v2, v23, v10
v_add_i32 v21, vcc, v21, v15
v_xor_b32 v1, v24, v9
v_lshrrev_b32 v23, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_addc_u32 v22, vcc, v16, v22, vcc
v_or_b32 v24, 0, v2
v_xor_b32 v2, v27, v22
v_or_b32 v23, v23, v1
v_xor_b32 v1, v28, v21
v_or_b32 v27, 0, v2
v_or_b32 v28, 0, v1
v_add_i32 v33, vcc, v33, v27
v_addc_u32 v34, vcc, v28, v34, vcc
v_xor_b32 v1, v15, v33
v_xor_b32 v2, v16, v34
v_lshlrev_b32 v15, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v16, 0, v1
v_add_i32 v21, vcc, v21, v16
v_or_b32 v15, v2, v15
v_addc_u32 v22, vcc, v22, v15, vcc
v_xor_b32 v1, v27, v21
v_xor_b32 v2, v28, v22
v_lshlrev_b32 v27, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v28, 0, v1
v_add_i32 v33, vcc, v33, v28
v_or_b32 v27, v2, v27
v_addc_u32 v34, vcc, v27, v34, vcc
v_xor_b32 v2, v15, v34
v_add_i32 v25, vcc, v3, v25
v_xor_b32 v1, v16, v33
v_lshrrev_b32 v15, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_addc_u32 v26, vcc, v4, v26, vcc
v_or_b32 v16, 0, v2
v_xor_b32 v2, v26, v31
v_or_b32 v15, v15, v1
v_xor_b32 v1, v25, v32
v_or_b32 v31, 0, v2
v_or_b32 v32, 0, v1
v_add_i32 v13, vcc, v13, v31
v_addc_u32 v14, vcc, v32, v14, vcc
v_xor_b32 v1, v3, v13
v_xor_b32 v2, v4, v14
v_lshlrev_b32 v3, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v4, 0, v1
v_add_i32 v25, vcc, v4, v25
v_or_b32 v3, v2, v3
v_addc_u32 v26, vcc, v26, v3, vcc
v_xor_b32 v1, v31, v25
v_xor_b32 v2, v32, v26
v_lshlrev_b32 v31, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v32, 0, v1
v_add_i32 v13, vcc, v13, v32
v_or_b32 v31, v2, v31
v_addc_u32 v14, vcc, v31, v14, vcc
v_xor_b32 v2, v3, v14
v_add_i32 v29, vcc, v29, v19
v_xor_b32 v1, v4, v13
v_lshrrev_b32 v3, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_addc_u32 v30, vcc, v20, v30, vcc
v_or_b32 v4, 0, v2
v_xor_b32 v2, v30, v5
v_or_b32 v3, v3, v1
v_xor_b32 v1, v29, v6
v_or_b32 v5, 0, v2
v_or_b32 v6, 0, v1
v_add_i32 v7, vcc, v7, v5
v_addc_u32 v8, vcc, v6, v8, vcc
v_xor_b32 v1, v19, v7
v_xor_b32 v2, v20, v8
v_lshlrev_b32 v19, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v20, 0, v1
v_add_i32 v29, vcc, v29, v20
v_or_b32 v19, v2, v19
v_addc_u32 v30, vcc, v19, v30, vcc
v_xor_b32 v1, v5, v29
v_xor_b32 v2, v6, v30
v_lshlrev_b32 v5, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v6, 0, v1
v_add_i32 v7, vcc, v7, v6
v_or_b32 v5, v2, v5
v_addc_u32 v8, vcc, v5, v8, vcc
v_xor_b32 v2, v19, v8
v_add_i32 v11, vcc, v11, v15
v_xor_b32 v1, v20, v7
v_lshrrev_b32 v19, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_addc_u32 v12, vcc, v12, v16, vcc
v_or_b32 v20, 0, v2
v_xor_b32 v2, v5, v12
v_or_b32 v19, v19, v1
v_xor_b32 v1, v6, v11
v_or_b32 v5, 0, v2
v_or_b32 v6, 0, v1
v_add_i32 v13, vcc, v5, v13
v_addc_u32 v14, vcc, v6, v14, vcc
v_xor_b32 v1, v15, v13
v_xor_b32 v2, v16, v14
v_lshlrev_b32 v15, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v16, 0, v1
v_add_i32 v11, vcc, v11, v16
v_or_b32 v15, v2, v15
v_addc_u32 v12, vcc, v12, v15, vcc
v_xor_b32 v1, v5, v11
v_xor_b32 v2, v6, v12
v_lshlrev_b32 v5, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v6, 0, v1
v_add_i32 v13, vcc, v6, v13
v_or_b32 v5, v2, v5
v_addc_u32 v14, vcc, v5, v14, vcc
v_xor_b32 v2, v15, v14
v_add_i32 v21, vcc, v21, v3
v_xor_b32 v1, v16, v13
v_lshrrev_b32 v15, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_addc_u32 v22, vcc, v4, v22, vcc
v_or_b32 v16, 0, v2
v_xor_b32 v2, v17, v22
v_or_b32 v15, v15, v1
v_xor_b32 v1, v18, v21
v_or_b32 v17, 0, v2
v_or_b32 v18, 0, v1
v_add_i32 v7, vcc, v7, v17
v_addc_u32 v8, vcc, v18, v8, vcc
v_xor_b32 v1, v3, v7
v_xor_b32 v2, v4, v8
v_lshlrev_b32 v3, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v4, 0, v1
v_add_i32 v21, vcc, v21, v4
v_or_b32 v3, v2, v3
v_addc_u32 v22, vcc, v3, v22, vcc
v_xor_b32 v1, v17, v21
v_xor_b32 v2, v18, v22
v_lshlrev_b32 v17, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v18, 0, v1
v_add_i32 v7, vcc, v7, v18
v_or_b32 v17, v2, v17
v_addc_u32 v8, vcc, v17, v8, vcc
v_xor_b32 v2, v3, v8
v_xor_b32 v1, v4, v7
v_lshrrev_b32 v3, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_or_b32 v3, v3, v1
v_add_i32 v1, vcc, 0, v25
v_or_b32 v4, 0, v2
v_addc_u32 v2, vcc, v26, v0, vcc
v_add_i32 v25, vcc, v19, v1
v_addc_u32 v26, vcc, v2, v20, vcc
v_xor_b32 v2, v27, v26
v_xor_b32 v1, v28, v25
v_or_b32 v27, 0, v2
v_or_b32 v28, 0, v1
v_add_i32 v9, vcc, v9, v27
v_addc_u32 v10, vcc, v28, v10, vcc
v_xor_b32 v1, v19, v9
v_xor_b32 v2, v20, v10
v_lshlrev_b32 v19, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v20, 0, v1
v_add_i32 v25, vcc, v20, v25
v_or_b32 v19, v2, v19
v_addc_u32 v26, vcc, v26, v19, vcc
v_xor_b32 v1, v27, v25
v_xor_b32 v2, v28, v26
v_lshlrev_b32 v27, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v28, 0, v1
v_add_i32 v9, vcc, v9, v28
v_or_b32 v27, v2, v27
v_addc_u32 v10, vcc, v27, v10, vcc
v_xor_b32 v2, v19, v10
v_add_i32 v29, vcc, v29, v23
v_xor_b32 v1, v20, v9
v_lshrrev_b32 v19, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_addc_u32 v30, vcc, v30, v24, vcc
v_or_b32 v20, 0, v2
v_xor_b32 v2, v31, v30
v_or_b32 v19, v19, v1
v_xor_b32 v1, v32, v29
v_or_b32 v31, 0, v2
v_or_b32 v32, 0, v1
v_add_i32 v33, vcc, v33, v31
v_addc_u32 v34, vcc, v32, v34, vcc
v_xor_b32 v1, v23, v33
v_xor_b32 v2, v24, v34
v_lshlrev_b32 v23, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v24, 0, v1
v_add_i32 v29, vcc, v29, v24
v_or_b32 v23, v2, v23
v_addc_u32 v30, vcc, v23, v30, vcc
v_xor_b32 v1, v31, v29
v_xor_b32 v2, v32, v30
v_lshlrev_b32 v31, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v32, 0, v1
v_add_i32 v33, vcc, v33, v32
v_or_b32 v31, v2, v31
v_addc_u32 v34, vcc, v31, v34, vcc
v_xor_b32 v2, v23, v34
v_xor_b32 v1, v24, v33
v_lshrrev_b32 v23, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_or_b32 v1, v23, v1
v_add_i32 v11, vcc, v11, v1
v_or_b32 v2, 0, v2
v_addc_u32 v12, vcc, v2, v12, vcc
v_xor_b32 v17, v12, v17
v_xor_b32 v18, v11, v18
v_or_b32 v17, 0, v17
v_add_i32 v9, vcc, v17, v9
v_or_b32 v18, 0, v18
v_addc_u32 v10, vcc, v18, v10, vcc
v_xor_b32 v1, v1, v9
v_xor_b32 v2, v2, v10
v_lshlrev_b32 v23, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v24, 0, v1
v_add_i32 v11, vcc, v11, v24
v_or_b32 v23, v2, v23
v_addc_u32 v12, vcc, v12, v23, vcc
v_xor_b32 v1, v17, v11
v_xor_b32 v2, v18, v12
v_lshlrev_b32 v17, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v18, 0, v1
v_add_i32 v9, vcc, v18, v9
v_or_b32 v17, v2, v17
v_addc_u32 v10, vcc, v17, v10, vcc
v_xor_b32 v2, v23, v10
v_add_i32 v21, vcc, v21, v15
v_xor_b32 v1, v24, v9
v_lshrrev_b32 v23, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_addc_u32 v22, vcc, v16, v22, vcc
v_or_b32 v24, 0, v2
v_xor_b32 v2, v27, v22
v_or_b32 v23, v23, v1
v_xor_b32 v1, v28, v21
v_or_b32 v27, 0, v2
v_or_b32 v28, 0, v1
v_add_i32 v33, vcc, v33, v27
v_addc_u32 v34, vcc, v28, v34, vcc
v_xor_b32 v1, v15, v33
v_xor_b32 v2, v16, v34
v_lshlrev_b32 v15, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v16, 0, v1
v_add_i32 v21, vcc, v21, v16
v_or_b32 v15, v2, v15
v_addc_u32 v22, vcc, v22, v15, vcc
v_xor_b32 v1, v27, v21
v_xor_b32 v2, v28, v22
v_lshlrev_b32 v27, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v28, 0, v1
v_add_i32 v33, vcc, v33, v28
v_or_b32 v27, v2, v27
v_addc_u32 v34, vcc, v27, v34, vcc
v_xor_b32 v2, v15, v34
v_add_i32 v25, vcc, v3, v25
v_xor_b32 v1, v16, v33
v_lshrrev_b32 v15, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_addc_u32 v26, vcc, v4, v26, vcc
v_or_b32 v16, 0, v2
v_xor_b32 v2, v26, v31
v_or_b32 v15, v15, v1
v_xor_b32 v1, v25, v32
v_or_b32 v31, 0, v2
v_or_b32 v32, 0, v1
v_add_i32 v13, vcc, v13, v31
v_addc_u32 v14, vcc, v32, v14, vcc
v_xor_b32 v1, v3, v13
v_xor_b32 v2, v4, v14
v_lshlrev_b32 v3, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v4, 0, v1
v_add_i32 v25, vcc, v4, v25
v_or_b32 v3, v2, v3
v_addc_u32 v26, vcc, v26, v3, vcc
v_xor_b32 v1, v31, v25
v_xor_b32 v2, v32, v26
v_lshlrev_b32 v31, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v32, 0, v1
v_add_i32 v13, vcc, v13, v32
v_or_b32 v31, v2, v31
v_addc_u32 v14, vcc, v31, v14, vcc
v_xor_b32 v2, v3, v14
v_xor_b32 v1, v4, v13
v_lshrrev_b32 v3, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_or_b32 v3, v3, v1
v_add_i32 v1, vcc, v29, v19
v_or_b32 v4, 0, v2
v_addc_u32 v2, vcc, v20, v30, vcc
v_add_i32 v29, vcc, 0, v1
v_addc_u32 v30, vcc, v2, v0, vcc
v_xor_b32 v2, v30, v5
v_xor_b32 v1, v29, v6
v_or_b32 v5, 0, v2
v_or_b32 v6, 0, v1
v_add_i32 v7, vcc, v7, v5
v_addc_u32 v8, vcc, v6, v8, vcc
v_xor_b32 v1, v19, v7
v_xor_b32 v2, v20, v8
v_lshlrev_b32 v19, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v20, 0, v1
v_add_i32 v29, vcc, v20, v29
v_or_b32 v19, v2, v19
v_addc_u32 v30, vcc, v19, v30, vcc
v_xor_b32 v1, v5, v29
v_xor_b32 v2, v6, v30
v_lshlrev_b32 v5, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v6, 0, v1
v_add_i32 v7, vcc, v7, v6
v_or_b32 v5, v2, v5
v_addc_u32 v8, vcc, v5, v8, vcc
v_xor_b32 v2, v19, v8
v_add_i32 v11, vcc, v11, v15
v_xor_b32 v1, v20, v7
v_lshrrev_b32 v19, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_addc_u32 v12, vcc, v12, v16, vcc
v_or_b32 v20, 0, v2
v_xor_b32 v2, v5, v12
v_or_b32 v19, v19, v1
v_xor_b32 v1, v6, v11
v_or_b32 v5, 0, v2
v_or_b32 v6, 0, v1
v_add_i32 v13, vcc, v13, v5
v_addc_u32 v14, vcc, v6, v14, vcc
v_xor_b32 v1, v15, v13
v_xor_b32 v2, v16, v14
v_lshlrev_b32 v15, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v16, 0, v1
v_add_i32 v11, vcc, v11, v16
v_or_b32 v15, v2, v15
v_addc_u32 v12, vcc, v12, v15, vcc
v_xor_b32 v1, v5, v11
v_xor_b32 v2, v6, v12
v_lshlrev_b32 v5, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v6, 0, v1
v_add_i32 v13, vcc, v13, v6
v_or_b32 v5, v2, v5
v_addc_u32 v14, vcc, v5, v14, vcc
v_xor_b32 v2, v15, v14
v_add_i32 v21, vcc, v21, v3
v_xor_b32 v1, v16, v13
v_lshrrev_b32 v15, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_addc_u32 v22, vcc, v4, v22, vcc
v_or_b32 v16, 0, v2
v_xor_b32 v2, v17, v22
v_or_b32 v15, v15, v1
v_xor_b32 v1, v18, v21
v_or_b32 v17, 0, v2
v_or_b32 v18, 0, v1
v_add_i32 v7, vcc, v17, v7
v_addc_u32 v8, vcc, v18, v8, vcc
v_xor_b32 v1, v3, v7
v_xor_b32 v2, v4, v8
v_lshlrev_b32 v3, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v4, 0, v1
v_add_i32 v21, vcc, v21, v4
v_or_b32 v3, v2, v3
v_addc_u32 v22, vcc, v3, v22, vcc
v_xor_b32 v1, v17, v21
v_xor_b32 v2, v18, v22
v_lshlrev_b32 v17, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v18, 0, v1
v_add_i32 v7, vcc, v18, v7
v_or_b32 v17, v2, v17
v_addc_u32 v8, vcc, v17, v8, vcc
v_xor_b32 v2, v3, v8
v_add_i32 v25, vcc, v25, v19
v_xor_b32 v1, v4, v7
v_lshrrev_b32 v3, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_addc_u32 v26, vcc, v26, v20, vcc
v_or_b32 v4, 0, v2
v_xor_b32 v2, v27, v26
v_or_b32 v3, v3, v1
v_xor_b32 v1, v28, v25
v_or_b32 v27, 0, v2
v_or_b32 v28, 0, v1
v_add_i32 v9, vcc, v9, v27
v_addc_u32 v10, vcc, v28, v10, vcc
v_xor_b32 v1, v19, v9
v_xor_b32 v2, v20, v10
v_lshlrev_b32 v19, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v20, 0, v1
v_add_i32 v25, vcc, v25, v20
v_or_b32 v19, v2, v19
v_addc_u32 v26, vcc, v26, v19, vcc
v_xor_b32 v1, v27, v25
v_xor_b32 v2, v28, v26
v_lshlrev_b32 v27, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v28, 0, v1
v_add_i32 v9, vcc, v9, v28
v_or_b32 v27, v2, v27
v_addc_u32 v10, vcc, v27, v10, vcc
v_xor_b32 v2, v19, v10
v_add_i32 v29, vcc, v23, v29
v_xor_b32 v1, v20, v9
v_lshrrev_b32 v19, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_addc_u32 v30, vcc, v30, v24, vcc
v_or_b32 v20, 0, v2
v_xor_b32 v2, v31, v30
v_or_b32 v19, v19, v1
v_xor_b32 v1, v32, v29
v_or_b32 v31, 0, v2
v_or_b32 v32, 0, v1
v_add_i32 v33, vcc, v33, v31
v_addc_u32 v34, vcc, v32, v34, vcc
v_xor_b32 v1, v23, v33
v_xor_b32 v2, v24, v34
v_lshlrev_b32 v23, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v24, 0, v1
v_add_i32 v29, vcc, v24, v29
v_or_b32 v23, v2, v23
v_addc_u32 v30, vcc, v23, v30, vcc
v_xor_b32 v1, v31, v29
v_xor_b32 v2, v32, v30
v_lshlrev_b32 v31, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v32, 0, v1
v_add_i32 v33, vcc, v33, v32
v_or_b32 v31, v2, v31
v_addc_u32 v34, vcc, v31, v34, vcc
v_xor_b32 v2, v23, v34
v_xor_b32 v1, v24, v33
v_lshrrev_b32 v23, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_or_b32 v1, v23, v1
v_add_i32 v11, vcc, v11, v1
v_or_b32 v2, 0, v2
v_addc_u32 v12, vcc, v2, v12, vcc
v_xor_b32 v17, v12, v17
v_xor_b32 v18, v11, v18
v_or_b32 v17, 0, v17
v_add_i32 v9, vcc, v9, v17
v_or_b32 v18, 0, v18
v_addc_u32 v10, vcc, v18, v10, vcc
v_xor_b32 v1, v1, v9
v_xor_b32 v2, v2, v10
v_lshlrev_b32 v23, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v24, 0, v1
v_add_i32 v1, vcc, 0, v11
v_or_b32 v23, v2, v23
v_addc_u32 v2, vcc, v0, v12, vcc
v_add_i32 v11, vcc, v24, v1
v_addc_u32 v12, vcc, v2, v23, vcc
v_xor_b32 v1, v17, v11
v_xor_b32 v2, v18, v12
v_lshlrev_b32 v17, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v18, 0, v1
v_add_i32 v9, vcc, v9, v18
v_or_b32 v17, v2, v17
v_addc_u32 v10, vcc, v17, v10, vcc
v_xor_b32 v2, v23, v10
v_add_i32 v21, vcc, v21, v15
v_xor_b32 v1, v24, v9
v_lshrrev_b32 v23, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_addc_u32 v22, vcc, v16, v22, vcc
v_or_b32 v24, 0, v2
v_xor_b32 v2, v27, v22
v_or_b32 v23, v23, v1
v_xor_b32 v1, v28, v21
v_or_b32 v27, 0, v2
v_or_b32 v28, 0, v1
v_add_i32 v33, vcc, v27, v33
v_addc_u32 v34, vcc, v28, v34, vcc
v_xor_b32 v1, v15, v33
v_xor_b32 v2, v16, v34
v_lshlrev_b32 v15, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v16, 0, v1
v_add_i32 v21, vcc, v21, v16
v_or_b32 v15, v2, v15
v_addc_u32 v22, vcc, v22, v15, vcc
v_xor_b32 v1, v27, v21
v_xor_b32 v2, v28, v22
v_lshlrev_b32 v27, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v28, 0, v1
v_add_i32 v33, vcc, v28, v33
v_or_b32 v27, v2, v27
v_addc_u32 v34, vcc, v27, v34, vcc
v_xor_b32 v2, v15, v34
v_add_i32 v25, vcc, v25, v3
v_xor_b32 v1, v16, v33
v_lshrrev_b32 v15, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_addc_u32 v26, vcc, v4, v26, vcc
v_or_b32 v16, 0, v2
v_xor_b32 v2, v26, v31
v_or_b32 v15, v15, v1
v_xor_b32 v1, v25, v32
v_or_b32 v31, 0, v2
v_or_b32 v32, 0, v1
v_add_i32 v13, vcc, v13, v31
v_addc_u32 v14, vcc, v32, v14, vcc
v_xor_b32 v1, v3, v13
v_xor_b32 v2, v4, v14
v_lshlrev_b32 v3, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v4, 0, v1
v_add_i32 v25, vcc, v25, v4
v_or_b32 v3, v2, v3
v_addc_u32 v26, vcc, v26, v3, vcc
v_xor_b32 v1, v31, v25
v_xor_b32 v2, v32, v26
v_lshlrev_b32 v31, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v32, 0, v1
v_add_i32 v13, vcc, v13, v32
v_or_b32 v31, v2, v31
v_addc_u32 v14, vcc, v31, v14, vcc
v_xor_b32 v2, v3, v14
v_add_i32 v29, vcc, v19, v29
v_xor_b32 v1, v4, v13
v_lshrrev_b32 v3, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_addc_u32 v30, vcc, v20, v30, vcc
v_or_b32 v4, 0, v2
v_xor_b32 v2, v30, v5
v_or_b32 v3, v3, v1
v_xor_b32 v1, v29, v6
v_or_b32 v5, 0, v2
v_or_b32 v6, 0, v1
v_add_i32 v7, vcc, v7, v5
v_addc_u32 v8, vcc, v6, v8, vcc
v_xor_b32 v1, v19, v7
v_xor_b32 v2, v20, v8
v_lshlrev_b32 v19, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v20, 0, v1
v_add_i32 v29, vcc, v20, v29
v_or_b32 v19, v2, v19
v_addc_u32 v30, vcc, v19, v30, vcc
v_xor_b32 v1, v5, v29
v_xor_b32 v2, v6, v30
v_lshlrev_b32 v5, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v6, 0, v1
v_add_i32 v7, vcc, v7, v6
v_or_b32 v5, v2, v5
v_addc_u32 v8, vcc, v5, v8, vcc
v_xor_b32 v2, v19, v8
v_add_i32 v11, vcc, v15, v11
v_xor_b32 v1, v20, v7
v_lshrrev_b32 v19, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_addc_u32 v12, vcc, v12, v16, vcc
v_or_b32 v20, 0, v2
v_xor_b32 v2, v5, v12
v_or_b32 v19, v19, v1
v_xor_b32 v1, v6, v11
v_or_b32 v5, 0, v2
v_or_b32 v6, 0, v1
v_add_i32 v13, vcc, v13, v5
v_addc_u32 v14, vcc, v6, v14, vcc
v_xor_b32 v1, v15, v13
v_xor_b32 v2, v16, v14
v_lshlrev_b32 v15, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v16, 0, v1
v_add_i32 v11, vcc, v16, v11
v_or_b32 v15, v2, v15
v_addc_u32 v12, vcc, v12, v15, vcc
v_xor_b32 v1, v5, v11
v_xor_b32 v2, v6, v12
v_lshlrev_b32 v5, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v6, 0, v1
v_add_i32 v13, vcc, v13, v6
v_or_b32 v5, v2, v5
v_addc_u32 v14, vcc, v5, v14, vcc
v_xor_b32 v2, v15, v14
v_add_i32 v21, vcc, v21, v3
v_xor_b32 v1, v16, v13
v_lshrrev_b32 v15, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_addc_u32 v22, vcc, v4, v22, vcc
v_or_b32 v16, 0, v2
v_xor_b32 v2, v17, v22
v_or_b32 v15, v15, v1
v_xor_b32 v1, v18, v21
v_or_b32 v17, 0, v2
v_or_b32 v18, 0, v1
v_add_i32 v7, vcc, v7, v17
v_addc_u32 v8, vcc, v18, v8, vcc
v_xor_b32 v1, v3, v7
v_xor_b32 v2, v4, v8
v_lshlrev_b32 v3, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v4, 0, v1
v_add_i32 v21, vcc, v21, v4
v_or_b32 v3, v2, v3
v_addc_u32 v22, vcc, v3, v22, vcc
v_xor_b32 v1, v17, v21
v_xor_b32 v2, v18, v22
v_lshlrev_b32 v17, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v18, 0, v1
v_add_i32 v7, vcc, v7, v18
v_or_b32 v17, v2, v17
v_addc_u32 v8, vcc, v17, v8, vcc
v_xor_b32 v2, v3, v8
v_add_i32 v25, vcc, v25, v19
v_xor_b32 v1, v4, v7
v_lshrrev_b32 v3, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_addc_u32 v26, vcc, v26, v20, vcc
v_or_b32 v4, 0, v2
v_xor_b32 v2, v27, v26
v_or_b32 v3, v3, v1
v_xor_b32 v1, v28, v25
v_or_b32 v27, 0, v2
v_or_b32 v28, 0, v1
v_add_i32 v9, vcc, v27, v9
v_addc_u32 v10, vcc, v28, v10, vcc
v_xor_b32 v1, v19, v9
v_xor_b32 v2, v20, v10
v_lshlrev_b32 v19, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v20, 0, v1
v_add_i32 v25, vcc, v25, v20
v_or_b32 v19, v2, v19
v_addc_u32 v26, vcc, v26, v19, vcc
v_xor_b32 v1, v27, v25
v_xor_b32 v2, v28, v26
v_lshlrev_b32 v27, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v28, 0, v1
v_add_i32 v9, vcc, v28, v9
v_or_b32 v27, v2, v27
v_addc_u32 v10, vcc, v27, v10, vcc
v_xor_b32 v2, v19, v10
v_add_i32 v29, vcc, v29, v23
v_xor_b32 v1, v20, v9
v_lshrrev_b32 v19, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_addc_u32 v30, vcc, v30, v24, vcc
v_or_b32 v20, 0, v2
v_xor_b32 v2, v31, v30
v_or_b32 v19, v19, v1
v_xor_b32 v1, v32, v29
v_or_b32 v31, 0, v2
v_or_b32 v32, 0, v1
v_add_i32 v33, vcc, v33, v31
v_addc_u32 v34, vcc, v32, v34, vcc
v_xor_b32 v1, v23, v33
v_xor_b32 v2, v24, v34
v_lshlrev_b32 v23, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v24, 0, v1
v_add_i32 v29, vcc, v29, v24
v_or_b32 v23, v2, v23
v_addc_u32 v30, vcc, v23, v30, vcc
v_xor_b32 v1, v31, v29
v_xor_b32 v2, v32, v30
v_lshlrev_b32 v31, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v32, 0, v1
v_add_i32 v33, vcc, v33, v32
v_or_b32 v31, v2, v31
v_addc_u32 v34, vcc, v31, v34, vcc
v_xor_b32 v2, v23, v34
v_xor_b32 v1, v24, v33
v_lshrrev_b32 v23, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_or_b32 v1, v23, v1
v_add_i32 v11, vcc, v1, v11
v_or_b32 v2, 0, v2
v_addc_u32 v12, vcc, v2, v12, vcc
v_xor_b32 v17, v12, v17
v_xor_b32 v18, v11, v18
v_or_b32 v17, 0, v17
v_add_i32 v9, vcc, v9, v17
v_or_b32 v18, 0, v18
v_addc_u32 v10, vcc, v18, v10, vcc
v_xor_b32 v1, v1, v9
v_xor_b32 v2, v2, v10
v_lshlrev_b32 v23, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v24, 0, v1
v_add_i32 v11, vcc, v24, v11
v_or_b32 v23, v2, v23
v_addc_u32 v12, vcc, v12, v23, vcc
v_xor_b32 v1, v17, v11
v_xor_b32 v2, v18, v12
v_lshlrev_b32 v17, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v18, 0, v1
v_add_i32 v35, vcc, v9, v18
v_or_b32 v17, v2, v17
v_addc_u32 v36, vcc, v17, v10, vcc
v_xor_b32 v2, v23, v36
v_xor_b32 v1, v24, v35
v_lshrrev_b32 v9, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_or_b32 v24, v9, v1
v_add_i32 v9, vcc, v21, v15
v_addc_u32 v10, vcc, v16, v22, vcc
v_or_b32 v37, 0, v2
v_xor_b32 v2, v27, v10
v_xor_b32 v1, v28, v9
v_or_b32 v21, 0, v2
v_or_b32 v22, 0, v1
v_add_i32 v23, vcc, v33, v21
v_addc_u32 v27, vcc, v22, v34, vcc
v_xor_b32 v1, v15, v23
v_xor_b32 v2, v16, v27
v_lshlrev_b32 v15, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v16, 0, v1
v_add_i32 v9, vcc, v9, v16
v_or_b32 v15, v2, v15
v_addc_u32 v10, vcc, v10, v15, vcc
v_xor_b32 v1, v21, v9
v_xor_b32 v2, v22, v10
v_lshlrev_b32 v21, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v28, 0, v1
v_add_i32 v33, vcc, v23, v28
v_or_b32 v22, v2, v21
v_addc_u32 v27, vcc, v22, v27, vcc
v_xor_b32 v2, v15, v27
v_add_i32 v21, vcc, v25, v3
v_xor_b32 v1, v16, v33
v_lshrrev_b32 v15, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_addc_u32 v23, vcc, v4, v26, vcc
v_or_b32 v16, 0, v2
v_xor_b32 v2, v23, v31
v_or_b32 v15, v15, v1
v_xor_b32 v1, v21, v32
v_or_b32 v25, 0, v2
v_or_b32 v26, 0, v1
v_add_i32 v13, vcc, v25, v13
v_addc_u32 v14, vcc, v26, v14, vcc
v_xor_b32 v1, v3, v13
v_xor_b32 v2, v4, v14
v_lshlrev_b32 v3, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v4, 0, v1
v_add_i32 v31, vcc, v21, v4
v_or_b32 v3, v2, v3
v_addc_u32 v32, vcc, v23, v3, vcc
v_xor_b32 v1, v25, v31
v_xor_b32 v2, v26, v32
v_lshlrev_b32 v21, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v26, 0, v1
v_add_i32 v13, vcc, v26, v13
v_or_b32 v25, v2, v21
v_addc_u32 v14, vcc, v25, v14, vcc
v_xor_b32 v2, v3, v14
v_xor_b32 v1, v4, v13
v_lshrrev_b32 v3, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_or_b32 v21, v3, v1
v_add_i32 v3, vcc, v29, v19
v_addc_u32 v4, vcc, v20, v30, vcc
v_or_b32 v23, 0, v2
v_xor_b32 v2, v4, v5
v_xor_b32 v1, v3, v6
v_or_b32 v5, 0, v2
v_or_b32 v6, 0, v1
v_add_i32 v7, vcc, v7, v5
v_addc_u32 v8, vcc, v6, v8, vcc
v_xor_b32 v1, v19, v7
v_xor_b32 v2, v20, v8
v_lshlrev_b32 v19, 8, v1
v_lshrrev_b64 v[1:2], 24, v[1:2]
v_or_b32 v20, 0, v1
v_add_i32 v29, vcc, v3, v20
v_or_b32 v19, v2, v19
v_addc_u32 v30, vcc, v19, v4, vcc
v_xor_b32 v1, v5, v29
v_xor_b32 v2, v6, v30
v_lshlrev_b32 v3, 16, v1
v_lshrrev_b64 v[1:2], 16, v[1:2]
v_or_b32 v4, 0, v1
v_add_i32 v5, vcc, v7, v4
v_or_b32 v3, v2, v3
v_addc_u32 v6, vcc, v3, v8, vcc
v_xor_b32 v2, v19, v6
v_xor_b32 v1, v20, v5
v_lshrrev_b32 v7, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_or_b32 v19, v7, v1
v_add_i32 v1, vcc, 0, v11
v_or_b32 v20, 0, v2
v_addc_u32 v2, vcc, v12, v0, vcc
v_add_i32 v7, vcc, v15, v1
v_addc_u32 v8, vcc, v2, v16, vcc
v_xor_b32 v2, v3, v8
v_xor_b32 v1, v4, v7
v_or_b32 v4, 0, v2
v_or_b32 v11, 0, v1
v_add_i32 v12, vcc, v13, v4
v_addc_u32 v13, vcc, v11, v14, vcc
v_xor_b32 v1, v15, v12
v_xor_b32 v2, v16, v13
v_lshrrev_b64 v[2:3], 24, v[1:2]
v_lshlrev_b32 v14, 8, v1
v_or_b32 v2, 0, v2
v_or_b32 v1, v3, v14
v_add_i32 v38, vcc, v2, v7
v_addc_u32 v39, vcc, v8, v1, vcc
v_xor_b32 v3, v4, v38
v_xor_b32 v4, v11, v39
v_lshlrev_b32 v7, 16, v3
v_lshrrev_b64 v[3:4], 16, v[3:4]
v_or_b32 v3, 0, v3
v_or_b32 v7, v4, v7
v_add_i32 v4, vcc, v12, v3
v_addc_u32 v3, vcc, v7, v13, vcc
v_add_i32 v9, vcc, v9, v21
v_addc_u32 v10, vcc, v23, v10, vcc
v_xor_b32 v8, v17, v10
v_xor_b32 v7, v18, v9
v_or_b32 v11, 0, v8
v_add_i32 v13, vcc, v5, v11
v_or_b32 v12, 0, v7
v_addc_u32 v14, vcc, v12, v6, vcc
v_xor_b32 v5, v21, v13
v_xor_b32 v6, v23, v14
v_lshlrev_b32 v7, 8, v5
v_lshrrev_b64 v[5:6], 24, v[5:6]
v_or_b32 v8, 0, v5
v_add_i32 v21, vcc, v9, v8
v_or_b32 v7, v6, v7
v_addc_u32 v23, vcc, v7, v10, vcc
v_xor_b32 v5, v11, v21
v_xor_b32 v6, v12, v23
v_lshrrev_b64 v[9:10], 16, v[5:6]
v_lshlrev_b32 v11, 16, v5
v_or_b32 v6, 0, v9
v_or_b32 v5, v10, v11
v_add_i32 v10, vcc, v13, v6
v_addc_u32 v12, vcc, v5, v14, vcc
v_add_i32 v9, vcc, v31, v19
v_addc_u32 v11, vcc, v32, v20, vcc
v_xor_b32 v14, v22, v11
v_xor_b32 v13, v28, v9
v_or_b32 v15, 0, v14
v_or_b32 v16, 0, v13
v_add_i32 v17, vcc, v15, v35
v_addc_u32 v18, vcc, v16, v36, vcc
v_xor_b32 v13, v19, v17
v_xor_b32 v14, v20, v18
v_lshlrev_b32 v19, 8, v13
v_lshrrev_b64 v[13:14], 24, v[13:14]
v_or_b32 v13, 0, v13
v_add_i32 v32, vcc, v9, v13
v_or_b32 v14, v14, v19
v_addc_u32 v34, vcc, v11, v14, vcc
v_xor_b32 v13, v15, v32
v_xor_b32 v14, v16, v34
v_lshlrev_b32 v9, 16, v13
v_lshrrev_b64 v[13:14], 16, v[13:14]
v_or_b32 v11, 0, v13
v_or_b32 v9, v14, v9
v_add_i32 v19, vcc, v11, v17
v_addc_u32 v28, vcc, v9, v18, vcc
v_add_i32 v17, vcc, v29, v24
v_addc_u32 v18, vcc, v30, v37, vcc
v_xor_b32 v14, v25, v18
v_xor_b32 v13, v26, v17
v_or_b32 v20, 0, v14
v_or_b32 v22, 0, v13
v_add_i32 v25, vcc, v33, v20
v_addc_u32 v26, vcc, v22, v27, vcc
v_xor_b32 v13, v24, v25
v_xor_b32 v14, v37, v26
v_lshlrev_b32 v15, 8, v13
v_lshrrev_b64 v[13:14], 24, v[13:14]
v_or_b32 v16, 0, v13
v_add_i32 v27, vcc, v17, v16
v_or_b32 v15, v14, v15
v_addc_u32 v29, vcc, v15, v18, vcc
v_xor_b32 v13, v20, v27
v_xor_b32 v14, v22, v29
v_lshrrev_b64 v[17:18], 16, v[13:14]
v_lshlrev_b32 v20, 16, v13
v_or_b32 v13, v18, v20
v_xor_b32 v18, v38, v19
v_xor_b32 v35, s24, v18
s_mov_b32 s26, 0x55555555
v_and_b32 v22, 0xfff, v35
v_mul_lo_i32 v18, v22, s26
v_or_b32 v14, 0, v17
v_add_i32 v17, vcc, v25, v14
v_bfe_u32 v19, v35, 1, 11
v_addc_u32 v20, vcc, v13, v26, vcc
v_add_i32 v18, vcc, v18, v19
v_bfe_u32 v19, v35, 3, 9
v_sub_i32 v18, vcc, v18, v19
v_lshrrev_b32 v26, 30, v18
s_mov_b32 s24, 0xaaaaaaab
v_sub_i32 v18, vcc, v22, v26
v_mul_lo_i32 v18, v18, s24
s_load_dwordx2 s[0:1], s[8:9], 0x40
s_mov_b32 s17, s16
s_load_dwordx2 s[8:9], s[8:9], 0x48
v_ashrrev_i32 v19, 31, v18
v_lshlrev_b64 v[18:19], 2, v[18:19]
s_mov_b32 s18, s16
s_mov_b32 s19, s16
s_waitcnt lgkmcnt(0)
v_add_i32 v24, vcc, s8, v18
v_mul_u32_u24 v18, 10, v26
v_mov_b32 v25, s9
v_and_b32 v18, 30, v18
v_addc_u32 v25, vcc, v19, v25, vcc
v_lshlrev_b32 v19, v18, 1
flat_atomic_add v19, v[24:25], v19 glc
s_waitcnt vmcnt(0) lgkmcnt(0)
v_xor_b32 v24, v39, v28
s_mov_b32 s20, s16
s_mov_b32 s21, s16
s_mov_b32 s22, s16
s_mov_b32 s23, s16
v_xor_b32 v36, s25, v24
v_lshlrev_b32 v37, 1, v0
v_bfe_u32 v33, v19, v18, 10
v_mov_b32 v18, 0x2ac
v_xor_b32 v19, v29, v12
v_cmp_gt_u32_e32 vcc, v18, v33
v_xor_b32 v18, v27, v10
v_mov_b32 v31, s23
v_xor_b32 v18, s14, v18
v_xor_b32 v19, s15, v19
v_mov_b32 v30, s22
v_mov_b32 v29, s21
v_mov_b32 v28, s20
v_mov_b32 v27, s19
v_mov_b32 v26, s18
v_mov_b32 v25, s17
v_mov_b32 v24, s16
s_and_saveexec_b64 s[14:15], vcc
s_xor_b64 s[14:15], exec, s[14:15]
s_cbranch_execz BB10_2
v_xor_b32 v0, v21, v17
v_xor_b32 v21, v23, v20
v_xor_b32 v26, s12, v0
v_xor_b32 v27, s13, v21
v_xor_b32 v0, v32, v4
v_xor_b32 v21, v34, v3
v_xor_b32 v28, s10, v0
v_xor_b32 v29, s11, v21
v_lshrrev_b64 v[23:24], 8, v[28:29]
s_mov_b32 s10, 0xff000000
v_and_b32 v0, s10, v23
v_lshrrev_b64 v[23:24], 8, v[26:27]
v_and_b32 v21, s10, v23
v_lshrrev_b64 v[23:24], 8, v[35:36]
v_and_b32 v23, s10, v23
v_lshrrev_b32 v24, 8, v35
v_or_b32 v23, v24, v23
v_lshrrev_b32 v24, 8, v36
v_lshlrev_b32 v25, 24, v26
v_or_b32 v24, v25, v24
v_lshrrev_b32 v25, 8, v26
v_or_b32 v25, v25, v21
v_lshrrev_b32 v21, 8, v27
v_lshlrev_b32 v26, 24, v28
v_or_b32 v26, v21, v26
v_lshrrev_b32 v21, 8, v28
v_or_b32 v35, v21, v0
v_lshlrev_b32 v0, 24, v18
v_lshrrev_b32 v21, 8, v29
v_or_b32 v36, v0, v21
v_mov_b32 v0, 0x2ac
v_mad_i32_i24 v21, v0, v22, v33
v_mov_b32 v22, 0
v_lshlrev_b64 v[21:22], 5, v[21:22]
v_add_i32 v27, vcc, s0, v21
v_mov_b32 v0, s1
v_addc_u32 v28, vcc, v22, v0, vcc
v_add_i32 v21, vcc, 16, v27
v_addc_u32 v22, vcc, 0, v28, vcc
flat_store_dwordx4 v[27:28], v[23:26]
s_waitcnt vmcnt(0) lgkmcnt(0)
flat_store_dwordx4 v[21:22], v[35:38]
s_waitcnt vmcnt(0) lgkmcnt(0)
BB10_2:
s_or_b64 exec, exec, s[14:15]
v_bfe_u32 v0, v18, 8, 12
v_mul_lo_i32 v21, v0, s26
v_lshrrev_b32 v22, 8, v18
v_bfe_u32 v23, v22, 1, 11
v_bfe_u32 v22, v22, 3, 9
v_add_i32 v21, vcc, v23, v21
v_subrev_i32 v21, vcc, v22, v21
v_lshrrev_b32 v22, 30, v21
v_subrev_i32 v21, vcc, v22, v0
v_mul_lo_i32 v21, v21, s24
v_mul_u32_u24 v25, 10, v22
v_ashrrev_i32 v22, 31, v21
v_lshlrev_b64 v[21:22], 2, v[21:22]
v_add_i32 v23, vcc, s8, v21
v_mov_b32 v21, s9
v_addc_u32 v24, vcc, v22, v21, vcc
v_and_b32 v21, 30, v25
v_lshlrev_b32 v22, v21, 1
flat_atomic_add v22, v[23:24], v22 glc
s_waitcnt vmcnt(0) lgkmcnt(0)
v_bfe_u32 v21, v22, v21, 10
v_mov_b32 v22, 0x2ac
v_cmp_gt_u32_e32 vcc, v22, v21
s_and_saveexec_b64 s[8:9], vcc
s_xor_b64 s[8:9], exec, s[8:9]
s_cbranch_execz BB10_4
v_xor_b32 v22, v8, v10
v_xor_b32 v8, v1, v3
v_xor_b32 v23, v7, v12
v_xor_b32 v7, v2, v4
v_lshrrev_b32 v3, 31, v8
v_lshlrev_b64 v[1:2], 1, v[7:8]
v_or_b32 v7, v3, v1
v_or_b32 v8, 0, v2
v_lshlrev_b64 v[1:2], 1, v[22:23]
v_lshrrev_b32 v3, 31, v23
v_or_b32 v10, v3, v1
v_or_b32 v12, 0, v2
v_xor_b32 v2, v15, v20
v_xor_b32 v1, v16, v17
v_lshrrev_b32 v3, 31, v2
v_lshlrev_b64 v[1:2], 1, v[1:2]
v_or_b32 v1, v3, v1
v_or_b32 v2, 0, v2
v_xor_b32 v1, v1, v6
v_xor_b32 v2, v2, v5
v_xor_b32 v3, s6, v1
v_xor_b32 v1, v7, v11
v_xor_b32 v4, s7, v2
v_xor_b32 v2, v8, v9
v_xor_b32 v5, s4, v1
v_xor_b32 v1, v10, v14
v_xor_b32 v6, s5, v2
v_xor_b32 v7, s2, v1
v_lshrrev_b64 v[1:2], 8, v[18:19]
v_lshlrev_b32 v1, 24, v3
v_xor_b32 v8, v12, v13
v_or_b32 v13, v2, v1
v_lshrrev_b64 v[1:2], 8, v[3:4]
v_lshlrev_b32 v9, 24, v5
v_or_b32 v14, v2, v9
v_lshlrev_b32 v11, 24, v7
v_lshrrev_b64 v[9:10], 8, v[5:6]
v_xor_b32 v8, s3, v8
v_lshrrev_b64 v[3:4], 16, v[3:4]
v_or_b32 v15, v10, v11
v_lshrrev_b64 v[28:29], 16, v[5:6]
v_lshlrev_b64 v[4:5], 16, v[7:8]
v_lshlrev_b64 v[11:12], 24, v[1:2]
v_and_b32 v4, 0xff000000, v4
v_lshrrev_b32 v5, 8, v15
v_or_b32 v29, v4, v5
v_lshrrev_b32 v12, 8, v13
v_lshrrev_b64 v[1:2], 16, v[18:19]
v_mov_b32 v4, 0x2ac
v_or_b32 v2, v12, v11
v_mad_i32_i24 v11, v4, v0, v21
v_mov_b32 v12, 0
v_lshlrev_b64 v[4:5], 5, v[11:12]
v_add_i32 v6, vcc, s0, v4
v_mov_b32 v0, s1
v_addc_u32 v7, vcc, v5, v0, vcc
v_lshlrev_b64 v[9:10], 24, v[9:10]
v_add_i32 v4, vcc, 16, v6
v_or_b32 v30, 1, v37
v_addc_u32 v5, vcc, 0, v7, vcc
v_lshrrev_b32 v10, 8, v14
flat_store_dwordx4 v[4:5], v[28:31]
s_waitcnt vmcnt(0) lgkmcnt(0)
v_or_b32 v4, v10, v9
flat_store_dwordx4 v[6:7], v[1:4]
s_waitcnt vmcnt(0) lgkmcnt(0)
BB10_4:
s_or_b64 exec, exec, s[8:9]
s_endpgm
.section .AMDGPU.csdata
.section .AMDGPU.runtime_metadata
.byte 4
.byte 6
.long 13
.ascii "kernel_round0"
.byte 7
.byte 9
.long 4
.byte 10
.long 4
.byte 11
.long 4
.ascii "uint"
.byte 13
.byte 0
.byte 14
.short 7
.byte 16
.byte 0
.byte 8
.byte 7
.byte 9
.long 8
.byte 10
.long 8
.byte 11
.long 6
.ascii "ulong*"
.byte 17
.byte 13
.byte 1
.byte 14
.short 10
.byte 16
.byte 0
.byte 15
.byte 2
.byte 8
.byte 7
.byte 9
.long 8
.byte 10
.long 8
.byte 11
.long 5
.ascii "char*"
.byte 13
.byte 1
.byte 14
.short 1
.byte 16
.byte 0
.byte 15
.byte 1
.byte 8
.byte 7
.byte 9
.long 8
.byte 10
.long 8
.byte 11
.long 5
.ascii "uint*"
.byte 13
.byte 1
.byte 14
.short 7
.byte 16
.byte 0
.byte 15
.byte 1
.byte 8
.byte 7
.byte 9
.long 8
.byte 10
.long 8
.byte 11
.long 5
.ascii "uint*"
.byte 13
.byte 1
.byte 14
.short 7
.byte 16
.byte 0
.byte 15
.byte 1
.byte 8
.byte 5
.section .AMDGPU.config
.text
.globl xor_and_store
.p2align 8
.type xor_and_store,@function
xor_and_store:
.amd_kernel_code_t
max_scratch_backing_memory_byte_size = 0
.dx10clamp
enable_ordered_append_gds = 0
private_element_size = 1
workitem_private_segment_byte_size = 64
workgroup_group_segment_byte_size = 0
gds_segment_byte_size = 0
workgroup_fbarrier_count = 0
wavefront_sgpr_count = 20
workitem_vgpr_count = 13
group_segment_alignment = 4
private_segment_alignment = 4
.end_amd_kernel_code_t
s_load_dword s5, s[8:9], 0x4c
s_add_u32 s10, s10, s13
s_lshr_b32 flat_scratch_hi, s10, 8
v_mov_b32 v0, 0
s_mov_b32 flat_scratch_lo, s11
s_waitcnt lgkmcnt(0)
s_cmp_gt_u32 s5, 0x2ab
s_cbranch_scc1 BB11_41
s_load_dword s7, s[8:9], 0x54
s_mov_b32 m0, -1
s_load_dword s4, s[8:9], 0x34
s_load_dword s6, s[8:9], 0x58
s_waitcnt lgkmcnt(0)
v_mov_b32 v2, s7
ds_read_b32 v1, v2
ds_read_b32 v2, v2 offset:2736
s_mov_b32 m0, -1
s_cmp_gt_u32 s4, 7
s_waitcnt lgkmcnt(0)
s_cbranch_scc1 BB11_10
v_mov_b32 v3, s7
ds_read_b32 v4, v3 offset:5472
s_mov_b32 m0, -1
s_cmp_eq_i32 s4, 7
s_waitcnt lgkmcnt(0)
s_cbranch_scc0 BB11_3
v_mov_b32 v3, s6
ds_read_b32 v5, v3
ds_read_b32 v6, v3 offset:2736
ds_read_b32 v3, v3 offset:5472
s_waitcnt lgkmcnt(0)
v_xor_b32 v1, v5, v1
v_xor_b32 v2, v6, v2
v_xor_b32 v3, v3, v4
v_lshlrev_b32 v4, 24, v2
v_lshrrev_b32 v5, 8, v1
v_or_b32 v4, v4, v5
buffer_store_dword v4, v0, s[0:3], s13 offen
v_lshlrev_b32 v3, 24, v3
s_waitcnt vmcnt(0) expcnt(0)
v_lshrrev_b32 v4, 8, v2
v_or_b32 v3, v3, v4
buffer_store_dword v3, v0, s[0:3], s13 offen offset:4
v_mov_b32 v6, 0
s_waitcnt vmcnt(0) expcnt(0)
s_branch BB11_21
BB11_10:
v_mov_b32 v3, s6
ds_read_b32 v4, v3
ds_read_b32 v3, v3 offset:2736
v_mov_b32 v8, 0
s_waitcnt lgkmcnt(0)
v_xor_b32 v1, v4, v1
v_xor_b32 v2, v3, v2
s_branch BB11_11
BB11_3:
v_mov_b32 v3, s7
ds_read_b32 v5, v3 offset:8208
s_mov_b32 m0, -1
s_cmp_lt_u32 s4, 5
s_waitcnt lgkmcnt(0)
s_cbranch_scc0 BB11_4
v_mov_b32 v3, s7
ds_read_b32 v6, v3 offset:10944
s_cmp_gt_u32 s4, 2
s_waitcnt lgkmcnt(0)
s_cbranch_scc1 BB11_7
s_mov_b32 m0, -1
v_mov_b32 v3, s7
ds_read_b32 v3, v3 offset:13680
s_waitcnt lgkmcnt(0)
BB11_7:
s_mov_b32 m0, -1
v_mov_b32 v7, s6
ds_read_b32 v8, v7
ds_read_b32 v9, v7 offset:2736
ds_read_b32 v11, v7 offset:8208
ds_read_b32 v10, v7 offset:5472
ds_read_b32 v12, v7 offset:10944
s_waitcnt lgkmcnt(0)
v_xor_b32 v1, v8, v1
v_xor_b32 v2, v9, v2
v_xor_b32 v5, v11, v5
v_xor_b32 v7, v10, v4
v_xor_b32 v4, v12, v6
v_mov_b32 v8, -1
s_cmp_lt_u32 s4, 3
s_cbranch_scc0 BB11_11
s_mov_b32 m0, -1
v_mov_b32 v6, s6
ds_read_b32 v6, v6 offset:13680
s_waitcnt lgkmcnt(0)
v_xor_b32 v3, v6, v3
s_branch BB11_11
BB11_4:
v_mov_b32 v3, s6
ds_read_b32 v6, v3
ds_read_b32 v7, v3 offset:2736
ds_read_b32 v8, v3 offset:5472
ds_read_b32 v3, v3 offset:8208
s_waitcnt lgkmcnt(0)
v_xor_b32 v1, v6, v1
v_xor_b32 v2, v7, v2
v_xor_b32 v7, v8, v4
v_xor_b32 v5, v3, v5
v_mov_b32 v8, -1
BB11_11:
s_and_b32 s6, 1, s4
v_cmp_eq_i32 s[6:7], 1, s6
s_and_b64 vcc, exec, s[6:7]
s_cbranch_vccnz BB11_13
v_lshrrev_b32 v1, 24, v1
v_lshlrev_b32 v6, 8, v2
v_or_b32 v1, v6, v1
buffer_store_dword v2, v0, s[0:3], s13 offen
s_nop 0
buffer_store_dword v7, v0, s[0:3], s13 offen offset:4
s_nop 0
buffer_store_dword v5, v0, s[0:3], s13 offen offset:8
s_nop 0
buffer_store_dword v4, v0, s[0:3], s13 offen offset:12
s_nop 0
buffer_store_dword v3, v0, s[0:3], s13 offen offset:16
v_mov_b32 v6, -1
s_waitcnt vmcnt(0) expcnt(0)
s_branch BB11_21
BB11_13:
v_lshlrev_b32 v6, 24, v2
v_lshrrev_b32 v9, 8, v1
v_or_b32 v6, v6, v9
buffer_store_dword v6, v0, s[0:3], s13 offen
s_cmp_gt_u32 s4, 7
s_waitcnt vmcnt(0) expcnt(0)
s_cbranch_scc1 BB11_15
v_lshlrev_b32 v6, 24, v7
v_lshrrev_b32 v9, 8, v2
v_cmp_ne_i32_e32 vcc, 0, v8
v_or_b32 v6, v6, v9
buffer_store_dword v6, v0, s[0:3], s13 offen offset:4
s_and_b64 vcc, exec, vcc
s_waitcnt vmcnt(0) expcnt(0)
s_cbranch_vccnz BB11_16
s_branch BB11_17
BB11_15:
v_cmp_ne_i32_e32 vcc, 0, v8
v_cndmask_b32 v8, 0, 1, vcc
v_cmp_ne_i32_e32 vcc, 1, v8
v_mov_b32 v6, 0
s_and_b64 vcc, exec, vcc
s_cbranch_vccnz BB11_21
BB11_16:
v_lshlrev_b32 v6, 24, v5
v_lshrrev_b32 v7, 8, v7
v_or_b32 v6, v6, v7
buffer_store_dword v6, v0, s[0:3], s13 offen offset:8
s_waitcnt vmcnt(0) expcnt(0)
BB11_17:
v_mov_b32 v6, 0
s_cmp_gt_u32 s4, 5
s_cbranch_scc1 BB11_21
v_lshlrev_b32 v7, 24, v4
v_lshrrev_b32 v5, 8, v5
v_or_b32 v5, v7, v5
buffer_store_dword v5, v0, s[0:3], s13 offen offset:12
s_cmp_gt_u32 s4, 3
s_waitcnt vmcnt(0) expcnt(0)
s_cbranch_scc1 BB11_21
v_lshlrev_b32 v5, 24, v3
v_lshrrev_b32 v4, 8, v4
v_or_b32 v4, v5, v4
v_mov_b32 v6, 0
buffer_store_dword v4, v0, s[0:3], s13 offen offset:16
s_cmp_gt_u32 s4, 1
s_waitcnt vmcnt(0) expcnt(0)
s_cbranch_scc1 BB11_21
v_lshrrev_b32 v3, 8, v3
buffer_store_dword v3, v0, s[0:3], s13 offen offset:20
s_waitcnt vmcnt(0) expcnt(0)
BB11_21:
s_load_dword s6, s[8:9], 0x48
s_load_dword s7, s[8:9], 0x50
s_or_b32 s10, s4, 1
v_mov_b32 v3, 6
s_cmp_eq_i32 s10, 1
s_waitcnt lgkmcnt(0)
s_cbranch_scc1 BB11_26
v_mov_b32 v3, 5
s_cmp_eq_i32 s10, 3
s_cbranch_scc1 BB11_26
v_mov_b32 v3, 4
s_cmp_eq_i32 s10, 5
s_cbranch_scc1 BB11_26
v_mov_b32 v3, 3
s_cmp_eq_i32 s4, 6
s_cbranch_scc1 BB11_26
v_cmp_eq_i32 s[10:11], 7, s4
v_cndmask_b32 v3, 1, 2, s[10:11]
BB11_26:
s_lshl_b32 s7, s7, 10
s_lshl_b32 s6, s6, 20
s_and_b32 s5, s5, 0x3ff
v_lshlrev_b32 v3, 2, v3
s_and_b32 s7, s7, 0xffc00
s_or_b32 s5, s5, s6
s_or_b32 s5, s5, s7
v_add_i32 v3, vcc, 0, v3
v_or_b32 v2, v2, v1
v_cmp_eq_i32_e32 vcc, 0, v2
v_mov_b32 v4, s5
buffer_store_dword v4, v3, s[0:3], s13 offen
s_and_b64 vcc, exec, vcc
s_waitcnt vmcnt(0) expcnt(0)
s_cbranch_vccnz BB11_41
s_load_dwordx2 s[6:7], s[8:9], 0x60
v_cmp_ne_i32_e32 vcc, 0, v6
v_cndmask_b32 v2, 0, 1, vcc
v_cmp_ne_i32_e32 vcc, 1, v2
s_and_b64 vcc, exec, vcc
s_waitcnt lgkmcnt(0)
s_cbranch_vccnz BB11_29
v_and_b32 v1, 0xfff, v1
s_branch BB11_30
BB11_29:
v_lshrrev_b32 v2, 8, v1
v_lshrrev_b32 v1, 24, v1
v_and_b32 v2, 0xf0f, v2
v_and_b32 v1, 0xf0, v1
v_or_b32 v1, v2, v1
BB11_30:
s_mov_b32 s5, 0x55555555
v_mul_lo_i32 v2, s5, v1
v_lshrrev_b32 v3, 1, v1
v_lshrrev_b32 v4, 3, v1
s_mov_b32 s5, 0xaaaaaaab
v_add_i32 v2, vcc, v2, v3
v_sub_i32 v2, vcc, v2, v4
v_lshrrev_b32 v3, 30, v2
v_subrev_i32 v2, vcc, v3, v1
v_mul_lo_i32 v2, s5, v2
v_mul_u32_u24 v6, 10, v3
v_ashrrev_i32 v3, 31, v2
v_lshlrev_b64 v[2:3], 2, v[2:3]
v_add_i32 v4, vcc, s6, v2
v_mov_b32 v2, s7
v_addc_u32 v5, vcc, v3, v2, vcc
v_and_b32 v2, 30, v6
v_lshlrev_b32 v3, v2, 1
flat_atomic_add v3, v[4:5], v3 glc
s_waitcnt vmcnt(0) lgkmcnt(0)
v_bfe_u32 v2, v3, v2, 10
v_mov_b32 v3, 0x2ac
v_cmp_gt_u32_e32 vcc, v3, v2
s_and_saveexec_b64 s[6:7], vcc
s_xor_b64 s[6:7], exec, s[6:7]
s_cbranch_execz BB11_40
s_load_dwordx2 s[8:9], s[8:9], 0x40
v_mov_b32 v3, 32
s_cmp_lt_u32 s4, 6
s_waitcnt lgkmcnt(0)
s_cbranch_scc1 BB11_33
s_or_b32 s5, s4, 7
v_cmp_eq_i32 s[10:11], 7, s5
v_cndmask_b32 v3, 8, 16, s[10:11]
BB11_33:
v_mov_b32 v4, 0x2ac
v_mad_i32_i24 v1, v4, v1, v2
v_mul_lo_i32 v1, v3, v1
v_mov_b32 v2, s9
v_ashrrev_i32 v3, 31, v1
v_add_i32 v1, vcc, s8, v1
v_addc_u32 v2, vcc, v3, v2, vcc
v_cmp_ne_i64_e32 vcc, 0, v[1:2]
s_and_saveexec_b64 s[8:9], vcc
s_xor_b64 s[8:9], exec, s[8:9]
s_cbranch_execz BB11_39
s_cmp_lt_u32 s4, 8
s_cbranch_scc1 BB11_36
buffer_load_dword v3, v0, s[0:3], s13 offen
s_nop 0
buffer_load_dword v4, v0, s[0:3], s13 offen offset:4
s_waitcnt vmcnt(0)
flat_store_dwordx2 v[1:2], v[3:4]
s_waitcnt vmcnt(0) lgkmcnt(0)
s_branch BB11_39
BB11_36:
s_cmp_lt_u32 s4, 6
s_cbranch_scc1 BB11_38
buffer_load_dword v3, v0, s[0:3], s13 offen
s_nop 0
buffer_load_dword v4, v0, s[0:3], s13 offen offset:4
s_nop 0
buffer_load_dword v5, v0, s[0:3], s13 offen offset:8
s_nop 0
buffer_load_dword v6, v0, s[0:3], s13 offen offset:12
s_waitcnt vmcnt(0)
flat_store_dwordx4 v[1:2], v[3:6]
s_waitcnt vmcnt(0) lgkmcnt(0)
s_branch BB11_39
BB11_38:
buffer_load_dword v3, v0, s[0:3], s13 offen
s_nop 0
buffer_load_dword v4, v0, s[0:3], s13 offen offset:4
s_nop 0
buffer_load_dword v5, v0, s[0:3], s13 offen offset:8
s_nop 0
buffer_load_dword v6, v0, s[0:3], s13 offen offset:12
s_nop 0
buffer_load_dword v7, v0, s[0:3], s13 offen offset:16
s_nop 0
buffer_load_dword v8, v0, s[0:3], s13 offen offset:20
s_nop 0
buffer_load_dword v9, v0, s[0:3], s13 offen offset:24
s_nop 0
buffer_load_dword v10, v0, s[0:3], s13 offen offset:28
v_add_i32 v0, vcc, 16, v1
s_waitcnt vmcnt(4)
flat_store_dwordx4 v[1:2], v[3:6]
s_waitcnt vmcnt(0) lgkmcnt(0)
v_addc_u32 v1, vcc, 0, v2, vcc
flat_store_dwordx4 v[0:1], v[7:10]
s_waitcnt vmcnt(0) lgkmcnt(0)
BB11_39:
s_or_b64 exec, exec, s[8:9]
BB11_40:
s_or_b64 exec, exec, s[6:7]
BB11_41:
s_endpgm
.section .AMDGPU.csdata
.section .AMDGPU.config
.text
.globl parallel_xor_and_store
.p2align 8
.type parallel_xor_and_store,@function
parallel_xor_and_store:
.amd_kernel_code_t
max_scratch_backing_memory_byte_size = 0
.dx10clamp
enable_ordered_append_gds = 0
private_element_size = 1
workitem_private_segment_byte_size = 0
workgroup_group_segment_byte_size = 0
gds_segment_byte_size = 0
workgroup_fbarrier_count = 0
wavefront_sgpr_count = 16
workitem_vgpr_count = 6
group_segment_alignment = 4
private_segment_alignment = 4
.end_amd_kernel_code_t
s_load_dword s0, s[8:9], 0x68
s_load_dword s1, s[8:9], 0x4c
v_lshlrev_b32 v0, 1, v0
v_mov_b32 v1, 0x2ac
s_mov_b32 m0, -1
s_waitcnt lgkmcnt(0)
v_add_i32 v0, vcc, s0, v0
ds_write_b16 v0, v1
s_cmp_gt_u32 s1, 0x2ab
s_waitcnt lgkmcnt(0)
s_cbranch_scc1 BB12_6
s_load_dword s0, s[8:9], 0x54
s_load_dword s1, s[8:9], 0x58
s_mov_b32 m0, -1
s_waitcnt lgkmcnt(0)
v_mov_b32 v1, s0
v_mov_b32 v2, s1
ds_read_b32 v3, v1
ds_read_b32 v4, v2
ds_read_b32 v1, v1 offset:2736
ds_read_b32 v2, v2 offset:2736
s_load_dword s0, s[8:9], 0x34
s_waitcnt lgkmcnt(0)
v_xor_b32 v3, v3, v4
v_xor_b32 v1, v1, v2
s_and_b32 s0, s0, 1
v_lshrrev_b32 v2, 24, v3
v_lshlrev_b32 v4, 8, v1
v_cmp_eq_i32 vcc, 0, s0
s_and_b32 s0, 1, s0
v_or_b32 v2, v4, v2
v_cndmask_b32 v3, v3, v2, vcc
v_cmp_eq_i32 s[0:1], 1, s0
s_and_b64 vcc, exec, s[0:1]
s_cbranch_vccnz BB12_3
v_and_b32 v2, 0xfff, v3
s_branch BB12_4
BB12_3:
v_lshrrev_b32 v2, 8, v3
v_lshrrev_b32 v4, 24, v3
v_and_b32 v2, 0xf0f, v2
v_and_b32 v4, 0xf0, v4
v_or_b32 v2, v2, v4
BB12_4:
v_or_b32 v1, v3, v1
v_cmp_eq_i32_e32 vcc, 0, v1
s_and_b64 vcc, exec, vcc
s_cbranch_vccnz BB12_6
s_mov_b32 s0, 0x55555555
v_mul_lo_i32 v1, s0, v2
v_lshrrev_b32 v3, 1, v2
v_lshrrev_b32 v4, 3, v2
s_mov_b32 s0, 0xaaaaaaab
v_add_i32 v1, vcc, v1, v3
v_sub_i32 v1, vcc, v1, v4
v_lshrrev_b32 v3, 30, v1
v_subrev_i32 v1, vcc, v3, v2
v_mul_lo_i32 v1, s0, v1
s_load_dwordx2 s[0:1], s[8:9], 0x60
v_mul_u32_u24 v5, 10, v3
s_mov_b32 m0, -1
v_ashrrev_i32 v2, 31, v1
v_lshlrev_b64 v[1:2], 2, v[1:2]
s_waitcnt lgkmcnt(0)
v_add_i32 v3, vcc, s0, v1
v_mov_b32 v1, s1
v_addc_u32 v4, vcc, v2, v1, vcc
v_and_b32 v1, 30, v5
v_lshlrev_b32 v2, v1, 1
flat_atomic_add v2, v[3:4], v2 glc
s_waitcnt vmcnt(0) lgkmcnt(0)
v_bfe_u32 v1, v2, v1, 10
ds_write_b16 v0, v1
s_waitcnt lgkmcnt(0)
BB12_6:
s_barrier
s_endpgm
.section .AMDGPU.csdata
.section .AMDGPU.config
.text
.globl equihash_round
.p2align 8
.type equihash_round,@function
equihash_round:
.amd_kernel_code_t
max_scratch_backing_memory_byte_size = 0
.dx10clamp
enable_ordered_append_gds = 0
private_element_size = 1
workitem_private_segment_byte_size = 64
workgroup_group_segment_byte_size = 0
gds_segment_byte_size = 0
workgroup_fbarrier_count = 0
wavefront_sgpr_count = 38
workitem_vgpr_count = 19
group_segment_alignment = 4
private_segment_alignment = 4
.end_amd_kernel_code_t
s_add_u32 s10, s10, s13
s_lshr_b32 flat_scratch_hi, s10, 8
v_mov_b32 v1, 0
s_mov_b32 flat_scratch_lo, s11
s_cmp_gt_u32 s12, 0xfff
s_cbranch_scc1 BB13_95
s_load_dword s18, s[8:9], 0x5c
s_load_dword s20, s[8:9], 0x70
v_mov_b32 v2, 0x100
v_cmp_gt_u32_e32 vcc, v2, v0
s_waitcnt lgkmcnt(0)
s_and_saveexec_b64 s[4:5], vcc
s_xor_b64 s[4:5], exec, s[4:5]
s_cbranch_execz BB13_10
v_lshlrev_b32 v3, 2, v0
v_add_i32 v2, vcc, 0xffffff00, v0
v_add_i32 v3, vcc, s20, v3
s_mov_b64 s[6:7], 0
s_mov_b32 m0, -1
BB13_12:
v_mov_b32 v4, 0x2ac
ds_write_b32 v3, v4
v_add_i32 v2, vcc, 0x100, v2
v_add_i32 v3, vcc, 0x400, v3
s_waitcnt lgkmcnt(0)
v_mov_b32 v4, 0xffffff00
v_cmp_gt_u32_e32 vcc, v4, v2
s_or_b64 s[6:7], vcc, s[6:7]
s_andn2_b64 exec, exec, s[6:7]
s_cbranch_execnz BB13_12
s_or_b64 exec, exec, s[6:7]
BB13_10:
s_or_b64 exec, exec, s[4:5]
s_load_dwordx2 s[6:7], s[8:9], 0x68
s_load_dword s19, s[8:9], 0x74
s_load_dword s10, s[8:9], 0x34
s_load_dwordx2 s[22:23], s[8:9], 0x38
s_load_dwordx2 s[14:15], s[8:9], 0x40
s_load_dword s11, s[8:9], 0x50
s_load_dword s16, s[8:9], 0x54
s_load_dword s17, s[8:9], 0x58
s_load_dwordx2 s[24:25], s[8:9], 0x60
v_mov_b32 v2, 0x2ac
v_cmp_gt_u32_e32 vcc, v2, v0
v_mov_b32 v2, 0
s_waitcnt lgkmcnt(0)
s_and_saveexec_b64 s[8:9], vcc
s_xor_b64 s[8:9], exec, s[8:9]
s_cbranch_execz BB13_19
v_sub_i32 v2, vcc, 0x2ab, v0
v_lshrrev_b32 v6, 8, v2
v_add_i32 v4, vcc, 1, v6
v_cmp_gt_u32_e32 vcc, 64, v4
v_cndmask_b32 v5, 0, -1, vcc
v_mov_b32 v2, v0
v_cmp_lt_u32_e32 vcc, 63, v4
s_and_saveexec_b64 s[26:27], vcc
s_xor_b64 s[26:27], exec, s[26:27]
s_cbranch_execz BB13_6
v_and_b32 v3, 63, v4
v_subrev_i32 v4, vcc, v3, v4
v_mov_b32 v5, -1
v_mov_b32 v2, v0
v_cmp_ne_i32_e32 vcc, 0, v4
s_and_saveexec_b64 s[28:29], vcc
s_xor_b64 s[28:29], exec, s[28:29]
s_cbranch_execz BB13_5
v_lshlrev_b32 v2, 8, v6
v_add_i32 v2, vcc, v2, v0
v_add_i32 v2, vcc, 0x100, v2
v_lshlrev_b32 v5, 8, v3
v_subrev_i32 v2, vcc, v5, v2
s_mov_b64 s[30:31], 0
v_mov_b32 v5, 0
s_mov_b32 m0, -1
BB13_8:
v_or_b32 v6, v5, v0
v_lshlrev_b32 v6, 1, v6
v_add_i32 v4, vcc, 0xffffffc0, v4
v_add_i32 v5, vcc, 0x4000, v5
v_mov_b32 v7, 0x2ac
v_add_i32 v6, vcc, s19, v6
v_cmp_eq_i32 s[4:5], 0, v4
ds_write_b16 v6, v7
ds_write_b16 v6, v7 offset:512
ds_write_b16 v6, v7 offset:1024
ds_write_b16 v6, v7 offset:1536
ds_write_b16 v6, v7 offset:2048
ds_write_b16 v6, v7 offset:2560
ds_write_b16 v6, v7 offset:3072
ds_write_b16 v6, v7 offset:3584
ds_write_b16 v6, v7 offset:4096
ds_write_b16 v6, v7 offset:4608
ds_write_b16 v6, v7 offset:5120
ds_write_b16 v6, v7 offset:5632
ds_write_b16 v6, v7 offset:6144
ds_write_b16 v6, v7 offset:6656
ds_write_b16 v6, v7 offset:7168
ds_write_b16 v6, v7 offset:7680
ds_write_b16 v6, v7 offset:8192
ds_write_b16 v6, v7 offset:8704
ds_write_b16 v6, v7 offset:9216
ds_write_b16 v6, v7 offset:9728
ds_write_b16 v6, v7 offset:10240
ds_write_b16 v6, v7 offset:10752
ds_write_b16 v6, v7 offset:11264
ds_write_b16 v6, v7 offset:11776
ds_write_b16 v6, v7 offset:12288
ds_write_b16 v6, v7 offset:12800
ds_write_b16 v6, v7 offset:13312
ds_write_b16 v6, v7 offset:13824
ds_write_b16 v6, v7 offset:14336
ds_write_b16 v6, v7 offset:14848
ds_write_b16 v6, v7 offset:15360
ds_write_b16 v6, v7 offset:15872
ds_write_b16 v6, v7 offset:16384
ds_write_b16 v6, v7 offset:16896
ds_write_b16 v6, v7 offset:17408
ds_write_b16 v6, v7 offset:17920
ds_write_b16 v6, v7 offset:18432
ds_write_b16 v6, v7 offset:18944
ds_write_b16 v6, v7 offset:19456
ds_write_b16 v6, v7 offset:19968
ds_write_b16 v6, v7 offset:20480
ds_write_b16 v6, v7 offset:20992
ds_write_b16 v6, v7 offset:21504
ds_write_b16 v6, v7 offset:22016
ds_write_b16 v6, v7 offset:22528
ds_write_b16 v6, v7 offset:23040
ds_write_b16 v6, v7 offset:23552
ds_write_b16 v6, v7 offset:24064
ds_write_b16 v6, v7 offset:24576
ds_write_b16 v6, v7 offset:25088
ds_write_b16 v6, v7 offset:25600
ds_write_b16 v6, v7 offset:26112
ds_write_b16 v6, v7 offset:26624
ds_write_b16 v6, v7 offset:27136
ds_write_b16 v6, v7 offset:27648
ds_write_b16 v6, v7 offset:28160
ds_write_b16 v6, v7 offset:28672
ds_write_b16 v6, v7 offset:29184
ds_write_b16 v6, v7 offset:29696
ds_write_b16 v6, v7 offset:30208
ds_write_b16 v6, v7 offset:30720
ds_write_b16 v6, v7 offset:31232
ds_write_b16 v6, v7 offset:31744
ds_write_b16 v6, v7 offset:32256
s_or_b64 s[30:31], s[4:5], s[30:31]
s_waitcnt lgkmcnt(0)
s_andn2_b64 exec, exec, s[30:31]
s_cbranch_execnz BB13_8
s_or_b64 exec, exec, s[30:31]
v_cmp_ne_i32_e32 vcc, 0, v3
v_cndmask_b32 v5, 0, -1, vcc
BB13_5:
s_or_b64 exec, exec, s[28:29]
BB13_6:
s_or_b64 exec, exec, s[26:27]
v_cmp_ne_i32_e32 vcc, 0, v5
s_and_saveexec_b64 s[4:5], vcc
s_xor_b64 s[4:5], exec, s[4:5]
s_cbranch_execz BB13_16
v_lshlrev_b32 v3, 1, v2
v_add_i32 v3, vcc, s19, v3
s_mov_b64 s[26:27], 0
s_mov_b32 m0, -1
BB13_14:
v_mov_b32 v4, 0x2ac
ds_write_b16 v3, v4
v_add_i32 v2, vcc, 0x100, v2
v_add_i32 v3, vcc, 0x200, v3
s_waitcnt lgkmcnt(0)
v_mov_b32 v4, 0x2ab
v_cmp_lt_u32_e32 vcc, v4, v2
s_or_b64 s[26:27], vcc, s[26:27]
s_andn2_b64 exec, exec, s[26:27]
s_cbranch_execnz BB13_14
s_or_b64 exec, exec, s[26:27]
BB13_16:
s_or_b64 exec, exec, s[4:5]
v_mov_b32 v2, 0
v_cmp_eq_i32_e32 vcc, 0, v0
s_and_saveexec_b64 s[4:5], vcc
s_xor_b64 s[4:5], exec, s[4:5]
s_cbranch_execz BB13_18
s_mul_i32 s21, s12, 0x55555555
s_lshr_b32 s26, s12, 1
s_add_i32 s21, s21, s26
s_lshr_b32 s26, s12, 3
s_sub_i32 s21, s21, s26
s_lshr_b32 s21, s21, 30
s_sub_i32 s26, s12, s21
s_mul_i32 s26, s26, 0xaaaaaaab
s_ashr_i32 s27, s26, 31
s_lshl_b64 s[26:27], s[26:27], 2
s_add_u32 s24, s24, s26
s_addc_u32 s25, s25, s27
v_mov_b32 v3, s25
v_mov_b32 v2, s24
flat_load_dword v2, v[2:3]
v_mul_u32_u24 v3, 10, s21
v_and_b32 v3, 30, v3
s_mov_b32 m0, -1
s_waitcnt vmcnt(0) lgkmcnt(0)
v_bfe_u32 v2, v2, v3, 10
v_min_u32 v2, 0x2ac, v2
v_mov_b32 v3, s18
ds_write_b32 v3, v2
s_waitcnt lgkmcnt(0)
BB13_18:
s_or_b64 exec, exec, s[4:5]
BB13_19:
s_or_b64 exec, exec, s[8:9]
s_barrier
v_cmp_ne_i32_e32 vcc, 0, v0
s_and_saveexec_b64 s[4:5], vcc
s_xor_b64 s[4:5], exec, s[4:5]
s_mov_b32 m0, -1
v_mov_b32 v2, s18
ds_read_b32 v2, v2
s_waitcnt lgkmcnt(0)
BB13_21:
s_or_b64 exec, exec, s[4:5]
s_barrier
v_cmp_eq_i32_e32 vcc, 0, v0
s_and_saveexec_b64 s[4:5], vcc
s_xor_b64 s[4:5], exec, s[4:5]
v_mov_b32 v3, 0
s_mov_b32 m0, -1
v_mov_b32 v4, s18
ds_write_b32 v4, v3
s_waitcnt lgkmcnt(0)
BB13_23:
s_or_b64 exec, exec, s[4:5]
s_barrier
v_cmp_lt_u32_e32 vcc, v0, v2
s_and_saveexec_b64 s[4:5], vcc
s_xor_b64 s[4:5], exec, s[4:5]
s_cbranch_execz BB13_49
s_add_i32 s8, s10, -1
s_or_b32 s21, s8, 7
v_cmp_eq_i32 s[26:27], 7, s21
v_cndmask_b32 v3, 8, 16, s[26:27]
v_cmp_eq_i32 s[26:27], 7, s8
v_cmp_gt_u32 s[24:25], 6, s8
v_cndmask_b32 v6, 1, 2, s[26:27]
s_and_b32 s26, s10, 1
v_cndmask_b32 v3, v3, 32, s[24:25]
s_and_b32 s25, 1, s26
v_cmp_eq_i32 vcc, 1, s25
s_mul_i32 s9, s12, 0x2ac
v_mov_b32 v5, 0xf000
v_mov_b32 v4, 0xf0000
v_mov_b32 v7, 0xf0
v_cndmask_b32 v4, v4, v5, vcc
v_cndmask_b32 v5, v5, v7, vcc
v_add_i32 v8, vcc, s9, v0
v_mul_lo_i32 v8, v3, v8
s_lshl_b32 s25, s26, 2
s_add_i32 s24, s10, -5
v_cmp_eq_i32 s[30:31], 6, s8
s_xor_b32 s25, s25, 4
s_lshl_b32 s26, s26, 3
v_lshlrev_b32 v10, 2, v0
v_cmp_gt_u32 s[28:29], 2, s24
v_cndmask_b32 v6, v6, 3, s[30:31]
v_cndmask_b32 v7, v6, 4, s[28:29]
s_add_i32 s21, s10, -3
s_add_i32 s25, s25, 12
s_xor_b32 s26, s26, 8
v_lshlrev_b32 v9, 8, v3
v_add_i32 v10, vcc, s11, v10
s_mov_b64 s[28:29], 0
v_mov_b32 v11, v0
BB13_25:
v_add_i32 v12, vcc, s9, v11
v_mul_lo_i32 v12, v12, v3
v_mov_b32 v14, s23
s_cmp_gt_u32 s8, 1
v_ashrrev_i32 v13, 31, v12
v_add_i32 v12, vcc, s22, v12
v_addc_u32 v13, vcc, v13, v14, vcc
s_cbranch_scc1 BB13_33
s_cmp_gt_u32 s21, 1
s_cbranch_scc1 BB13_30
s_cmp_lt_u32 s24, 2
s_cbranch_scc0 BB13_28
flat_load_dword v14, v[12:13]
s_waitcnt vmcnt(0) lgkmcnt(0)
buffer_store_dword v14, v1, s[0:3], s13 offen
s_waitcnt vmcnt(0) expcnt(0)
v_add_i32 v14, vcc, 4, v12
v_addc_u32 v15, vcc, 0, v13, vcc
flat_load_dword v14, v[14:15]
s_waitcnt vmcnt(0) lgkmcnt(0)
buffer_store_dword v14, v1, s[0:3], s13 offen offset:4
s_waitcnt vmcnt(0) expcnt(0)
v_add_i32 v14, vcc, 8, v12
v_addc_u32 v15, vcc, 0, v13, vcc
flat_load_dword v14, v[14:15]
s_waitcnt vmcnt(0) lgkmcnt(0)
buffer_store_dword v14, v1, s[0:3], s13 offen offset:8
s_waitcnt vmcnt(0) expcnt(0)
v_add_i32 v14, vcc, 12, v12
v_addc_u32 v15, vcc, 0, v13, vcc
flat_load_dword v14, v[14:15]
s_waitcnt vmcnt(0) lgkmcnt(0)
buffer_store_dword v14, v1, s[0:3], s13 offen offset:12
s_waitcnt vmcnt(0) expcnt(0)
v_add_i32 v14, vcc, 16, v12
v_addc_u32 v15, vcc, 0, v13, vcc
flat_load_dword v14, v[14:15]
s_waitcnt vmcnt(0) lgkmcnt(0)
buffer_store_dword v14, v1, s[0:3], s13 offen offset:16
s_waitcnt vmcnt(0) expcnt(0)
v_add_i32 v14, vcc, 20, v12
v_addc_u32 v15, vcc, 0, v13, vcc
flat_load_dword v12, v[14:15]
s_waitcnt vmcnt(0) lgkmcnt(0)
buffer_store_dword v12, v1, s[0:3], s13 offen offset:20
s_waitcnt vmcnt(0) expcnt(0)
s_branch BB13_41
BB13_33:
s_cmp_gt_u32 s21, 1
s_cbranch_scc1 BB13_37
s_cmp_lt_u32 s24, 2
s_cbranch_scc0 BB13_35
flat_load_dword v14, v[12:13]
s_waitcnt vmcnt(0) lgkmcnt(0)
buffer_store_dword v14, v1, s[0:3], s13 offen
s_waitcnt vmcnt(0) expcnt(0)
v_add_i32 v14, vcc, 4, v12
v_addc_u32 v15, vcc, 0, v13, vcc
flat_load_dword v14, v[14:15]
s_waitcnt vmcnt(0) lgkmcnt(0)
buffer_store_dword v14, v1, s[0:3], s13 offen offset:4
s_waitcnt vmcnt(0) expcnt(0)
v_add_i32 v14, vcc, 8, v12
v_addc_u32 v15, vcc, 0, v13, vcc
flat_load_dword v14, v[14:15]
s_waitcnt vmcnt(0) lgkmcnt(0)
buffer_store_dword v14, v1, s[0:3], s13 offen offset:8
s_waitcnt vmcnt(0) expcnt(0)
v_add_i32 v14, vcc, 12, v12
v_addc_u32 v15, vcc, 0, v13, vcc
flat_load_dword v14, v[14:15]
s_waitcnt vmcnt(0) lgkmcnt(0)
buffer_store_dword v14, v1, s[0:3], s13 offen offset:12
s_waitcnt vmcnt(0) expcnt(0)
v_add_i32 v14, vcc, 16, v12
v_addc_u32 v15, vcc, 0, v13, vcc
flat_load_dword v12, v[14:15]
s_waitcnt vmcnt(0) lgkmcnt(0)
buffer_store_dword v12, v1, s[0:3], s13 offen offset:16
s_waitcnt vmcnt(0) expcnt(0)
s_branch BB13_41
BB13_30:
s_cmp_lt_u32 s24, 2
s_cbranch_scc0 BB13_31
flat_load_dword v14, v[12:13]
s_waitcnt vmcnt(0) lgkmcnt(0)
buffer_store_dword v14, v1, s[0:3], s13 offen
s_waitcnt vmcnt(0) expcnt(0)
v_add_i32 v14, vcc, 4, v12
v_addc_u32 v15, vcc, 0, v13, vcc
flat_load_dword v14, v[14:15]
s_waitcnt vmcnt(0) lgkmcnt(0)
buffer_store_dword v14, v1, s[0:3], s13 offen offset:4
s_waitcnt vmcnt(0) expcnt(0)
v_add_i32 v14, vcc, 8, v12
v_addc_u32 v15, vcc, 0, v13, vcc
flat_load_dword v14, v[14:15]
s_waitcnt vmcnt(0) lgkmcnt(0)
buffer_store_dword v14, v1, s[0:3], s13 offen offset:8
s_waitcnt vmcnt(0) expcnt(0)
v_add_i32 v14, vcc, 12, v12
v_addc_u32 v15, vcc, 0, v13, vcc
flat_load_dword v14, v[14:15]
s_waitcnt vmcnt(0) lgkmcnt(0)
buffer_store_dword v14, v1, s[0:3], s13 offen offset:12
s_waitcnt vmcnt(0) expcnt(0)
v_add_i32 v14, vcc, 16, v12
v_addc_u32 v15, vcc, 0, v13, vcc
flat_load_dword v14, v[14:15]
s_waitcnt vmcnt(0) lgkmcnt(0)
buffer_store_dword v14, v1, s[0:3], s13 offen offset:16
s_waitcnt vmcnt(0) expcnt(0)
v_add_i32 v14, vcc, 20, v12
v_addc_u32 v15, vcc, 0, v13, vcc
flat_load_dword v12, v[14:15]
s_waitcnt vmcnt(0) lgkmcnt(0)
buffer_store_dword v12, v1, s[0:3], s13 offen offset:20
s_waitcnt vmcnt(0) expcnt(0)
s_branch BB13_41
BB13_37:
s_cmp_lt_u32 s24, 2
s_cbranch_scc0 BB13_38
flat_load_dword v14, v[12:13]
s_waitcnt vmcnt(0) lgkmcnt(0)
buffer_store_dword v14, v1, s[0:3], s13 offen
s_waitcnt vmcnt(0) expcnt(0)
v_add_i32 v14, vcc, 4, v12
v_addc_u32 v15, vcc, 0, v13, vcc
flat_load_dword v14, v[14:15]
s_waitcnt vmcnt(0) lgkmcnt(0)
buffer_store_dword v14, v1, s[0:3], s13 offen offset:4
s_waitcnt vmcnt(0) expcnt(0)
v_add_i32 v14, vcc, 8, v12
v_addc_u32 v15, vcc, 0, v13, vcc
flat_load_dword v14, v[14:15]
s_waitcnt vmcnt(0) lgkmcnt(0)
buffer_store_dword v14, v1, s[0:3], s13 offen offset:8
s_waitcnt vmcnt(0) expcnt(0)
v_add_i32 v14, vcc, 12, v12
v_addc_u32 v15, vcc, 0, v13, vcc
flat_load_dword v12, v[14:15]
s_waitcnt vmcnt(0) lgkmcnt(0)
buffer_store_dword v12, v1, s[0:3], s13 offen offset:12
s_waitcnt vmcnt(0) expcnt(0)
s_branch BB13_41
BB13_28:
flat_load_dword v14, v[12:13]
s_waitcnt vmcnt(0) lgkmcnt(0)
buffer_store_dword v14, v1, s[0:3], s13 offen
s_waitcnt vmcnt(0) expcnt(0)
v_add_i32 v14, vcc, 4, v12
v_addc_u32 v15, vcc, 0, v13, vcc
flat_load_dword v14, v[14:15]
s_waitcnt vmcnt(0) lgkmcnt(0)
buffer_store_dword v14, v1, s[0:3], s13 offen offset:4
s_waitcnt vmcnt(0) expcnt(0)
v_add_i32 v14, vcc, 8, v12
v_addc_u32 v15, vcc, 0, v13, vcc
flat_load_dword v14, v[14:15]
s_waitcnt vmcnt(0) lgkmcnt(0)
buffer_store_dword v14, v1, s[0:3], s13 offen offset:8
s_waitcnt vmcnt(0) expcnt(0)
v_add_i32 v14, vcc, 12, v12
v_addc_u32 v15, vcc, 0, v13, vcc
flat_load_dword v14, v[14:15]
s_waitcnt vmcnt(0) lgkmcnt(0)
buffer_store_dword v14, v1, s[0:3], s13 offen offset:12
s_waitcnt vmcnt(0) expcnt(0)
v_add_i32 v14, vcc, 16, v12
v_addc_u32 v15, vcc, 0, v13, vcc
flat_load_dword v14, v[14:15]
s_waitcnt vmcnt(0) lgkmcnt(0)
buffer_store_dword v14, v1, s[0:3], s13 offen offset:16
s_waitcnt vmcnt(0) expcnt(0)
v_add_i32 v14, vcc, 20, v12
v_addc_u32 v15, vcc, 0, v13, vcc
flat_load_dword v12, v[14:15]
s_waitcnt vmcnt(0) lgkmcnt(0)
buffer_store_dword v12, v1, s[0:3], s13 offen offset:20
s_waitcnt vmcnt(0) expcnt(0)
s_branch BB13_41
BB13_35:
flat_load_dword v14, v[12:13]
s_waitcnt vmcnt(0) lgkmcnt(0)
buffer_store_dword v14, v1, s[0:3], s13 offen
s_waitcnt vmcnt(0) expcnt(0)
v_add_i32 v14, vcc, 4, v12
v_addc_u32 v15, vcc, 0, v13, vcc
flat_load_dword v14, v[14:15]
s_waitcnt vmcnt(0) lgkmcnt(0)
buffer_store_dword v14, v1, s[0:3], s13 offen offset:4
s_waitcnt vmcnt(0) expcnt(0)
v_add_i32 v14, vcc, 8, v12
v_addc_u32 v15, vcc, 0, v13, vcc
flat_load_dword v14, v[14:15]
s_waitcnt vmcnt(0) lgkmcnt(0)
buffer_store_dword v14, v1, s[0:3], s13 offen offset:8
s_waitcnt vmcnt(0) expcnt(0)
v_add_i32 v14, vcc, 12, v12
v_addc_u32 v15, vcc, 0, v13, vcc
flat_load_dword v14, v[14:15]
s_waitcnt vmcnt(0) lgkmcnt(0)
buffer_store_dword v14, v1, s[0:3], s13 offen offset:12
s_waitcnt vmcnt(0) expcnt(0)
v_add_i32 v14, vcc, 16, v12
v_addc_u32 v15, vcc, 0, v13, vcc
flat_load_dword v12, v[14:15]
s_waitcnt vmcnt(0) lgkmcnt(0)
buffer_store_dword v12, v1, s[0:3], s13 offen offset:16
s_waitcnt vmcnt(0) expcnt(0)
s_branch BB13_41
BB13_31:
flat_load_dword v14, v[12:13]
s_waitcnt vmcnt(0) lgkmcnt(0)
buffer_store_dword v14, v1, s[0:3], s13 offen
s_waitcnt vmcnt(0) expcnt(0)
v_add_i32 v14, vcc, 4, v12
v_addc_u32 v15, vcc, 0, v13, vcc
flat_load_dword v14, v[14:15]
s_waitcnt vmcnt(0) lgkmcnt(0)
buffer_store_dword v14, v1, s[0:3], s13 offen offset:4
s_waitcnt vmcnt(0) expcnt(0)
v_add_i32 v14, vcc, 8, v12
v_addc_u32 v15, vcc, 0, v13, vcc
flat_load_dword v14, v[14:15]
s_waitcnt vmcnt(0) lgkmcnt(0)
buffer_store_dword v14, v1, s[0:3], s13 offen offset:8
s_waitcnt vmcnt(0) expcnt(0)
v_add_i32 v14, vcc, 12, v12
v_addc_u32 v15, vcc, 0, v13, vcc
flat_load_dword v14, v[14:15]
s_waitcnt vmcnt(0) lgkmcnt(0)
buffer_store_dword v14, v1, s[0:3], s13 offen offset:12
s_waitcnt vmcnt(0) expcnt(0)
v_add_i32 v14, vcc, 16, v12
v_addc_u32 v15, vcc, 0, v13, vcc
flat_load_dword v14, v[14:15]
s_waitcnt vmcnt(0) lgkmcnt(0)
buffer_store_dword v14, v1, s[0:3], s13 offen offset:16
s_waitcnt vmcnt(0) expcnt(0)
v_add_i32 v14, vcc, 20, v12
v_addc_u32 v15, vcc, 0, v13, vcc
flat_load_dword v12, v[14:15]
s_waitcnt vmcnt(0) lgkmcnt(0)
buffer_store_dword v12, v1, s[0:3], s13 offen offset:20
s_waitcnt vmcnt(0) expcnt(0)
s_branch BB13_41
BB13_38:
s_mov_b32 s27, 0
v_ashrrev_i32 v13, 31, v8
v_add_i32 v12, vcc, s22, v8
v_mov_b32 v14, s23
v_addc_u32 v13, vcc, v13, v14, vcc
v_mov_b32 v14, 0
v_mov_b32 v15, s27
BB13_39:
flat_load_dword v16, v[12:13]
v_add_i32 v14, vcc, 1, v14
s_waitcnt vmcnt(0) lgkmcnt(0)
buffer_store_dword v16, v15, s[0:3], s13 offen
v_add_i32 v15, vcc, 4, v15
v_add_i32 v12, vcc, 4, v12
v_addc_u32 v13, vcc, 0, v13, vcc
v_cmp_lt_u32_e32 vcc, v14, v6
s_and_b64 vcc, exec, vcc
s_waitcnt vmcnt(0) expcnt(0)
s_cbranch_vccnz BB13_39
BB13_41:
s_cmp_gt_u32 s8, 1
s_cbranch_scc1 BB13_43
buffer_load_dword v13, v1, s[0:3], s13 offen offset:4
s_nop 0
buffer_load_dword v14, v1, s[0:3], s13 offen offset:8
s_nop 0
buffer_load_dword v15, v1, s[0:3], s13 offen offset:12
s_nop 0
buffer_load_dword v16, v1, s[0:3], s13 offen offset:16
s_nop 0
buffer_load_dword v12, v1, s[0:3], s13 offen
s_nop 0
buffer_load_dword v17, v1, s[0:3], s13 offen offset:20
v_lshlrev_b32 v18, 2, v11
s_mov_b32 m0, -1
v_add_i32 v18, vcc, s11, v18
s_waitcnt vmcnt(5)
ds_write_b32 v18, v13 offset:2736
s_waitcnt vmcnt(4)
ds_write_b32 v18, v14 offset:5472
s_waitcnt vmcnt(3)
ds_write_b32 v18, v15 offset:8208
s_waitcnt vmcnt(2)
ds_write_b32 v18, v16 offset:10944
s_waitcnt vmcnt(1)
ds_write_b32 v18, v12
s_waitcnt vmcnt(0)
ds_write_b32 v18, v17 offset:13680
s_waitcnt lgkmcnt(0)
s_branch BB13_47
BB13_43:
s_cmp_lt_u32 s21, 2
s_cbranch_scc0 BB13_44
buffer_load_dword v13, v1, s[0:3], s13 offen offset:4
s_nop 0
buffer_load_dword v14, v1, s[0:3], s13 offen offset:8
s_nop 0
buffer_load_dword v15, v1, s[0:3], s13 offen offset:12
s_nop 0
buffer_load_dword v12, v1, s[0:3], s13 offen
s_nop 0
buffer_load_dword v16, v1, s[0:3], s13 offen offset:16
v_lshlrev_b32 v17, 2, v11
s_mov_b32 m0, -1
v_add_i32 v17, vcc, s11, v17
s_waitcnt vmcnt(4)
ds_write_b32 v17, v13 offset:2736
s_waitcnt vmcnt(3)
ds_write_b32 v17, v14 offset:5472
s_waitcnt vmcnt(2)
ds_write_b32 v17, v15 offset:8208
s_waitcnt vmcnt(1)
ds_write_b32 v17, v12
s_waitcnt vmcnt(0)
ds_write_b32 v17, v16 offset:10944
s_waitcnt lgkmcnt(0)
s_branch BB13_47
BB13_44:
s_mov_b32 s27, 0
v_mov_b32 v12, 0
v_mov_b32 v13, s27
v_mov_b32 v14, v10
BB13_45:
buffer_load_dword v15, v13, s[0:3], s13 offen
s_mov_b32 m0, -1
v_add_i32 v12, vcc, 1, v12
v_add_i32 v13, vcc, 4, v13
s_waitcnt vmcnt(0)
ds_write_b32 v14, v15
v_add_i32 v14, vcc, 0xab0, v14
v_cmp_lt_u32_e32 vcc, v12, v7
s_and_b64 vcc, exec, vcc
s_waitcnt lgkmcnt(0)
s_cbranch_vccnz BB13_45
buffer_load_dword v12, v1, s[0:3], s13 offen
s_waitcnt vmcnt(0)
BB13_47:
v_and_b32 v13, v12, v4
v_and_b32 v12, v12, v5
v_lshrrev_b32 v13, s25, v13
v_lshrrev_b32 v12, s26, v12
v_or_b32 v12, v12, v13
v_lshlrev_b32 v12, 2, v12
v_add_i32 v12, vcc, s20, v12
s_mov_b32 m0, -1
ds_wrxchg_rtn_b32 v12, v12, v11
v_lshlrev_b32 v13, 1, v11
v_add_i32 v13, vcc, s19, v13
s_waitcnt lgkmcnt(0)
v_add_i32 v11, vcc, 0x100, v11
v_add_i32 v8, vcc, v9, v8
v_add_i32 v10, vcc, 0x400, v10
ds_write_b16 v13, v12
v_cmp_ge_u32_e32 vcc, v11, v2
s_or_b64 s[28:29], vcc, s[28:29]
s_waitcnt lgkmcnt(0)
s_andn2_b64 exec, exec, s[28:29]
s_cbranch_execnz BB13_25
s_or_b64 exec, exec, s[28:29]
BB13_49:
s_or_b64 exec, exec, s[4:5]
s_barrier
v_mov_b32 v2, 0x2ac
v_cmp_gt_u32_e32 vcc, v2, v0
s_and_saveexec_b64 s[4:5], vcc
s_xor_b64 s[4:5], exec, s[4:5]
s_cbranch_execz BB13_54
s_mov_b64 s[8:9], 0
v_mov_b32 v2, v0
BB13_56:
v_lshlrev_b32 v3, 1, v2
v_add_i32 v3, vcc, s19, v3
s_mov_b32 m0, -1
ds_read_u16 v3, v3
v_mov_b32 v4, 0x2ac
s_waitcnt lgkmcnt(0)
v_cmp_gt_u32_e32 vcc, v4, v3
s_and_saveexec_b64 s[20:21], vcc
s_xor_b64 s[20:21], exec, s[20:21]
s_cbranch_execz BB13_62
s_mov_b64 s[22:23], 0
BB13_58:
v_mov_b32 v4, 1
s_mov_b32 m0, -1
v_mov_b32 v5, s18
ds_add_rtn_u32 v4, v5, v4
v_mov_b32 v5, 0x31a
s_waitcnt lgkmcnt(0)
v_cmp_gt_u32_e32 vcc, v5, v4
s_and_saveexec_b64 s[24:25], vcc
s_xor_b64 s[24:25], exec, s[24:25]
s_cbranch_execz BB13_60
v_lshlrev_b32 v4, 1, v4
v_add_i32 v5, vcc, s16, v4
s_mov_b32 m0, -1
v_add_i32 v4, vcc, s17, v4
ds_write_b16 v5, v2
ds_write_b16 v4, v3
s_waitcnt lgkmcnt(0)
v_lshlrev_b32 v3, 1, v3
v_add_i32 v3, vcc, s19, v3
ds_read_u16 v3, v3
v_mov_b32 v4, 0x2ab
s_waitcnt lgkmcnt(0)
v_cmp_lt_u32_e32 vcc, v4, v3
s_or_b64 s[22:23], vcc, s[22:23]
BB13_60:
s_or_b64 exec, exec, s[24:25]
s_or_b64 s[22:23], s[24:25], s[22:23]
s_andn2_b64 exec, exec, s[22:23]
s_cbranch_execnz BB13_58
s_or_b64 exec, exec, s[22:23]
BB13_62:
s_or_b64 exec, exec, s[20:21]
v_add_i32 v2, vcc, 0x100, v2
v_mov_b32 v3, 0x2ab
v_cmp_lt_u32_e32 vcc, v3, v2
s_or_b64 s[8:9], vcc, s[8:9]
s_andn2_b64 exec, exec, s[8:9]
s_cbranch_execnz BB13_56
s_or_b64 exec, exec, s[8:9]
BB13_54:
s_or_b64 exec, exec, s[4:5]
s_barrier
s_mov_b32 m0, -1
v_mov_b32 v2, s18
ds_read_b32 v2, v2
s_waitcnt lgkmcnt(0)
v_min_u32 v2, 0x31a, v2
v_cmp_eq_i32_e32 vcc, 0, v2
s_and_b64 vcc, exec, vcc
s_cbranch_vccnz BB13_95
s_lshl_b32 s5, s12, 20
v_not_b32 v3, v0
s_or_b32 s4, s10, 1
s_mov_b32 s8, 0x55555555
s_mov_b32 s9, 0xaaaaaaab
s_or_b32 s12, s10, 7
BB13_52:
v_mov_b32 v7, 0x2ac
v_cmp_lt_u32_e32 vcc, v0, v2
s_and_saveexec_b64 s[18:19], vcc
s_xor_b64 s[18:19], exec, s[18:19]
s_cbranch_execz BB13_64
v_add_i32 v4, vcc, v2, v3
v_lshlrev_b32 v4, 1, v4
v_add_i32 v5, vcc, s16, v4
s_mov_b32 m0, -1
v_add_i32 v4, vcc, s17, v4
ds_read_u16 v7, v5
ds_read_u16 v4, v4
s_waitcnt lgkmcnt(0)
v_lshlrev_b32 v5, 2, v7
v_lshlrev_b32 v6, 2, v4
v_add_i32 v5, vcc, s11, v5
v_add_i32 v6, vcc, s11, v6
BB13_64:
s_or_b64 exec, exec, s[18:19]
v_mov_b32 v8, 0x2ac
v_cmp_gt_u32_e32 vcc, v8, v7
s_and_saveexec_b64 s[18:19], vcc
s_xor_b64 s[18:19], exec, s[18:19]
s_cbranch_execz BB13_94
s_mov_b32 m0, -1
ds_read_b32 v8, v5
ds_read_b32 v9, v5 offset:2736
s_mov_b32 m0, -1
s_cmp_gt_u32 s10, 7
s_waitcnt lgkmcnt(0)
s_cbranch_scc1 BB13_73
ds_read_b32 v11, v5 offset:5472
s_mov_b32 m0, -1
s_cmp_eq_i32 s10, 7
s_waitcnt lgkmcnt(0)
s_cbranch_scc0 BB13_67
ds_read_b32 v10, v6
ds_read_b32 v12, v6 offset:2736
ds_read_b32 v13, v6 offset:5472
s_waitcnt lgkmcnt(0)
v_xor_b32 v8, v10, v8
v_xor_b32 v9, v12, v9
v_xor_b32 v10, v13, v11
v_lshlrev_b32 v11, 24, v9
v_lshrrev_b32 v12, 8, v8
v_or_b32 v11, v11, v12
buffer_store_dword v11, v1, s[0:3], s13 offen
v_lshlrev_b32 v10, 24, v10
s_waitcnt vmcnt(0) expcnt(0)
v_lshrrev_b32 v11, 8, v9
v_or_b32 v10, v10, v11
v_mov_b32 v13, 0
buffer_store_dword v10, v1, s[0:3], s13 offen offset:4
s_waitcnt vmcnt(0) expcnt(0)
s_branch BB13_85
BB13_73:
ds_read_b32 v10, v6
ds_read_b32 v11, v6 offset:2736
v_mov_b32 v15, 0
s_waitcnt lgkmcnt(0)
v_xor_b32 v8, v10, v8
v_xor_b32 v9, v11, v9
BB13_74:
s_and_b32 s20, 1, s10
v_cmp_eq_i32 s[20:21], 1, s20
s_and_b64 vcc, exec, s[20:21]
s_cbranch_vccnz BB13_76
v_lshrrev_b32 v8, 24, v8
v_lshlrev_b32 v13, 8, v9
v_or_b32 v8, v13, v8
buffer_store_dword v9, v1, s[0:3], s13 offen
s_nop 0
buffer_store_dword v14, v1, s[0:3], s13 offen offset:4
s_nop 0
buffer_store_dword v12, v1, s[0:3], s13 offen offset:8
s_nop 0
buffer_store_dword v11, v1, s[0:3], s13 offen offset:12
s_nop 0
buffer_store_dword v10, v1, s[0:3], s13 offen offset:16
v_mov_b32 v13, -1
s_waitcnt vmcnt(0) expcnt(0)
s_branch BB13_85
BB13_76:
v_lshlrev_b32 v13, 24, v9
v_lshrrev_b32 v16, 8, v8
v_or_b32 v13, v13, v16
buffer_store_dword v13, v1, s[0:3], s13 offen
s_cmp_gt_u32 s10, 7
s_waitcnt vmcnt(0) expcnt(0)
s_cbranch_scc1 BB13_78
v_lshlrev_b32 v13, 24, v14
v_lshrrev_b32 v16, 8, v9
v_cmp_ne_i32_e32 vcc, 0, v15
v_or_b32 v13, v13, v16
buffer_store_dword v13, v1, s[0:3], s13 offen offset:4
s_and_b64 vcc, exec, vcc
s_waitcnt vmcnt(0) expcnt(0)
s_cbranch_vccnz BB13_79
s_branch BB13_80
BB13_67:
ds_read_b32 v12, v5 offset:8208
s_mov_b32 m0, -1
s_cmp_lt_u32 s10, 5
s_waitcnt lgkmcnt(0)
s_cbranch_scc0 BB13_68
ds_read_b32 v13, v5 offset:10944
s_cmp_gt_u32 s10, 2
s_waitcnt lgkmcnt(0)
s_cbranch_scc1 BB13_71
s_mov_b32 m0, -1
ds_read_b32 v10, v5 offset:13680
s_waitcnt lgkmcnt(0)
BB13_71:
s_mov_b32 m0, -1
ds_read_b32 v14, v6
ds_read_b32 v15, v6 offset:2736
ds_read_b32 v17, v6 offset:8208
ds_read_b32 v16, v6 offset:5472
ds_read_b32 v18, v6 offset:10944
s_waitcnt lgkmcnt(0)
v_xor_b32 v8, v14, v8
v_xor_b32 v9, v15, v9
v_xor_b32 v12, v17, v12
v_xor_b32 v14, v16, v11
v_xor_b32 v11, v18, v13
v_mov_b32 v15, -1
s_cmp_lt_u32 s10, 3
s_cbranch_scc0 BB13_74
s_mov_b32 m0, -1
ds_read_b32 v13, v6 offset:13680
s_waitcnt lgkmcnt(0)
v_xor_b32 v10, v13, v10
s_branch BB13_74
BB13_78:
v_cmp_ne_i32_e32 vcc, 0, v15
v_cndmask_b32 v15, 0, 1, vcc
v_cmp_ne_i32_e32 vcc, 1, v15
v_mov_b32 v13, 0
s_and_b64 vcc, exec, vcc
s_cbranch_vccnz BB13_85
BB13_79:
v_lshlrev_b32 v13, 24, v12
v_lshrrev_b32 v14, 8, v14
v_or_b32 v13, v13, v14
buffer_store_dword v13, v1, s[0:3], s13 offen offset:8
s_waitcnt vmcnt(0) expcnt(0)
BB13_80:
v_mov_b32 v13, 0
s_cmp_gt_u32 s10, 5
s_cbranch_scc1 BB13_85
v_lshlrev_b32 v14, 24, v11
v_lshrrev_b32 v12, 8, v12
v_or_b32 v12, v14, v12
buffer_store_dword v12, v1, s[0:3], s13 offen offset:12
s_cmp_gt_u32 s10, 3
s_waitcnt vmcnt(0) expcnt(0)
s_cbranch_scc1 BB13_85
v_lshlrev_b32 v12, 24, v10
v_lshrrev_b32 v11, 8, v11
v_or_b32 v11, v12, v11
v_mov_b32 v13, 0
buffer_store_dword v11, v1, s[0:3], s13 offen offset:16
s_cmp_gt_u32 s10, 1
s_waitcnt vmcnt(0) expcnt(0)
s_cbranch_scc1 BB13_85
v_lshrrev_b32 v10, 8, v10
buffer_store_dword v10, v1, s[0:3], s13 offen offset:20
s_waitcnt vmcnt(0) expcnt(0)
BB13_85:
v_mov_b32 v10, 6
s_cmp_eq_i32 s4, 1
s_cbranch_scc1 BB13_90
v_mov_b32 v10, 5
s_cmp_eq_i32 s4, 3
s_cbranch_scc1 BB13_90
v_mov_b32 v10, 4
s_cmp_eq_i32 s4, 5
s_cbranch_scc1 BB13_90
v_mov_b32 v10, 3
s_cmp_eq_i32 s10, 6
s_cbranch_scc1 BB13_90
v_cmp_eq_i32 s[20:21], 7, s10
v_cndmask_b32 v10, 1, 2, s[20:21]
BB13_90:
v_lshlrev_b32 v11, 10, v4
v_and_b32 v7, 0x3ff, v7
v_lshlrev_b32 v10, 2, v10
v_and_b32 v11, 0xffc00, v11
v_or_b32 v7, s5, v7
v_or_b32 v7, v11, v7
v_add_i32 v10, vcc, 0, v10
buffer_store_dword v7, v10, s[0:3], s13 offen
s_waitcnt vmcnt(0) expcnt(0)
v_or_b32 v7, v9, v8
v_cmp_ne_i32_e32 vcc, 0, v7
s_and_saveexec_b64 s[20:21], vcc
s_xor_b64 s[20:21], exec, s[20:21]
s_cbranch_execz BB13_93
v_cmp_ne_i32_e32 vcc, 0, v13
v_cndmask_b32 v7, 0, 1, vcc
v_cmp_ne_i32_e32 vcc, 1, v7
s_and_b64 vcc, exec, vcc
s_cbranch_vccnz BB13_96
v_and_b32 v7, 0xfff, v8
s_branch BB13_97
BB13_96:
v_lshrrev_b32 v7, 8, v8
v_lshrrev_b32 v8, 24, v8
v_and_b32 v7, 0xf0f, v7
v_and_b32 v8, 0xf0, v8
v_or_b32 v7, v7, v8
BB13_97:
v_mul_lo_i32 v8, s8, v7
v_lshrrev_b32 v9, 1, v7
v_lshrrev_b32 v10, 3, v7
v_add_i32 v8, vcc, v8, v9
v_sub_i32 v8, vcc, v8, v10
v_lshrrev_b32 v9, 30, v8
v_subrev_i32 v8, vcc, v9, v7
v_mul_lo_i32 v8, s9, v8
v_mul_u32_u24 v12, 10, v9
v_ashrrev_i32 v9, 31, v8
v_lshlrev_b64 v[8:9], 2, v[8:9]
v_add_i32 v10, vcc, s6, v8
v_mov_b32 v8, s7
v_addc_u32 v11, vcc, v9, v8, vcc
v_and_b32 v8, 30, v12
v_lshlrev_b32 v9, v8, 1
flat_atomic_add v9, v[10:11], v9 glc
s_waitcnt vmcnt(0) lgkmcnt(0)
v_bfe_u32 v8, v9, v8, 10
v_mov_b32 v9, 0x2ac
v_cmp_gt_u32_e32 vcc, v9, v8
s_and_saveexec_b64 s[22:23], vcc
s_xor_b64 s[22:23], exec, s[22:23]
s_cbranch_execz BB13_107
v_mov_b32 v9, 32
s_cmp_lt_u32 s10, 6
s_cbranch_scc1 BB13_100
v_cmp_eq_i32 s[24:25], 7, s12
v_cndmask_b32 v9, 8, 16, s[24:25]
BB13_100:
v_mov_b32 v10, 0x2ac
v_mad_i32_i24 v7, v10, v7, v8
v_mul_lo_i32 v7, v9, v7
v_mov_b32 v8, s15
v_ashrrev_i32 v9, 31, v7
v_add_i32 v7, vcc, s14, v7
v_addc_u32 v8, vcc, v9, v8, vcc
v_cmp_ne_i64_e32 vcc, 0, v[7:8]
s_and_saveexec_b64 s[24:25], vcc
s_xor_b64 s[24:25], exec, s[24:25]
s_cbranch_execz BB13_106
s_cmp_lt_u32 s10, 8
s_cbranch_scc1 BB13_103
buffer_load_dword v9, v1, s[0:3], s13 offen
s_nop 0
buffer_load_dword v10, v1, s[0:3], s13 offen offset:4
s_waitcnt vmcnt(0)
flat_store_dwordx2 v[7:8], v[9:10]
s_waitcnt vmcnt(0) lgkmcnt(0)
s_branch BB13_106
BB13_68:
ds_read_b32 v14, v6 offset:5472
ds_read_b32 v10, v6
ds_read_b32 v13, v6 offset:2736
ds_read_b32 v15, v6 offset:8208
s_waitcnt lgkmcnt(0)
v_xor_b32 v14, v14, v11
v_xor_b32 v8, v10, v8
v_xor_b32 v9, v13, v9
v_xor_b32 v12, v15, v12
v_mov_b32 v15, -1
s_branch BB13_74
BB13_103:
s_cmp_lt_u32 s10, 6
s_cbranch_scc1 BB13_105
buffer_load_dword v9, v1, s[0:3], s13 offen
s_nop 0
buffer_load_dword v10, v1, s[0:3], s13 offen offset:4
s_nop 0
buffer_load_dword v11, v1, s[0:3], s13 offen offset:8
s_nop 0
buffer_load_dword v12, v1, s[0:3], s13 offen offset:12
s_waitcnt vmcnt(0)
flat_store_dwordx4 v[7:8], v[9:12]
s_waitcnt vmcnt(0) lgkmcnt(0)
s_branch BB13_106
BB13_105:
buffer_load_dword v9, v1, s[0:3], s13 offen
s_nop 0
buffer_load_dword v10, v1, s[0:3], s13 offen offset:4
s_nop 0
buffer_load_dword v11, v1, s[0:3], s13 offen offset:8
s_nop 0
buffer_load_dword v12, v1, s[0:3], s13 offen offset:12
s_nop 0
buffer_load_dword v13, v1, s[0:3], s13 offen offset:16
s_nop 0
buffer_load_dword v14, v1, s[0:3], s13 offen offset:20
s_nop 0
buffer_load_dword v15, v1, s[0:3], s13 offen offset:24
s_nop 0
buffer_load_dword v16, v1, s[0:3], s13 offen offset:28
s_waitcnt vmcnt(4)
flat_store_dwordx4 v[7:8], v[9:12]
s_waitcnt vmcnt(0) lgkmcnt(0)
v_add_i32 v9, vcc, 16, v7
v_addc_u32 v10, vcc, 0, v8, vcc
flat_store_dwordx4 v[9:10], v[13:16]
s_waitcnt vmcnt(0) lgkmcnt(0)
BB13_106:
s_or_b64 exec, exec, s[24:25]
BB13_107:
s_or_b64 exec, exec, s[22:23]
BB13_93:
s_or_b64 exec, exec, s[20:21]
BB13_94:
s_or_b64 exec, exec, s[18:19]
v_min_u32 v7, 0x100, v2
v_subrev_i32 v2, vcc, v7, v2
v_cmp_ne_i32_e32 vcc, 0, v2
s_and_b64 vcc, exec, vcc
s_cbranch_vccnz BB13_52
BB13_95:
s_endpgm
.section .AMDGPU.csdata
.section .AMDGPU.config
.text
.globl kernel_round1
.p2align 8
.type kernel_round1,@function
.amdgpu_hsa_kernel kernel_round1
kernel_round1:
.amd_kernel_code_t
max_scratch_backing_memory_byte_size = 0
.dx10clamp
enable_ordered_append_gds = 0
private_element_size = 1
workitem_private_segment_byte_size = 0
workgroup_group_segment_byte_size = 21988
gds_segment_byte_size = 0
workgroup_fbarrier_count = 0
wavefront_sgpr_count = 30
workitem_vgpr_count = 21
group_segment_alignment = 4
private_segment_alignment = 4
.end_amd_kernel_code_t
s_cmp_gt_u32 s12, 0xfff
s_cbranch_scc1 BB14_51
v_mov_b32 v1, 0x100
v_cmp_gt_u32_e32 vcc, v1, v0
s_and_saveexec_b64 s[0:1], vcc
s_xor_b64 s[0:1], exec, s[0:1]
s_cbranch_execz BB14_10
v_add_i32 v1, vcc, 0xffffff00, v0
v_lshlrev_b32 v2, 2, v0
s_mov_b64 s[2:3], 0
s_mov_b32 m0, -1
BB14_12:
v_mov_b32 v3, 0x2ac
ds_write_b32 v2, v3
v_add_i32 v1, vcc, 0x100, v1
v_add_i32 v2, vcc, 0x400, v2
s_waitcnt lgkmcnt(0)
v_mov_b32 v3, 0xffffff00
v_cmp_gt_u32_e32 vcc, v3, v1
s_or_b64 s[2:3], vcc, s[2:3]
s_andn2_b64 exec, exec, s[2:3]
s_cbranch_execnz BB14_12
s_or_b64 exec, exec, s[2:3]
BB14_10:
s_or_b64 exec, exec, s[0:1]
s_load_dwordx2 s[6:7], s[8:9], 0x38
s_load_dwordx2 s[2:3], s[8:9], 0x40
s_load_dwordx2 s[10:11], s[8:9], 0x48
s_load_dwordx2 s[4:5], s[8:9], 0x50
v_mov_b32 v1, 0x2ac
v_cmp_gt_u32_e32 vcc, v1, v0
v_mov_b32 v1, 0
s_waitcnt lgkmcnt(0)
s_and_saveexec_b64 s[0:1], vcc
s_xor_b64 s[0:1], exec, s[0:1]
s_cbranch_execz BB14_19
v_sub_i32 v1, vcc, 0x2ab, v0
v_lshrrev_b32 v5, 8, v1
v_add_i32 v3, vcc, 1, v5
v_cmp_gt_u32_e32 vcc, 64, v3
v_cndmask_b32 v4, 0, -1, vcc
v_mov_b32 v1, v0
v_cmp_lt_u32_e32 vcc, 63, v3
s_and_saveexec_b64 s[8:9], vcc
s_xor_b64 s[8:9], exec, s[8:9]
s_cbranch_execz BB14_6
v_and_b32 v2, 63, v3
v_subrev_i32 v3, vcc, v2, v3
v_mov_b32 v4, -1
v_mov_b32 v1, v0
v_cmp_ne_i32_e32 vcc, 0, v3
s_and_saveexec_b64 s[14:15], vcc
s_xor_b64 s[14:15], exec, s[14:15]
s_cbranch_execz BB14_5
v_lshlrev_b32 v1, 8, v5
v_add_i32 v1, vcc, v1, v0
v_add_i32 v1, vcc, 0x100, v1
v_lshlrev_b32 v4, 8, v2
v_subrev_i32 v1, vcc, v4, v1
s_mov_b64 s[16:17], 0
v_mov_b32 v4, 0
s_mov_b32 m0, -1
BB14_8:
v_or_b32 v5, v4, v0
v_mov_b32 v6, 0x2ac
v_lshlrev_b32 v5, 1, v5
v_add_i32 v3, vcc, 0xffffffc0, v3
v_add_i32 v4, vcc, 0x4000, v4
v_cmp_eq_i32_e32 vcc, 0, v3
ds_write_b16 v5, v6 offset:1024
ds_write_b16 v5, v6 offset:1536
ds_write_b16 v5, v6 offset:2048
ds_write_b16 v5, v6 offset:2560
ds_write_b16 v5, v6 offset:3072
ds_write_b16 v5, v6 offset:3584
ds_write_b16 v5, v6 offset:4096
ds_write_b16 v5, v6 offset:4608
ds_write_b16 v5, v6 offset:5120
ds_write_b16 v5, v6 offset:5632
ds_write_b16 v5, v6 offset:6144
ds_write_b16 v5, v6 offset:6656
ds_write_b16 v5, v6 offset:7168
ds_write_b16 v5, v6 offset:7680
ds_write_b16 v5, v6 offset:8192
ds_write_b16 v5, v6 offset:8704
ds_write_b16 v5, v6 offset:9216
ds_write_b16 v5, v6 offset:9728
ds_write_b16 v5, v6 offset:10240
ds_write_b16 v5, v6 offset:10752
ds_write_b16 v5, v6 offset:11264
ds_write_b16 v5, v6 offset:11776
ds_write_b16 v5, v6 offset:12288
ds_write_b16 v5, v6 offset:12800
ds_write_b16 v5, v6 offset:13312
ds_write_b16 v5, v6 offset:13824
ds_write_b16 v5, v6 offset:14336
ds_write_b16 v5, v6 offset:14848
ds_write_b16 v5, v6 offset:15360
ds_write_b16 v5, v6 offset:15872
ds_write_b16 v5, v6 offset:16384
ds_write_b16 v5, v6 offset:16896
ds_write_b16 v5, v6 offset:17408
ds_write_b16 v5, v6 offset:17920
ds_write_b16 v5, v6 offset:18432
ds_write_b16 v5, v6 offset:18944
ds_write_b16 v5, v6 offset:19456
ds_write_b16 v5, v6 offset:19968
ds_write_b16 v5, v6 offset:20480
ds_write_b16 v5, v6 offset:20992
ds_write_b16 v5, v6 offset:21504
ds_write_b16 v5, v6 offset:22016
ds_write_b16 v5, v6 offset:22528
ds_write_b16 v5, v6 offset:23040
ds_write_b16 v5, v6 offset:23552
ds_write_b16 v5, v6 offset:24064
ds_write_b16 v5, v6 offset:24576
ds_write_b16 v5, v6 offset:25088
ds_write_b16 v5, v6 offset:25600
ds_write_b16 v5, v6 offset:26112
ds_write_b16 v5, v6 offset:26624
ds_write_b16 v5, v6 offset:27136
ds_write_b16 v5, v6 offset:27648
ds_write_b16 v5, v6 offset:28160
ds_write_b16 v5, v6 offset:28672
ds_write_b16 v5, v6 offset:29184
ds_write_b16 v5, v6 offset:29696
ds_write_b16 v5, v6 offset:30208
ds_write_b16 v5, v6 offset:30720
ds_write_b16 v5, v6 offset:31232
ds_write_b16 v5, v6 offset:31744
ds_write_b16 v5, v6 offset:32256
ds_write_b16 v5, v6 offset:32768
ds_write_b16 v5, v6 offset:33280
s_or_b64 s[16:17], vcc, s[16:17]
s_waitcnt lgkmcnt(0)
s_andn2_b64 exec, exec, s[16:17]
s_cbranch_execnz BB14_8
s_or_b64 exec, exec, s[16:17]
v_cmp_ne_i32_e32 vcc, 0, v2
v_cndmask_b32 v4, 0, -1, vcc
BB14_5:
s_or_b64 exec, exec, s[14:15]
BB14_6:
s_or_b64 exec, exec, s[8:9]
v_cmp_ne_i32_e32 vcc, 0, v4
s_and_saveexec_b64 s[8:9], vcc
s_xor_b64 s[8:9], exec, s[8:9]
s_cbranch_execz BB14_16
v_lshlrev_b32 v2, 1, v1
v_add_i32 v2, vcc, 0x400, v2
s_mov_b64 s[14:15], 0
s_mov_b32 m0, -1
BB14_14:
v_mov_b32 v3, 0x2ac
ds_write_b16 v2, v3
v_add_i32 v1, vcc, 0x100, v1
v_add_i32 v2, vcc, 0x200, v2
s_waitcnt lgkmcnt(0)
v_mov_b32 v3, 0x2ab
v_cmp_lt_u32_e32 vcc, v3, v1
s_or_b64 s[14:15], vcc, s[14:15]
s_andn2_b64 exec, exec, s[14:15]
s_cbranch_execnz BB14_14
s_or_b64 exec, exec, s[14:15]
BB14_16:
s_or_b64 exec, exec, s[8:9]
v_mov_b32 v1, 0
v_cmp_eq_i32_e32 vcc, 0, v0
s_and_saveexec_b64 s[8:9], vcc
s_xor_b64 s[8:9], exec, s[8:9]
s_cbranch_execz BB14_18
s_mul_i32 s13, s12, 0x55555555
s_lshr_b32 s14, s12, 1
s_add_i32 s13, s13, s14
s_lshr_b32 s14, s12, 3
s_sub_i32 s13, s13, s14
s_lshr_b32 s13, s13, 30
s_sub_i32 s14, s12, s13
s_mul_i32 s14, s14, 0xaaaaaaab
s_ashr_i32 s15, s14, 31
s_lshl_b64 s[14:15], s[14:15], 2
s_add_u32 s10, s10, s14
s_addc_u32 s11, s11, s15
v_mov_b32 v2, s11
v_mov_b32 v1, s10
flat_load_dword v1, v[1:2]
v_mul_u32_u24 v3, 10, s13
v_and_b32 v3, 30, v3
v_mov_b32 v2, 0
s_mov_b32 m0, -1
s_waitcnt vmcnt(0) lgkmcnt(0)
v_bfe_u32 v1, v1, v3, 10
v_min_u32 v1, 0x2ac, v1
ds_write_b32 v2, v1 offset:2392
s_waitcnt lgkmcnt(0)
BB14_18:
s_or_b64 exec, exec, s[8:9]
BB14_19:
s_or_b64 exec, exec, s[0:1]
s_barrier
v_cmp_ne_i32_e32 vcc, 0, v0
s_and_saveexec_b64 s[0:1], vcc
s_xor_b64 s[0:1], exec, s[0:1]
v_mov_b32 v1, 0
s_mov_b32 m0, -1
ds_read_b32 v1, v1 offset:2392
s_waitcnt lgkmcnt(0)
BB14_21:
s_or_b64 exec, exec, s[0:1]
s_barrier
v_cmp_eq_i32_e32 vcc, 0, v0
s_and_saveexec_b64 s[0:1], vcc
s_xor_b64 s[0:1], exec, s[0:1]
v_mov_b32 v2, 0
s_mov_b32 m0, -1
ds_write_b32 v2, v2 offset:2392
s_waitcnt lgkmcnt(0)
BB14_23:
s_or_b64 exec, exec, s[0:1]
s_barrier
v_cmp_lt_u32_e32 vcc, v0, v1
s_and_saveexec_b64 s[8:9], vcc
s_xor_b64 s[8:9], exec, s[8:9]
s_cbranch_execz BB14_27
v_lshlrev_b32 v3, 2, v0
v_lshlrev_b32 v2, 1, v0
s_movk_i32 s10, 0x400
s_mul_i32 s0, s12, 0x5580
v_lshlrev_b32 v4, 5, v0
v_add_i32 v2, vcc, s10, v2
v_add_i32 v3, vcc, 0x95c, v3
v_add_i32 v4, vcc, s0, v4
s_mov_b64 s[14:15], 0
v_mov_b32 v5, v0
s_mov_b32 m0, -1
BB14_25:
v_ashrrev_i32 v7, 31, v4
v_add_i32 v6, vcc, s6, v4
v_mov_b32 v8, s7
v_addc_u32 v7, vcc, v7, v8, vcc
v_add_i32 v8, vcc, 4, v6
v_addc_u32 v9, vcc, 0, v7, vcc
flat_load_dword v11, v[8:9]
v_add_i32 v8, vcc, 8, v6
v_addc_u32 v9, vcc, 0, v7, vcc
flat_load_dword v12, v[8:9]
v_add_i32 v8, vcc, 12, v6
v_addc_u32 v9, vcc, 0, v7, vcc
flat_load_dword v13, v[8:9]
v_add_i32 v8, vcc, 16, v6
v_addc_u32 v9, vcc, 0, v7, vcc
flat_load_dword v14, v[8:9]
v_add_i32 v8, vcc, 20, v6
flat_load_dword v10, v[6:7]
v_addc_u32 v9, vcc, 0, v7, vcc
flat_load_dword v6, v[8:9]
v_add_i32 v4, vcc, 0x2000, v4
s_waitcnt vmcnt(5) lgkmcnt(0)
ds_write_b32 v3, v11 offset:2736
s_waitcnt vmcnt(4)
ds_write_b32 v3, v12 offset:5472
s_waitcnt vmcnt(3)
ds_write_b32 v3, v13 offset:8208
s_waitcnt vmcnt(2)
ds_write_b32 v3, v14 offset:10944
s_waitcnt vmcnt(1)
v_bfe_u32 v7, v10, 12, 4
v_and_b32 v8, 0xf0, v10
v_or_b32 v7, v8, v7
ds_write_b32 v3, v10
s_waitcnt vmcnt(0)
ds_write_b32 v3, v6 offset:13680
v_lshlrev_b32 v7, 2, v7
s_waitcnt lgkmcnt(0)
ds_wrxchg_rtn_b32 v6, v7, v5
s_waitcnt lgkmcnt(0)
v_add_i32 v5, vcc, 0x100, v5
v_add_i32 v3, vcc, s10, v3
v_cmp_ge_u32 s[0:1], v5, v1
ds_write_b16 v2, v6
v_add_i32 v2, vcc, 0x200, v2
s_or_b64 s[14:15], s[0:1], s[14:15]
s_waitcnt lgkmcnt(0)
s_andn2_b64 exec, exec, s[14:15]
s_cbranch_execnz BB14_25
s_or_b64 exec, exec, s[14:15]
BB14_27:
s_or_b64 exec, exec, s[8:9]
s_barrier
v_mov_b32 v1, 0x2ac
v_cmp_gt_u32_e32 vcc, v1, v0
s_and_saveexec_b64 s[0:1], vcc
s_xor_b64 s[0:1], exec, s[0:1]
s_cbranch_execz BB14_32
s_mov_b64 s[6:7], 0
v_mov_b32 v1, v0
BB14_34:
v_lshlrev_b32 v2, 1, v1
s_mov_b32 m0, -1
ds_read_u16 v2, v2 offset:1024
v_mov_b32 v3, 0x2ac
s_waitcnt lgkmcnt(0)
v_cmp_gt_u32_e32 vcc, v3, v2
s_and_saveexec_b64 s[8:9], vcc
s_xor_b64 s[8:9], exec, s[8:9]
s_cbranch_execz BB14_40
s_mov_b64 s[10:11], 0
BB14_36:
v_mov_b32 v3, 1
v_mov_b32 v4, 0
s_mov_b32 m0, -1
ds_add_rtn_u32 v3, v4, v3 offset:2392
v_mov_b32 v4, 0x31a
s_waitcnt lgkmcnt(0)
v_cmp_gt_u32_e32 vcc, v4, v3
s_and_saveexec_b64 s[14:15], vcc
s_xor_b64 s[14:15], exec, s[14:15]
v_lshlrev_b32 v3, 1, v3
s_mov_b32 m0, -1
ds_write_b16 v3, v2 offset:18812
s_waitcnt lgkmcnt(0)
v_lshlrev_b32 v2, 1, v2
ds_read_u16 v2, v2 offset:1024
ds_write_b16 v3, v1 offset:20400
v_mov_b32 v3, 0x2ab
s_waitcnt lgkmcnt(0)
v_cmp_lt_u32_e32 vcc, v3, v2
s_or_b64 s[10:11], vcc, s[10:11]
BB14_38:
s_or_b64 exec, exec, s[14:15]
s_or_b64 s[10:11], s[14:15], s[10:11]
s_andn2_b64 exec, exec, s[10:11]
s_cbranch_execnz BB14_36
s_or_b64 exec, exec, s[10:11]
BB14_40:
s_or_b64 exec, exec, s[8:9]
v_add_i32 v1, vcc, 0x100, v1
v_mov_b32 v2, 0x2ab
v_cmp_lt_u32_e32 vcc, v2, v1
s_or_b64 s[6:7], vcc, s[6:7]
s_andn2_b64 exec, exec, s[6:7]
s_cbranch_execnz BB14_34
s_or_b64 exec, exec, s[6:7]
BB14_32:
s_or_b64 exec, exec, s[0:1]
s_barrier
v_mov_b32 v1, 0
s_mov_b32 m0, -1
ds_read_b32 v1, v1 offset:2392
s_mov_b32 s16, 0
s_waitcnt lgkmcnt(0)
v_min_u32 v1, 0x31a, v1
v_cmp_eq_i32_e32 vcc, 0, v1
s_and_b64 vcc, exec, vcc
s_cbranch_vccnz BB14_51
s_mov_b32 s17, s16
s_mov_b32 s18, s16
s_mov_b32 s19, s16
s_mov_b32 s20, s16
s_mov_b32 s21, s16
s_mov_b32 s22, s16
s_mov_b32 s23, s16
v_mov_b32 v3, s16
v_mov_b32 v4, s17
v_mov_b32 v5, s18
v_not_b32 v2, v0
v_mov_b32 v6, s19
v_mov_b32 v7, s20
v_mov_b32 v8, s21
v_mov_b32 v9, s22
v_mov_b32 v10, s23
s_movk_i32 s0, 0x95c
s_lshl_b32 s1, s12, 20
s_mov_b32 s6, 0x55555555
s_mov_b32 s7, 0xaaaaaaab
BB14_30:
v_mov_b32 v6, 0x2ac
v_cmp_lt_u32_e32 vcc, v0, v1
s_and_saveexec_b64 s[8:9], vcc
s_xor_b64 s[8:9], exec, s[8:9]
v_add_i32 v3, vcc, v1, v2
v_lshlrev_b32 v3, 1, v3
s_mov_b32 m0, -1
ds_read_u16 v6, v3 offset:20400
ds_read_u16 v3, v3 offset:18812
s_waitcnt lgkmcnt(0)
v_lshlrev_b32 v4, 2, v6
v_lshlrev_b32 v5, 2, v3
v_add_i32 v4, vcc, s0, v4
v_add_i32 v5, vcc, s0, v5
BB14_42:
s_or_b64 exec, exec, s[8:9]
v_mov_b32 v7, 0x2ac
v_cmp_gt_u32_e32 vcc, v7, v6
s_and_saveexec_b64 s[8:9], vcc
s_xor_b64 s[8:9], exec, s[8:9]
s_cbranch_execz BB14_50
s_mov_b32 m0, -1
ds_read_b32 v7, v4
ds_read_b32 v14, v5
ds_read_b32 v8, v4 offset:2736
ds_read_b32 v16, v5 offset:2736
ds_read_b32 v9, v4 offset:5472
ds_read_b32 v11, v4 offset:8208
s_waitcnt lgkmcnt(0)
v_xor_b32 v15, v7, v14
ds_read_b32 v13, v4 offset:13680
ds_read_b32 v17, v5 offset:5472
ds_read_b32 v18, v5 offset:8208
ds_read_b32 v7, v5 offset:13680
ds_read_b32 v12, v4 offset:10944
ds_read_b32 v19, v5 offset:10944
v_xor_b32 v20, v8, v16
s_waitcnt lgkmcnt(0)
v_xor_b32 v8, v9, v17
v_xor_b32 v9, v11, v18
v_xor_b32 v18, v13, v7
v_lshlrev_b32 v7, 24, v20
v_lshrrev_b32 v16, 8, v15
v_xor_b32 v17, v12, v19
v_or_b32 v11, v7, v16
v_lshlrev_b32 v7, 24, v8
v_lshrrev_b32 v12, 8, v20
v_or_b32 v12, v7, v12
v_lshlrev_b32 v7, 24, v9
v_lshrrev_b32 v8, 8, v8
v_or_b32 v13, v7, v8
v_and_b32 v6, 0x3ff, v6
v_lshrrev_b32 v8, 8, v9
v_lshlrev_b32 v9, 10, v3
v_lshlrev_b32 v7, 24, v17
v_or_b32 v14, v7, v8
v_lshlrev_b32 v7, 24, v18
v_lshrrev_b32 v8, 8, v17
v_and_b32 v9, 0xffc00, v9
v_or_b32 v6, s1, v6
v_or_b32 v7, v7, v8
v_or_b32 v9, v9, v6
v_or_b32 v6, v20, v15
v_lshrrev_b32 v8, 8, v18
v_cmp_ne_i32_e32 vcc, 0, v6
s_and_saveexec_b64 s[10:11], vcc
s_xor_b64 s[10:11], exec, s[10:11]
s_cbranch_execz BB14_49
v_lshrrev_b32 v15, 24, v15
v_and_b32 v6, 0xf0f, v16
v_and_b32 v15, 0xf0, v15
v_or_b32 v6, v6, v15
v_mul_lo_i32 v15, s6, v6
v_lshrrev_b32 v16, 1, v6
v_add_i32 v15, vcc, v15, v16
v_lshrrev_b32 v16, 3, v6
v_sub_i32 v15, vcc, v15, v16
v_lshrrev_b32 v16, 30, v15
v_subrev_i32 v15, vcc, v16, v6
v_mul_lo_i32 v15, s7, v15
v_mul_u32_u24 v19, 10, v16
v_ashrrev_i32 v16, 31, v15
v_lshlrev_b64 v[15:16], 2, v[15:16]
v_add_i32 v17, vcc, s4, v15
v_mov_b32 v15, s5
v_addc_u32 v18, vcc, v16, v15, vcc
v_and_b32 v15, 30, v19
v_lshlrev_b32 v16, v15, 1
flat_atomic_add v16, v[17:18], v16 glc
s_waitcnt vmcnt(0) lgkmcnt(0)
v_bfe_u32 v15, v16, v15, 10
v_mov_b32 v16, 0x2ac
v_cmp_gt_u32_e32 vcc, v16, v15
s_and_saveexec_b64 s[12:13], vcc
s_xor_b64 s[12:13], exec, s[12:13]
s_cbranch_execz BB14_48
v_mov_b32 v16, 0x2ac
v_mad_i32_i24 v6, v16, v6, v15
v_lshlrev_b32 v6, 5, v6
v_ashrrev_i32 v16, 31, v6
v_add_i32 v15, vcc, s2, v6
v_mov_b32 v6, s3
v_addc_u32 v16, vcc, v16, v6, vcc
v_cmp_ne_i64_e32 vcc, 0, v[15:16]
s_and_saveexec_b64 s[14:15], vcc
s_xor_b64 s[14:15], exec, s[14:15]
flat_store_dwordx4 v[15:16], v[11:14]
s_waitcnt vmcnt(0) lgkmcnt(0)
v_add_i32 v11, vcc, 16, v15
v_addc_u32 v12, vcc, 0, v16, vcc
flat_store_dwordx4 v[11:12], v[7:10]
s_waitcnt vmcnt(0) lgkmcnt(0)
BB14_47:
s_or_b64 exec, exec, s[14:15]
BB14_48:
s_or_b64 exec, exec, s[12:13]
BB14_49:
s_or_b64 exec, exec, s[10:11]
BB14_50:
s_or_b64 exec, exec, s[8:9]
v_min_u32 v6, 0x100, v1
v_subrev_i32 v1, vcc, v6, v1
v_cmp_ne_i32_e32 vcc, 0, v1
s_and_b64 vcc, exec, vcc
s_cbranch_vccnz BB14_30
BB14_51:
s_endpgm
.section .AMDGPU.csdata
.section .AMDGPU.runtime_metadata
.byte 4
.byte 6
.long 13
.ascii "kernel_round1"
.byte 7
.byte 9
.long 4
.byte 10
.long 4
.byte 11
.long 4
.ascii "uint"
.byte 13
.byte 0
.byte 14
.short 7
.byte 16
.byte 0
.byte 8
.byte 7
.byte 9
.long 8
.byte 10
.long 8
.byte 11
.long 5
.ascii "char*"
.byte 13
.byte 1
.byte 14
.short 1
.byte 16
.byte 0
.byte 15
.byte 1
.byte 8
.byte 7
.byte 9
.long 8
.byte 10
.long 8
.byte 11
.long 5
.ascii "char*"
.byte 13
.byte 1
.byte 14
.short 1
.byte 16
.byte 0
.byte 15
.byte 1
.byte 8
.byte 7
.byte 9
.long 8
.byte 10
.long 8
.byte 11
.long 5
.ascii "uint*"
.byte 13
.byte 1
.byte 14
.short 7
.byte 16
.byte 0
.byte 15
.byte 1
.byte 8
.byte 7
.byte 9
.long 8
.byte 10
.long 8
.byte 11
.long 5
.ascii "uint*"
.byte 13
.byte 1
.byte 14
.short 7
.byte 16
.byte 0
.byte 15
.byte 1
.byte 8
.byte 7
.byte 9
.long 8
.byte 10
.long 8
.byte 11
.long 5
.ascii "uint*"
.byte 13
.byte 1
.byte 14
.short 7
.byte 16
.byte 0
.byte 15
.byte 1
.byte 8
.byte 5
.section .AMDGPU.config
.text
.globl kernel_round2
.p2align 8
.type kernel_round2,@function
.amdgpu_hsa_kernel kernel_round2
kernel_round2:
.amd_kernel_code_t
max_scratch_backing_memory_byte_size = 0
.dx10clamp
enable_ordered_append_gds = 0
private_element_size = 1
workitem_private_segment_byte_size = 0
workgroup_group_segment_byte_size = 21988
gds_segment_byte_size = 0
workgroup_fbarrier_count = 0
wavefront_sgpr_count = 30
workitem_vgpr_count = 21
group_segment_alignment = 4
private_segment_alignment = 4
.end_amd_kernel_code_t
s_cmp_gt_u32 s12, 0xfff
s_cbranch_scc1 BB15_51
v_mov_b32 v1, 0x100
v_cmp_gt_u32_e32 vcc, v1, v0
s_and_saveexec_b64 s[0:1], vcc
s_xor_b64 s[0:1], exec, s[0:1]
s_cbranch_execz BB15_10
v_add_i32 v1, vcc, 0xffffff00, v0
v_lshlrev_b32 v2, 2, v0
s_mov_b64 s[2:3], 0
s_mov_b32 m0, -1
BB15_12:
v_mov_b32 v3, 0x2ac
ds_write_b32 v2, v3
v_add_i32 v1, vcc, 0x100, v1
v_add_i32 v2, vcc, 0x400, v2
s_waitcnt lgkmcnt(0)
v_mov_b32 v3, 0xffffff00
v_cmp_gt_u32_e32 vcc, v3, v1
s_or_b64 s[2:3], vcc, s[2:3]
s_andn2_b64 exec, exec, s[2:3]
s_cbranch_execnz BB15_12
s_or_b64 exec, exec, s[2:3]
BB15_10:
s_or_b64 exec, exec, s[0:1]
s_load_dwordx2 s[6:7], s[8:9], 0x38
s_load_dwordx2 s[2:3], s[8:9], 0x40
s_load_dwordx2 s[10:11], s[8:9], 0x48
s_load_dwordx2 s[4:5], s[8:9], 0x50
v_mov_b32 v1, 0x2ac
v_cmp_gt_u32_e32 vcc, v1, v0
v_mov_b32 v1, 0
s_waitcnt lgkmcnt(0)
s_and_saveexec_b64 s[0:1], vcc
s_xor_b64 s[0:1], exec, s[0:1]
s_cbranch_execz BB15_19
v_sub_i32 v1, vcc, 0x2ab, v0
v_lshrrev_b32 v5, 8, v1
v_add_i32 v3, vcc, 1, v5
v_cmp_gt_u32_e32 vcc, 64, v3
v_cndmask_b32 v4, 0, -1, vcc
v_mov_b32 v1, v0
v_cmp_lt_u32_e32 vcc, 63, v3
s_and_saveexec_b64 s[8:9], vcc
s_xor_b64 s[8:9], exec, s[8:9]
s_cbranch_execz BB15_6
v_and_b32 v2, 63, v3
v_subrev_i32 v3, vcc, v2, v3
v_mov_b32 v4, -1
v_mov_b32 v1, v0
v_cmp_ne_i32_e32 vcc, 0, v3
s_and_saveexec_b64 s[14:15], vcc
s_xor_b64 s[14:15], exec, s[14:15]
s_cbranch_execz BB15_5
v_lshlrev_b32 v1, 8, v5
v_add_i32 v1, vcc, v1, v0
v_add_i32 v1, vcc, 0x100, v1
v_lshlrev_b32 v4, 8, v2
v_subrev_i32 v1, vcc, v4, v1
s_mov_b64 s[16:17], 0
v_mov_b32 v4, 0
s_mov_b32 m0, -1
BB15_8:
v_or_b32 v5, v4, v0
v_mov_b32 v6, 0x2ac
v_lshlrev_b32 v5, 1, v5
v_add_i32 v3, vcc, 0xffffffc0, v3
v_add_i32 v4, vcc, 0x4000, v4
v_cmp_eq_i32_e32 vcc, 0, v3
ds_write_b16 v5, v6 offset:1024
ds_write_b16 v5, v6 offset:1536
ds_write_b16 v5, v6 offset:2048
ds_write_b16 v5, v6 offset:2560
ds_write_b16 v5, v6 offset:3072
ds_write_b16 v5, v6 offset:3584
ds_write_b16 v5, v6 offset:4096
ds_write_b16 v5, v6 offset:4608
ds_write_b16 v5, v6 offset:5120
ds_write_b16 v5, v6 offset:5632
ds_write_b16 v5, v6 offset:6144
ds_write_b16 v5, v6 offset:6656
ds_write_b16 v5, v6 offset:7168
ds_write_b16 v5, v6 offset:7680
ds_write_b16 v5, v6 offset:8192
ds_write_b16 v5, v6 offset:8704
ds_write_b16 v5, v6 offset:9216
ds_write_b16 v5, v6 offset:9728
ds_write_b16 v5, v6 offset:10240
ds_write_b16 v5, v6 offset:10752
ds_write_b16 v5, v6 offset:11264
ds_write_b16 v5, v6 offset:11776
ds_write_b16 v5, v6 offset:12288
ds_write_b16 v5, v6 offset:12800
ds_write_b16 v5, v6 offset:13312
ds_write_b16 v5, v6 offset:13824
ds_write_b16 v5, v6 offset:14336
ds_write_b16 v5, v6 offset:14848
ds_write_b16 v5, v6 offset:15360
ds_write_b16 v5, v6 offset:15872
ds_write_b16 v5, v6 offset:16384
ds_write_b16 v5, v6 offset:16896
ds_write_b16 v5, v6 offset:17408
ds_write_b16 v5, v6 offset:17920
ds_write_b16 v5, v6 offset:18432
ds_write_b16 v5, v6 offset:18944
ds_write_b16 v5, v6 offset:19456
ds_write_b16 v5, v6 offset:19968
ds_write_b16 v5, v6 offset:20480
ds_write_b16 v5, v6 offset:20992
ds_write_b16 v5, v6 offset:21504
ds_write_b16 v5, v6 offset:22016
ds_write_b16 v5, v6 offset:22528
ds_write_b16 v5, v6 offset:23040
ds_write_b16 v5, v6 offset:23552
ds_write_b16 v5, v6 offset:24064
ds_write_b16 v5, v6 offset:24576
ds_write_b16 v5, v6 offset:25088
ds_write_b16 v5, v6 offset:25600
ds_write_b16 v5, v6 offset:26112
ds_write_b16 v5, v6 offset:26624
ds_write_b16 v5, v6 offset:27136
ds_write_b16 v5, v6 offset:27648
ds_write_b16 v5, v6 offset:28160
ds_write_b16 v5, v6 offset:28672
ds_write_b16 v5, v6 offset:29184
ds_write_b16 v5, v6 offset:29696
ds_write_b16 v5, v6 offset:30208
ds_write_b16 v5, v6 offset:30720
ds_write_b16 v5, v6 offset:31232
ds_write_b16 v5, v6 offset:31744
ds_write_b16 v5, v6 offset:32256
ds_write_b16 v5, v6 offset:32768
ds_write_b16 v5, v6 offset:33280
s_or_b64 s[16:17], vcc, s[16:17]
s_waitcnt lgkmcnt(0)
s_andn2_b64 exec, exec, s[16:17]
s_cbranch_execnz BB15_8
s_or_b64 exec, exec, s[16:17]
v_cmp_ne_i32_e32 vcc, 0, v2
v_cndmask_b32 v4, 0, -1, vcc
BB15_5:
s_or_b64 exec, exec, s[14:15]
BB15_6:
s_or_b64 exec, exec, s[8:9]
v_cmp_ne_i32_e32 vcc, 0, v4
s_and_saveexec_b64 s[8:9], vcc
s_xor_b64 s[8:9], exec, s[8:9]
s_cbranch_execz BB15_16
v_lshlrev_b32 v2, 1, v1
v_add_i32 v2, vcc, 0x400, v2
s_mov_b64 s[14:15], 0
s_mov_b32 m0, -1
BB15_14:
v_mov_b32 v3, 0x2ac
ds_write_b16 v2, v3
v_add_i32 v1, vcc, 0x100, v1
v_add_i32 v2, vcc, 0x200, v2
s_waitcnt lgkmcnt(0)
v_mov_b32 v3, 0x2ab
v_cmp_lt_u32_e32 vcc, v3, v1
s_or_b64 s[14:15], vcc, s[14:15]
s_andn2_b64 exec, exec, s[14:15]
s_cbranch_execnz BB15_14
s_or_b64 exec, exec, s[14:15]
BB15_16:
s_or_b64 exec, exec, s[8:9]
v_mov_b32 v1, 0
v_cmp_eq_i32_e32 vcc, 0, v0
s_and_saveexec_b64 s[8:9], vcc
s_xor_b64 s[8:9], exec, s[8:9]
s_cbranch_execz BB15_18
s_mul_i32 s13, s12, 0x55555555
s_lshr_b32 s14, s12, 1
s_add_i32 s13, s13, s14
s_lshr_b32 s14, s12, 3
s_sub_i32 s13, s13, s14
s_lshr_b32 s13, s13, 30
s_sub_i32 s14, s12, s13
s_mul_i32 s14, s14, 0xaaaaaaab
s_ashr_i32 s15, s14, 31
s_lshl_b64 s[14:15], s[14:15], 2
s_add_u32 s10, s10, s14
s_addc_u32 s11, s11, s15
v_mov_b32 v2, s11
v_mov_b32 v1, s10
flat_load_dword v1, v[1:2]
v_mul_u32_u24 v3, 10, s13
v_and_b32 v3, 30, v3
v_mov_b32 v2, 0
s_mov_b32 m0, -1
s_waitcnt vmcnt(0) lgkmcnt(0)
v_bfe_u32 v1, v1, v3, 10
v_min_u32 v1, 0x2ac, v1
ds_write_b32 v2, v1 offset:2392
s_waitcnt lgkmcnt(0)
BB15_18:
s_or_b64 exec, exec, s[8:9]
BB15_19:
s_or_b64 exec, exec, s[0:1]
s_barrier
v_cmp_ne_i32_e32 vcc, 0, v0
s_and_saveexec_b64 s[0:1], vcc
s_xor_b64 s[0:1], exec, s[0:1]
v_mov_b32 v1, 0
s_mov_b32 m0, -1
ds_read_b32 v1, v1 offset:2392
s_waitcnt lgkmcnt(0)
BB15_21:
s_or_b64 exec, exec, s[0:1]
s_barrier
v_cmp_eq_i32_e32 vcc, 0, v0
s_and_saveexec_b64 s[0:1], vcc
s_xor_b64 s[0:1], exec, s[0:1]
v_mov_b32 v2, 0
s_mov_b32 m0, -1
ds_write_b32 v2, v2 offset:2392
s_waitcnt lgkmcnt(0)
BB15_23:
s_or_b64 exec, exec, s[0:1]
s_barrier
v_cmp_lt_u32_e32 vcc, v0, v1
s_and_saveexec_b64 s[8:9], vcc
s_xor_b64 s[8:9], exec, s[8:9]
s_cbranch_execz BB15_27
v_lshlrev_b32 v3, 2, v0
v_lshlrev_b32 v2, 1, v0
s_movk_i32 s10, 0x400
s_mul_i32 s0, s12, 0x5580
v_lshlrev_b32 v4, 5, v0
v_add_i32 v2, vcc, s10, v2
v_add_i32 v3, vcc, 0x95c, v3
v_add_i32 v4, vcc, s0, v4
s_mov_b64 s[14:15], 0
v_mov_b32 v5, v0
s_mov_b32 m0, -1
BB15_25:
v_ashrrev_i32 v7, 31, v4
v_add_i32 v6, vcc, s6, v4
v_mov_b32 v8, s7
v_addc_u32 v7, vcc, v7, v8, vcc
v_add_i32 v8, vcc, 4, v6
v_addc_u32 v9, vcc, 0, v7, vcc
flat_load_dword v11, v[8:9]
v_add_i32 v8, vcc, 8, v6
v_addc_u32 v9, vcc, 0, v7, vcc
flat_load_dword v12, v[8:9]
v_add_i32 v8, vcc, 12, v6
v_addc_u32 v9, vcc, 0, v7, vcc
flat_load_dword v13, v[8:9]
v_add_i32 v8, vcc, 16, v6
v_addc_u32 v9, vcc, 0, v7, vcc
flat_load_dword v10, v[6:7]
s_nop 0
flat_load_dword v14, v[8:9]
v_add_i32 v8, vcc, 20, v6
v_addc_u32 v9, vcc, 0, v7, vcc
flat_load_dword v6, v[8:9]
v_add_i32 v4, vcc, 0x2000, v4
s_waitcnt vmcnt(5) lgkmcnt(0)
ds_write_b32 v3, v11 offset:2736
s_waitcnt vmcnt(4)
ds_write_b32 v3, v12 offset:5472
s_waitcnt vmcnt(3)
ds_write_b32 v3, v13 offset:8208
s_waitcnt vmcnt(2)
v_and_b32 v8, 0xf000, v10
v_bfe_u32 v7, v10, 16, 4
v_lshrrev_b32 v8, 8, v8
v_or_b32 v7, v8, v7
ds_write_b32 v3, v10
v_lshlrev_b32 v7, 2, v7
s_waitcnt vmcnt(1)
ds_write_b32 v3, v14 offset:10944
s_waitcnt vmcnt(0)
ds_write_b32 v3, v6 offset:13680
s_waitcnt lgkmcnt(0)
ds_wrxchg_rtn_b32 v6, v7, v5
s_waitcnt lgkmcnt(0)
v_add_i32 v5, vcc, 0x100, v5
v_add_i32 v3, vcc, s10, v3
v_cmp_ge_u32 s[0:1], v5, v1
ds_write_b16 v2, v6
v_add_i32 v2, vcc, 0x200, v2
s_or_b64 s[14:15], s[0:1], s[14:15]
s_waitcnt lgkmcnt(0)
s_andn2_b64 exec, exec, s[14:15]
s_cbranch_execnz BB15_25
s_or_b64 exec, exec, s[14:15]
BB15_27:
s_or_b64 exec, exec, s[8:9]
s_barrier
v_mov_b32 v1, 0x2ac
v_cmp_gt_u32_e32 vcc, v1, v0
s_and_saveexec_b64 s[0:1], vcc
s_xor_b64 s[0:1], exec, s[0:1]
s_cbranch_execz BB15_32
s_mov_b64 s[6:7], 0
v_mov_b32 v1, v0
BB15_34:
v_lshlrev_b32 v2, 1, v1
s_mov_b32 m0, -1
ds_read_u16 v2, v2 offset:1024
v_mov_b32 v3, 0x2ac
s_waitcnt lgkmcnt(0)
v_cmp_gt_u32_e32 vcc, v3, v2
s_and_saveexec_b64 s[8:9], vcc
s_xor_b64 s[8:9], exec, s[8:9]
s_cbranch_execz BB15_40
s_mov_b64 s[10:11], 0
BB15_36:
v_mov_b32 v3, 1
v_mov_b32 v4, 0
s_mov_b32 m0, -1
ds_add_rtn_u32 v3, v4, v3 offset:2392
v_mov_b32 v4, 0x31a
s_waitcnt lgkmcnt(0)
v_cmp_gt_u32_e32 vcc, v4, v3
s_and_saveexec_b64 s[14:15], vcc
s_xor_b64 s[14:15], exec, s[14:15]
v_lshlrev_b32 v3, 1, v3
s_mov_b32 m0, -1
ds_write_b16 v3, v2 offset:18812
s_waitcnt lgkmcnt(0)
v_lshlrev_b32 v2, 1, v2
ds_read_u16 v2, v2 offset:1024
ds_write_b16 v3, v1 offset:20400
v_mov_b32 v3, 0x2ab
s_waitcnt lgkmcnt(0)
v_cmp_lt_u32_e32 vcc, v3, v2
s_or_b64 s[10:11], vcc, s[10:11]
BB15_38:
s_or_b64 exec, exec, s[14:15]
s_or_b64 s[10:11], s[14:15], s[10:11]
s_andn2_b64 exec, exec, s[10:11]
s_cbranch_execnz BB15_36
s_or_b64 exec, exec, s[10:11]
BB15_40:
s_or_b64 exec, exec, s[8:9]
v_add_i32 v1, vcc, 0x100, v1
v_mov_b32 v2, 0x2ab
v_cmp_lt_u32_e32 vcc, v2, v1
s_or_b64 s[6:7], vcc, s[6:7]
s_andn2_b64 exec, exec, s[6:7]
s_cbranch_execnz BB15_34
s_or_b64 exec, exec, s[6:7]
BB15_32:
s_or_b64 exec, exec, s[0:1]
s_barrier
v_mov_b32 v1, 0
s_mov_b32 m0, -1
ds_read_b32 v1, v1 offset:2392
s_mov_b32 s16, 0
s_waitcnt lgkmcnt(0)
v_min_u32 v1, 0x31a, v1
v_cmp_eq_i32_e32 vcc, 0, v1
s_and_b64 vcc, exec, vcc
s_cbranch_vccnz BB15_51
s_mov_b32 s17, s16
s_mov_b32 s18, s16
s_mov_b32 s19, s16
s_mov_b32 s20, s16
s_mov_b32 s21, s16
s_mov_b32 s22, s16
s_mov_b32 s23, s16
v_mov_b32 v3, s16
v_mov_b32 v4, s17
v_mov_b32 v5, s18
v_not_b32 v2, v0
v_mov_b32 v6, s19
v_mov_b32 v7, s20
v_mov_b32 v8, s21
v_mov_b32 v9, s22
v_mov_b32 v10, s23
s_movk_i32 s0, 0x95c
s_lshl_b32 s1, s12, 20
s_mov_b32 s6, 0x55555555
s_mov_b32 s7, 0xaaaaaaab
BB15_30:
v_mov_b32 v6, 0x2ac
v_cmp_lt_u32_e32 vcc, v0, v1
s_and_saveexec_b64 s[8:9], vcc
s_xor_b64 s[8:9], exec, s[8:9]
v_add_i32 v3, vcc, v1, v2
v_lshlrev_b32 v3, 1, v3
s_mov_b32 m0, -1
ds_read_u16 v6, v3 offset:20400
ds_read_u16 v3, v3 offset:18812
s_waitcnt lgkmcnt(0)
v_lshlrev_b32 v4, 2, v6
v_lshlrev_b32 v5, 2, v3
v_add_i32 v4, vcc, s0, v4
v_add_i32 v5, vcc, s0, v5
BB15_42:
s_or_b64 exec, exec, s[8:9]
v_mov_b32 v7, 0x2ac
v_cmp_gt_u32_e32 vcc, v7, v6
s_and_saveexec_b64 s[8:9], vcc
s_xor_b64 s[8:9], exec, s[8:9]
s_cbranch_execz BB15_50
s_mov_b32 m0, -1
ds_read_b32 v7, v4
ds_read_b32 v11, v5
ds_read_b32 v8, v4 offset:2736
ds_read_b32 v16, v5 offset:2736
ds_read_b32 v15, v4 offset:13680
ds_read_b32 v12, v4 offset:5472
s_waitcnt lgkmcnt(0)
v_xor_b32 v20, v7, v11
ds_read_b32 v7, v5 offset:13680
v_xor_b32 v11, v8, v16
ds_read_b32 v17, v5 offset:5472
ds_read_b32 v13, v4 offset:8208
ds_read_b32 v18, v5 offset:8208
s_waitcnt lgkmcnt(0)
v_xor_b32 v7, v15, v7
ds_read_b32 v14, v4 offset:10944
ds_read_b32 v19, v5 offset:10944
v_lshrrev_b32 v8, 24, v20
v_lshlrev_b32 v15, 8, v11
v_or_b32 v15, v15, v8
v_or_b32 v8, v11, v15
v_and_b32 v6, 0x3ff, v6
v_cmp_ne_i32_e32 vcc, 0, v8
v_lshlrev_b32 v8, 10, v3
v_and_b32 v8, 0xffc00, v8
v_or_b32 v6, s1, v6
v_xor_b32 v12, v12, v17
v_xor_b32 v13, v13, v18
s_waitcnt lgkmcnt(0)
v_xor_b32 v14, v14, v19
v_or_b32 v8, v8, v6
s_and_saveexec_b64 s[10:11], vcc
s_xor_b64 s[10:11], exec, s[10:11]
s_cbranch_execz BB15_49
v_and_b32 v6, 0xfff, v15
v_mul_lo_i32 v16, s6, v6
v_bfe_u32 v17, v15, 1, 11
v_bfe_u32 v15, v15, 3, 9
v_add_i32 v16, vcc, v16, v17
v_sub_i32 v15, vcc, v16, v15
v_lshrrev_b32 v16, 30, v15
v_sub_i32 v15, vcc, v6, v16
v_mul_lo_i32 v15, s7, v15
v_mul_u32_u24 v19, 10, v16
v_ashrrev_i32 v16, 31, v15
v_lshlrev_b64 v[15:16], 2, v[15:16]
v_add_i32 v17, vcc, s4, v15
v_mov_b32 v15, s5
v_addc_u32 v18, vcc, v16, v15, vcc
v_and_b32 v15, 30, v19
v_lshlrev_b32 v16, v15, 1
flat_atomic_add v16, v[17:18], v16 glc
s_waitcnt vmcnt(0) lgkmcnt(0)
v_bfe_u32 v15, v16, v15, 10
v_mov_b32 v16, 0x2ac
v_cmp_gt_u32_e32 vcc, v16, v15
s_and_saveexec_b64 s[12:13], vcc
s_xor_b64 s[12:13], exec, s[12:13]
s_cbranch_execz BB15_48
v_mov_b32 v16, 0x2ac
v_mad_i32_i24 v6, v16, v6, v15
v_lshlrev_b32 v6, 5, v6
v_ashrrev_i32 v16, 31, v6
v_add_i32 v15, vcc, s2, v6
v_mov_b32 v6, s3
v_addc_u32 v16, vcc, v16, v6, vcc
v_cmp_ne_i64_e32 vcc, 0, v[15:16]
s_and_saveexec_b64 s[14:15], vcc
s_xor_b64 s[14:15], exec, s[14:15]
flat_store_dwordx4 v[15:16], v[11:14]
s_waitcnt vmcnt(0) lgkmcnt(0)
v_add_i32 v11, vcc, 16, v15
v_addc_u32 v12, vcc, 0, v16, vcc
flat_store_dwordx4 v[11:12], v[7:10]
s_waitcnt vmcnt(0) lgkmcnt(0)
BB15_47:
s_or_b64 exec, exec, s[14:15]
BB15_48:
s_or_b64 exec, exec, s[12:13]
BB15_49:
s_or_b64 exec, exec, s[10:11]
BB15_50:
s_or_b64 exec, exec, s[8:9]
v_min_u32 v6, 0x100, v1
v_subrev_i32 v1, vcc, v6, v1
v_cmp_ne_i32_e32 vcc, 0, v1
s_and_b64 vcc, exec, vcc
s_cbranch_vccnz BB15_30
BB15_51:
s_endpgm
.section .AMDGPU.csdata
.section .AMDGPU.runtime_metadata
.byte 4
.byte 6
.long 13
.ascii "kernel_round2"
.byte 7
.byte 9
.long 4
.byte 10
.long 4
.byte 11
.long 4
.ascii "uint"
.byte 13
.byte 0
.byte 14
.short 7
.byte 16
.byte 0
.byte 8
.byte 7
.byte 9
.long 8
.byte 10
.long 8
.byte 11
.long 5
.ascii "char*"
.byte 13
.byte 1
.byte 14
.short 1
.byte 16
.byte 0
.byte 15
.byte 1
.byte 8
.byte 7
.byte 9
.long 8
.byte 10
.long 8
.byte 11
.long 5
.ascii "char*"
.byte 13
.byte 1
.byte 14
.short 1
.byte 16
.byte 0
.byte 15
.byte 1
.byte 8
.byte 7
.byte 9
.long 8
.byte 10
.long 8
.byte 11
.long 5
.ascii "uint*"
.byte 13
.byte 1
.byte 14
.short 7
.byte 16
.byte 0
.byte 15
.byte 1
.byte 8
.byte 7
.byte 9
.long 8
.byte 10
.long 8
.byte 11
.long 5
.ascii "uint*"
.byte 13
.byte 1
.byte 14
.short 7
.byte 16
.byte 0
.byte 15
.byte 1
.byte 8
.byte 7
.byte 9
.long 8
.byte 10
.long 8
.byte 11
.long 5
.ascii "uint*"
.byte 13
.byte 1
.byte 14
.short 7
.byte 16
.byte 0
.byte 15
.byte 1
.byte 8
.byte 5
.section .AMDGPU.config
.text
.globl kernel_round3
.p2align 8
.type kernel_round3,@function
.amdgpu_hsa_kernel kernel_round3
kernel_round3:
.amd_kernel_code_t
max_scratch_backing_memory_byte_size = 0
.dx10clamp
enable_ordered_append_gds = 0
private_element_size = 1
workitem_private_segment_byte_size = 0
workgroup_group_segment_byte_size = 19252
gds_segment_byte_size = 0
workgroup_fbarrier_count = 0
wavefront_sgpr_count = 30
workitem_vgpr_count = 21
group_segment_alignment = 4
private_segment_alignment = 4
.end_amd_kernel_code_t
s_cmp_gt_u32 s12, 0xfff
s_cbranch_scc1 BB16_51
v_mov_b32 v1, 0x100
v_cmp_gt_u32_e32 vcc, v1, v0
s_and_saveexec_b64 s[0:1], vcc
s_xor_b64 s[0:1], exec, s[0:1]
s_cbranch_execz BB16_10
v_add_i32 v1, vcc, 0xffffff00, v0
v_lshlrev_b32 v2, 2, v0
s_mov_b64 s[2:3], 0
s_mov_b32 m0, -1
BB16_12:
v_mov_b32 v3, 0x2ac
ds_write_b32 v2, v3
v_add_i32 v1, vcc, 0x100, v1
v_add_i32 v2, vcc, 0x400, v2
s_waitcnt lgkmcnt(0)
v_mov_b32 v3, 0xffffff00
v_cmp_gt_u32_e32 vcc, v3, v1
s_or_b64 s[2:3], vcc, s[2:3]
s_andn2_b64 exec, exec, s[2:3]
s_cbranch_execnz BB16_12
s_or_b64 exec, exec, s[2:3]
BB16_10:
s_or_b64 exec, exec, s[0:1]
s_load_dwordx2 s[6:7], s[8:9], 0x38
s_load_dwordx2 s[2:3], s[8:9], 0x40
s_load_dwordx2 s[10:11], s[8:9], 0x48
s_load_dwordx2 s[4:5], s[8:9], 0x50
v_mov_b32 v1, 0x2ac
v_cmp_gt_u32_e32 vcc, v1, v0
v_mov_b32 v1, 0
s_waitcnt lgkmcnt(0)
s_and_saveexec_b64 s[0:1], vcc
s_xor_b64 s[0:1], exec, s[0:1]
s_cbranch_execz BB16_19
v_sub_i32 v1, vcc, 0x2ab, v0
v_lshrrev_b32 v5, 8, v1
v_add_i32 v3, vcc, 1, v5
v_cmp_gt_u32_e32 vcc, 64, v3
v_cndmask_b32 v4, 0, -1, vcc
v_mov_b32 v1, v0
v_cmp_lt_u32_e32 vcc, 63, v3
s_and_saveexec_b64 s[8:9], vcc
s_xor_b64 s[8:9], exec, s[8:9]
s_cbranch_execz BB16_6
v_and_b32 v2, 63, v3
v_subrev_i32 v3, vcc, v2, v3
v_mov_b32 v4, -1
v_mov_b32 v1, v0
v_cmp_ne_i32_e32 vcc, 0, v3
s_and_saveexec_b64 s[14:15], vcc
s_xor_b64 s[14:15], exec, s[14:15]
s_cbranch_execz BB16_5
v_lshlrev_b32 v1, 8, v5
v_add_i32 v1, vcc, v1, v0
v_add_i32 v1, vcc, 0x100, v1
v_lshlrev_b32 v4, 8, v2
v_subrev_i32 v1, vcc, v4, v1
s_mov_b64 s[16:17], 0
v_mov_b32 v4, 0
s_mov_b32 m0, -1
BB16_8:
v_or_b32 v5, v4, v0
v_mov_b32 v6, 0x2ac
v_lshlrev_b32 v5, 1, v5
v_add_i32 v3, vcc, 0xffffffc0, v3
v_add_i32 v4, vcc, 0x4000, v4
v_cmp_eq_i32_e32 vcc, 0, v3
ds_write_b16 v5, v6 offset:1024
ds_write_b16 v5, v6 offset:1536
ds_write_b16 v5, v6 offset:2048
ds_write_b16 v5, v6 offset:2560
ds_write_b16 v5, v6 offset:3072
ds_write_b16 v5, v6 offset:3584
ds_write_b16 v5, v6 offset:4096
ds_write_b16 v5, v6 offset:4608
ds_write_b16 v5, v6 offset:5120
ds_write_b16 v5, v6 offset:5632
ds_write_b16 v5, v6 offset:6144
ds_write_b16 v5, v6 offset:6656
ds_write_b16 v5, v6 offset:7168
ds_write_b16 v5, v6 offset:7680
ds_write_b16 v5, v6 offset:8192
ds_write_b16 v5, v6 offset:8704
ds_write_b16 v5, v6 offset:9216
ds_write_b16 v5, v6 offset:9728
ds_write_b16 v5, v6 offset:10240
ds_write_b16 v5, v6 offset:10752
ds_write_b16 v5, v6 offset:11264
ds_write_b16 v5, v6 offset:11776
ds_write_b16 v5, v6 offset:12288
ds_write_b16 v5, v6 offset:12800
ds_write_b16 v5, v6 offset:13312
ds_write_b16 v5, v6 offset:13824
ds_write_b16 v5, v6 offset:14336
ds_write_b16 v5, v6 offset:14848
ds_write_b16 v5, v6 offset:15360
ds_write_b16 v5, v6 offset:15872
ds_write_b16 v5, v6 offset:16384
ds_write_b16 v5, v6 offset:16896
ds_write_b16 v5, v6 offset:17408
ds_write_b16 v5, v6 offset:17920
ds_write_b16 v5, v6 offset:18432
ds_write_b16 v5, v6 offset:18944
ds_write_b16 v5, v6 offset:19456
ds_write_b16 v5, v6 offset:19968
ds_write_b16 v5, v6 offset:20480
ds_write_b16 v5, v6 offset:20992
ds_write_b16 v5, v6 offset:21504
ds_write_b16 v5, v6 offset:22016
ds_write_b16 v5, v6 offset:22528
ds_write_b16 v5, v6 offset:23040
ds_write_b16 v5, v6 offset:23552
ds_write_b16 v5, v6 offset:24064
ds_write_b16 v5, v6 offset:24576
ds_write_b16 v5, v6 offset:25088
ds_write_b16 v5, v6 offset:25600
ds_write_b16 v5, v6 offset:26112
ds_write_b16 v5, v6 offset:26624
ds_write_b16 v5, v6 offset:27136
ds_write_b16 v5, v6 offset:27648
ds_write_b16 v5, v6 offset:28160
ds_write_b16 v5, v6 offset:28672
ds_write_b16 v5, v6 offset:29184
ds_write_b16 v5, v6 offset:29696
ds_write_b16 v5, v6 offset:30208
ds_write_b16 v5, v6 offset:30720
ds_write_b16 v5, v6 offset:31232
ds_write_b16 v5, v6 offset:31744
ds_write_b16 v5, v6 offset:32256
ds_write_b16 v5, v6 offset:32768
ds_write_b16 v5, v6 offset:33280
s_or_b64 s[16:17], vcc, s[16:17]
s_waitcnt lgkmcnt(0)
s_andn2_b64 exec, exec, s[16:17]
s_cbranch_execnz BB16_8
s_or_b64 exec, exec, s[16:17]
v_cmp_ne_i32_e32 vcc, 0, v2
v_cndmask_b32 v4, 0, -1, vcc
BB16_5:
s_or_b64 exec, exec, s[14:15]
BB16_6:
s_or_b64 exec, exec, s[8:9]
v_cmp_ne_i32_e32 vcc, 0, v4
s_and_saveexec_b64 s[8:9], vcc
s_xor_b64 s[8:9], exec, s[8:9]
s_cbranch_execz BB16_16
v_lshlrev_b32 v2, 1, v1
v_add_i32 v2, vcc, 0x400, v2
s_mov_b64 s[14:15], 0
s_mov_b32 m0, -1
BB16_14:
v_mov_b32 v3, 0x2ac
ds_write_b16 v2, v3
v_add_i32 v1, vcc, 0x100, v1
v_add_i32 v2, vcc, 0x200, v2
s_waitcnt lgkmcnt(0)
v_mov_b32 v3, 0x2ab
v_cmp_lt_u32_e32 vcc, v3, v1
s_or_b64 s[14:15], vcc, s[14:15]
s_andn2_b64 exec, exec, s[14:15]
s_cbranch_execnz BB16_14
s_or_b64 exec, exec, s[14:15]
BB16_16:
s_or_b64 exec, exec, s[8:9]
v_mov_b32 v1, 0
v_cmp_eq_i32_e32 vcc, 0, v0
s_and_saveexec_b64 s[8:9], vcc
s_xor_b64 s[8:9], exec, s[8:9]
s_cbranch_execz BB16_18
s_mul_i32 s13, s12, 0x55555555
s_lshr_b32 s14, s12, 1
s_add_i32 s13, s13, s14
s_lshr_b32 s14, s12, 3
s_sub_i32 s13, s13, s14
s_lshr_b32 s13, s13, 30
s_sub_i32 s14, s12, s13
s_mul_i32 s14, s14, 0xaaaaaaab
s_ashr_i32 s15, s14, 31
s_lshl_b64 s[14:15], s[14:15], 2
s_add_u32 s10, s10, s14
s_addc_u32 s11, s11, s15
v_mov_b32 v2, s11
v_mov_b32 v1, s10
flat_load_dword v1, v[1:2]
v_mul_u32_u24 v3, 10, s13
v_and_b32 v3, 30, v3
v_mov_b32 v2, 0
s_mov_b32 m0, -1
s_waitcnt vmcnt(0) lgkmcnt(0)
v_bfe_u32 v1, v1, v3, 10
v_min_u32 v1, 0x2ac, v1
ds_write_b32 v2, v1 offset:2392
s_waitcnt lgkmcnt(0)
BB16_18:
s_or_b64 exec, exec, s[8:9]
BB16_19:
s_or_b64 exec, exec, s[0:1]
s_barrier
v_cmp_ne_i32_e32 vcc, 0, v0
s_and_saveexec_b64 s[0:1], vcc
s_xor_b64 s[0:1], exec, s[0:1]
v_mov_b32 v1, 0
s_mov_b32 m0, -1
ds_read_b32 v1, v1 offset:2392
s_waitcnt lgkmcnt(0)
BB16_21:
s_or_b64 exec, exec, s[0:1]
s_barrier
v_cmp_eq_i32_e32 vcc, 0, v0
s_and_saveexec_b64 s[0:1], vcc
s_xor_b64 s[0:1], exec, s[0:1]
v_mov_b32 v2, 0
s_mov_b32 m0, -1
ds_write_b32 v2, v2 offset:2392
s_waitcnt lgkmcnt(0)
BB16_23:
s_or_b64 exec, exec, s[0:1]
s_barrier
v_cmp_lt_u32_e32 vcc, v0, v1
s_and_saveexec_b64 s[8:9], vcc
s_xor_b64 s[8:9], exec, s[8:9]
s_cbranch_execz BB16_27
v_lshlrev_b32 v3, 2, v0
v_lshlrev_b32 v2, 1, v0
s_movk_i32 s10, 0x400
s_mul_i32 s0, s12, 0x5580
v_lshlrev_b32 v4, 5, v0
v_add_i32 v2, vcc, s10, v2
v_add_i32 v3, vcc, 0x95c, v3
v_add_i32 v4, vcc, s0, v4
s_mov_b64 s[14:15], 0
v_mov_b32 v5, v0
s_mov_b32 m0, -1
BB16_25:
v_ashrrev_i32 v7, 31, v4
v_add_i32 v6, vcc, s6, v4
v_mov_b32 v8, s7
v_addc_u32 v7, vcc, v7, v8, vcc
v_add_i32 v8, vcc, 4, v6
v_addc_u32 v9, vcc, 0, v7, vcc
flat_load_dword v11, v[8:9]
v_add_i32 v8, vcc, 8, v6
v_addc_u32 v9, vcc, 0, v7, vcc
flat_load_dword v12, v[8:9]
v_add_i32 v8, vcc, 12, v6
v_addc_u32 v9, vcc, 0, v7, vcc
flat_load_dword v13, v[8:9]
v_add_i32 v8, vcc, 16, v6
flat_load_dword v10, v[6:7]
v_addc_u32 v9, vcc, 0, v7, vcc
flat_load_dword v6, v[8:9]
v_add_i32 v4, vcc, 0x2000, v4
s_waitcnt vmcnt(4) lgkmcnt(0)
ds_write_b32 v3, v11 offset:2736
s_waitcnt vmcnt(3)
ds_write_b32 v3, v12 offset:5472
s_waitcnt vmcnt(2)
ds_write_b32 v3, v13 offset:8208
s_waitcnt vmcnt(1)
v_bfe_u32 v7, v10, 12, 4
v_and_b32 v8, 0xf0, v10
v_or_b32 v7, v8, v7
ds_write_b32 v3, v10
s_waitcnt vmcnt(0)
ds_write_b32 v3, v6 offset:10944
v_lshlrev_b32 v7, 2, v7
s_waitcnt lgkmcnt(0)
ds_wrxchg_rtn_b32 v6, v7, v5
s_waitcnt lgkmcnt(0)
v_add_i32 v5, vcc, 0x100, v5
v_add_i32 v3, vcc, s10, v3
v_cmp_ge_u32 s[0:1], v5, v1
ds_write_b16 v2, v6
v_add_i32 v2, vcc, 0x200, v2
s_or_b64 s[14:15], s[0:1], s[14:15]
s_waitcnt lgkmcnt(0)
s_andn2_b64 exec, exec, s[14:15]
s_cbranch_execnz BB16_25
s_or_b64 exec, exec, s[14:15]
BB16_27:
s_or_b64 exec, exec, s[8:9]
s_barrier
v_mov_b32 v1, 0x2ac
v_cmp_gt_u32_e32 vcc, v1, v0
s_and_saveexec_b64 s[0:1], vcc
s_xor_b64 s[0:1], exec, s[0:1]
s_cbranch_execz BB16_32
s_mov_b64 s[6:7], 0
v_mov_b32 v1, v0
BB16_34:
v_lshlrev_b32 v2, 1, v1
s_mov_b32 m0, -1
ds_read_u16 v2, v2 offset:1024
v_mov_b32 v3, 0x2ac
s_waitcnt lgkmcnt(0)
v_cmp_gt_u32_e32 vcc, v3, v2
s_and_saveexec_b64 s[8:9], vcc
s_xor_b64 s[8:9], exec, s[8:9]
s_cbranch_execz BB16_40
s_mov_b64 s[10:11], 0
BB16_36:
v_mov_b32 v3, 1
v_mov_b32 v4, 0
s_mov_b32 m0, -1
ds_add_rtn_u32 v3, v4, v3 offset:2392
v_mov_b32 v4, 0x31a
s_waitcnt lgkmcnt(0)
v_cmp_gt_u32_e32 vcc, v4, v3
s_and_saveexec_b64 s[14:15], vcc
s_xor_b64 s[14:15], exec, s[14:15]
v_lshlrev_b32 v3, 1, v3
s_mov_b32 m0, -1
ds_write_b16 v3, v2 offset:16076
s_waitcnt lgkmcnt(0)
v_lshlrev_b32 v2, 1, v2
ds_read_u16 v2, v2 offset:1024
ds_write_b16 v3, v1 offset:17664
v_mov_b32 v3, 0x2ab
s_waitcnt lgkmcnt(0)
v_cmp_lt_u32_e32 vcc, v3, v2
s_or_b64 s[10:11], vcc, s[10:11]
BB16_38:
s_or_b64 exec, exec, s[14:15]
s_or_b64 s[10:11], s[14:15], s[10:11]
s_andn2_b64 exec, exec, s[10:11]
s_cbranch_execnz BB16_36
s_or_b64 exec, exec, s[10:11]
BB16_40:
s_or_b64 exec, exec, s[8:9]
v_add_i32 v1, vcc, 0x100, v1
v_mov_b32 v2, 0x2ab
v_cmp_lt_u32_e32 vcc, v2, v1
s_or_b64 s[6:7], vcc, s[6:7]
s_andn2_b64 exec, exec, s[6:7]
s_cbranch_execnz BB16_34
s_or_b64 exec, exec, s[6:7]
BB16_32:
s_or_b64 exec, exec, s[0:1]
s_barrier
v_mov_b32 v1, 0
s_mov_b32 m0, -1
ds_read_b32 v1, v1 offset:2392
s_mov_b32 s16, 0
s_waitcnt lgkmcnt(0)
v_min_u32 v1, 0x31a, v1
v_cmp_eq_i32_e32 vcc, 0, v1
s_and_b64 vcc, exec, vcc
s_cbranch_vccnz BB16_51
s_mov_b32 s17, s16
s_mov_b32 s18, s16
s_mov_b32 s19, s16
s_mov_b32 s20, s16
s_mov_b32 s21, s16
s_mov_b32 s22, s16
s_mov_b32 s23, s16
v_mov_b32 v3, s16
v_mov_b32 v4, s17
v_mov_b32 v5, s18
v_not_b32 v2, v0
v_mov_b32 v6, s19
v_mov_b32 v7, s20
v_mov_b32 v8, s21
v_mov_b32 v9, s22
v_mov_b32 v10, s23
s_movk_i32 s0, 0x95c
s_lshl_b32 s1, s12, 20
s_mov_b32 s6, 0x55555555
s_mov_b32 s7, 0xaaaaaaab
BB16_30:
v_mov_b32 v6, 0x2ac
v_cmp_lt_u32_e32 vcc, v0, v1
s_and_saveexec_b64 s[8:9], vcc
s_xor_b64 s[8:9], exec, s[8:9]
v_add_i32 v3, vcc, v1, v2
v_lshlrev_b32 v3, 1, v3
s_mov_b32 m0, -1
ds_read_u16 v6, v3 offset:17664
ds_read_u16 v3, v3 offset:16076
s_waitcnt lgkmcnt(0)
v_lshlrev_b32 v4, 2, v6
v_lshlrev_b32 v5, 2, v3
v_add_i32 v4, vcc, s0, v4
v_add_i32 v5, vcc, s0, v5
BB16_42:
s_or_b64 exec, exec, s[8:9]
v_mov_b32 v7, 0x2ac
v_cmp_gt_u32_e32 vcc, v7, v6
s_and_saveexec_b64 s[8:9], vcc
s_xor_b64 s[8:9], exec, s[8:9]
s_cbranch_execz BB16_50
s_mov_b32 m0, -1
ds_read_b32 v7, v4
ds_read_b32 v14, v5
ds_read_b32 v8, v4 offset:2736
ds_read_b32 v16, v5 offset:2736
ds_read_b32 v11, v4 offset:5472
ds_read_b32 v17, v5 offset:5472
ds_read_b32 v12, v4 offset:8208
ds_read_b32 v13, v4 offset:10944
ds_read_b32 v18, v5 offset:8208
ds_read_b32 v19, v5 offset:10944
s_waitcnt lgkmcnt(0)
v_xor_b32 v15, v7, v14
v_xor_b32 v20, v8, v16
v_xor_b32 v7, v11, v17
v_xor_b32 v8, v12, v18
v_xor_b32 v17, v13, v19
v_lshlrev_b32 v12, 24, v7
v_lshrrev_b32 v13, 8, v20
v_or_b32 v12, v12, v13
v_lshlrev_b32 v13, 24, v8
v_lshrrev_b32 v7, 8, v7
v_or_b32 v13, v13, v7
v_lshlrev_b32 v7, 24, v17
v_lshrrev_b32 v8, 8, v8
v_or_b32 v14, v7, v8
v_lshlrev_b32 v8, 10, v3
v_and_b32 v6, 0x3ff, v6
v_lshlrev_b32 v11, 24, v20
v_lshrrev_b32 v16, 8, v15
v_and_b32 v8, 0xffc00, v8
v_or_b32 v6, s1, v6
v_or_b32 v8, v8, v6
v_or_b32 v6, v20, v15
v_or_b32 v11, v11, v16
v_lshrrev_b32 v7, 8, v17
v_cmp_ne_i32_e32 vcc, 0, v6
s_and_saveexec_b64 s[10:11], vcc
s_xor_b64 s[10:11], exec, s[10:11]
s_cbranch_execz BB16_49
v_lshrrev_b32 v15, 24, v15
v_and_b32 v6, 0xf0f, v16
v_and_b32 v15, 0xf0, v15
v_or_b32 v6, v6, v15
v_mul_lo_i32 v15, s6, v6
v_lshrrev_b32 v16, 1, v6
v_add_i32 v15, vcc, v15, v16
v_lshrrev_b32 v16, 3, v6
v_sub_i32 v15, vcc, v15, v16
v_lshrrev_b32 v16, 30, v15
v_subrev_i32 v15, vcc, v16, v6
v_mul_lo_i32 v15, s7, v15
v_mul_u32_u24 v19, 10, v16
v_ashrrev_i32 v16, 31, v15
v_lshlrev_b64 v[15:16], 2, v[15:16]
v_add_i32 v17, vcc, s4, v15
v_mov_b32 v15, s5
v_addc_u32 v18, vcc, v16, v15, vcc
v_and_b32 v15, 30, v19
v_lshlrev_b32 v16, v15, 1
flat_atomic_add v16, v[17:18], v16 glc
s_waitcnt vmcnt(0) lgkmcnt(0)
v_bfe_u32 v15, v16, v15, 10
v_mov_b32 v16, 0x2ac
v_cmp_gt_u32_e32 vcc, v16, v15
s_and_saveexec_b64 s[12:13], vcc
s_xor_b64 s[12:13], exec, s[12:13]
s_cbranch_execz BB16_48
v_mov_b32 v16, 0x2ac
v_mad_i32_i24 v6, v16, v6, v15
v_lshlrev_b32 v6, 5, v6
v_ashrrev_i32 v16, 31, v6
v_add_i32 v15, vcc, s2, v6
v_mov_b32 v6, s3
v_addc_u32 v16, vcc, v16, v6, vcc
v_cmp_ne_i64_e32 vcc, 0, v[15:16]
s_and_saveexec_b64 s[14:15], vcc
s_xor_b64 s[14:15], exec, s[14:15]
flat_store_dwordx4 v[15:16], v[11:14]
s_waitcnt vmcnt(0) lgkmcnt(0)
v_add_i32 v11, vcc, 16, v15
v_addc_u32 v12, vcc, 0, v16, vcc
flat_store_dwordx4 v[11:12], v[7:10]
s_waitcnt vmcnt(0) lgkmcnt(0)
BB16_47:
s_or_b64 exec, exec, s[14:15]
BB16_48:
s_or_b64 exec, exec, s[12:13]
BB16_49:
s_or_b64 exec, exec, s[10:11]
BB16_50:
s_or_b64 exec, exec, s[8:9]
v_min_u32 v6, 0x100, v1
v_subrev_i32 v1, vcc, v6, v1
v_cmp_ne_i32_e32 vcc, 0, v1
s_and_b64 vcc, exec, vcc
s_cbranch_vccnz BB16_30
BB16_51:
s_endpgm
.section .AMDGPU.csdata
.section .AMDGPU.runtime_metadata
.byte 4
.byte 6
.long 13
.ascii "kernel_round3"
.byte 7
.byte 9
.long 4
.byte 10
.long 4
.byte 11
.long 4
.ascii "uint"
.byte 13
.byte 0
.byte 14
.short 7
.byte 16
.byte 0
.byte 8
.byte 7
.byte 9
.long 8
.byte 10
.long 8
.byte 11
.long 5
.ascii "char*"
.byte 13
.byte 1
.byte 14
.short 1
.byte 16
.byte 0
.byte 15
.byte 1
.byte 8
.byte 7
.byte 9
.long 8
.byte 10
.long 8
.byte 11
.long 5
.ascii "char*"
.byte 13
.byte 1
.byte 14
.short 1
.byte 16
.byte 0
.byte 15
.byte 1
.byte 8
.byte 7
.byte 9
.long 8
.byte 10
.long 8
.byte 11
.long 5
.ascii "uint*"
.byte 13
.byte 1
.byte 14
.short 7
.byte 16
.byte 0
.byte 15
.byte 1
.byte 8
.byte 7
.byte 9
.long 8
.byte 10
.long 8
.byte 11
.long 5
.ascii "uint*"
.byte 13
.byte 1
.byte 14
.short 7
.byte 16
.byte 0
.byte 15
.byte 1
.byte 8
.byte 7
.byte 9
.long 8
.byte 10
.long 8
.byte 11
.long 5
.ascii "uint*"
.byte 13
.byte 1
.byte 14
.short 7
.byte 16
.byte 0
.byte 15
.byte 1
.byte 8
.byte 5
.section .AMDGPU.config
.text
.globl kernel_round4
.p2align 8
.type kernel_round4,@function
.amdgpu_hsa_kernel kernel_round4
kernel_round4:
.amd_kernel_code_t
max_scratch_backing_memory_byte_size = 0
.dx10clamp
enable_ordered_append_gds = 0
private_element_size = 1
workitem_private_segment_byte_size = 0
workgroup_group_segment_byte_size = 19252
gds_segment_byte_size = 0
workgroup_fbarrier_count = 0
wavefront_sgpr_count = 30
workitem_vgpr_count = 20
group_segment_alignment = 4
private_segment_alignment = 4
.end_amd_kernel_code_t
s_cmp_gt_u32 s12, 0xfff
s_cbranch_scc1 BB17_51
v_mov_b32 v1, 0x100
v_cmp_gt_u32_e32 vcc, v1, v0
s_and_saveexec_b64 s[0:1], vcc
s_xor_b64 s[0:1], exec, s[0:1]
s_cbranch_execz BB17_10
v_add_i32 v1, vcc, 0xffffff00, v0
v_lshlrev_b32 v2, 2, v0
s_mov_b64 s[2:3], 0
s_mov_b32 m0, -1
BB17_12:
v_mov_b32 v3, 0x2ac
ds_write_b32 v2, v3
v_add_i32 v1, vcc, 0x100, v1
v_add_i32 v2, vcc, 0x400, v2
s_waitcnt lgkmcnt(0)
v_mov_b32 v3, 0xffffff00
v_cmp_gt_u32_e32 vcc, v3, v1
s_or_b64 s[2:3], vcc, s[2:3]
s_andn2_b64 exec, exec, s[2:3]
s_cbranch_execnz BB17_12
s_or_b64 exec, exec, s[2:3]
BB17_10:
s_or_b64 exec, exec, s[0:1]
s_load_dwordx2 s[6:7], s[8:9], 0x38
s_load_dwordx2 s[2:3], s[8:9], 0x40
s_load_dwordx2 s[10:11], s[8:9], 0x48
s_load_dwordx2 s[4:5], s[8:9], 0x50
v_mov_b32 v1, 0x2ac
v_cmp_gt_u32_e32 vcc, v1, v0
v_mov_b32 v1, 0
s_waitcnt lgkmcnt(0)
s_and_saveexec_b64 s[0:1], vcc
s_xor_b64 s[0:1], exec, s[0:1]
s_cbranch_execz BB17_19
v_sub_i32 v1, vcc, 0x2ab, v0
v_lshrrev_b32 v5, 8, v1
v_add_i32 v3, vcc, 1, v5
v_cmp_gt_u32_e32 vcc, 64, v3
v_cndmask_b32 v4, 0, -1, vcc
v_mov_b32 v1, v0
v_cmp_lt_u32_e32 vcc, 63, v3
s_and_saveexec_b64 s[8:9], vcc
s_xor_b64 s[8:9], exec, s[8:9]
s_cbranch_execz BB17_6
v_and_b32 v2, 63, v3
v_subrev_i32 v3, vcc, v2, v3
v_mov_b32 v4, -1
v_mov_b32 v1, v0
v_cmp_ne_i32_e32 vcc, 0, v3
s_and_saveexec_b64 s[14:15], vcc
s_xor_b64 s[14:15], exec, s[14:15]
s_cbranch_execz BB17_5
v_lshlrev_b32 v1, 8, v5
v_add_i32 v1, vcc, v1, v0
v_add_i32 v1, vcc, 0x100, v1
v_lshlrev_b32 v4, 8, v2
v_subrev_i32 v1, vcc, v4, v1
s_mov_b64 s[16:17], 0
v_mov_b32 v4, 0
s_mov_b32 m0, -1
BB17_8:
v_or_b32 v5, v4, v0
v_mov_b32 v6, 0x2ac
v_lshlrev_b32 v5, 1, v5
v_add_i32 v3, vcc, 0xffffffc0, v3
v_add_i32 v4, vcc, 0x4000, v4
v_cmp_eq_i32_e32 vcc, 0, v3
ds_write_b16 v5, v6 offset:1024
ds_write_b16 v5, v6 offset:1536
ds_write_b16 v5, v6 offset:2048
ds_write_b16 v5, v6 offset:2560
ds_write_b16 v5, v6 offset:3072
ds_write_b16 v5, v6 offset:3584
ds_write_b16 v5, v6 offset:4096
ds_write_b16 v5, v6 offset:4608
ds_write_b16 v5, v6 offset:5120
ds_write_b16 v5, v6 offset:5632
ds_write_b16 v5, v6 offset:6144
ds_write_b16 v5, v6 offset:6656
ds_write_b16 v5, v6 offset:7168
ds_write_b16 v5, v6 offset:7680
ds_write_b16 v5, v6 offset:8192
ds_write_b16 v5, v6 offset:8704
ds_write_b16 v5, v6 offset:9216
ds_write_b16 v5, v6 offset:9728
ds_write_b16 v5, v6 offset:10240
ds_write_b16 v5, v6 offset:10752
ds_write_b16 v5, v6 offset:11264
ds_write_b16 v5, v6 offset:11776
ds_write_b16 v5, v6 offset:12288
ds_write_b16 v5, v6 offset:12800
ds_write_b16 v5, v6 offset:13312
ds_write_b16 v5, v6 offset:13824
ds_write_b16 v5, v6 offset:14336
ds_write_b16 v5, v6 offset:14848
ds_write_b16 v5, v6 offset:15360
ds_write_b16 v5, v6 offset:15872
ds_write_b16 v5, v6 offset:16384
ds_write_b16 v5, v6 offset:16896
ds_write_b16 v5, v6 offset:17408
ds_write_b16 v5, v6 offset:17920
ds_write_b16 v5, v6 offset:18432
ds_write_b16 v5, v6 offset:18944
ds_write_b16 v5, v6 offset:19456
ds_write_b16 v5, v6 offset:19968
ds_write_b16 v5, v6 offset:20480
ds_write_b16 v5, v6 offset:20992
ds_write_b16 v5, v6 offset:21504
ds_write_b16 v5, v6 offset:22016
ds_write_b16 v5, v6 offset:22528
ds_write_b16 v5, v6 offset:23040
ds_write_b16 v5, v6 offset:23552
ds_write_b16 v5, v6 offset:24064
ds_write_b16 v5, v6 offset:24576
ds_write_b16 v5, v6 offset:25088
ds_write_b16 v5, v6 offset:25600
ds_write_b16 v5, v6 offset:26112
ds_write_b16 v5, v6 offset:26624
ds_write_b16 v5, v6 offset:27136
ds_write_b16 v5, v6 offset:27648
ds_write_b16 v5, v6 offset:28160
ds_write_b16 v5, v6 offset:28672
ds_write_b16 v5, v6 offset:29184
ds_write_b16 v5, v6 offset:29696
ds_write_b16 v5, v6 offset:30208
ds_write_b16 v5, v6 offset:30720
ds_write_b16 v5, v6 offset:31232
ds_write_b16 v5, v6 offset:31744
ds_write_b16 v5, v6 offset:32256
ds_write_b16 v5, v6 offset:32768
ds_write_b16 v5, v6 offset:33280
s_or_b64 s[16:17], vcc, s[16:17]
s_waitcnt lgkmcnt(0)
s_andn2_b64 exec, exec, s[16:17]
s_cbranch_execnz BB17_8
s_or_b64 exec, exec, s[16:17]
v_cmp_ne_i32_e32 vcc, 0, v2
v_cndmask_b32 v4, 0, -1, vcc
BB17_5:
s_or_b64 exec, exec, s[14:15]
BB17_6:
s_or_b64 exec, exec, s[8:9]
v_cmp_ne_i32_e32 vcc, 0, v4
s_and_saveexec_b64 s[8:9], vcc
s_xor_b64 s[8:9], exec, s[8:9]
s_cbranch_execz BB17_16
v_lshlrev_b32 v2, 1, v1
v_add_i32 v2, vcc, 0x400, v2
s_mov_b64 s[14:15], 0
s_mov_b32 m0, -1
BB17_14:
v_mov_b32 v3, 0x2ac
ds_write_b16 v2, v3
v_add_i32 v1, vcc, 0x100, v1
v_add_i32 v2, vcc, 0x200, v2
s_waitcnt lgkmcnt(0)
v_mov_b32 v3, 0x2ab
v_cmp_lt_u32_e32 vcc, v3, v1
s_or_b64 s[14:15], vcc, s[14:15]
s_andn2_b64 exec, exec, s[14:15]
s_cbranch_execnz BB17_14
s_or_b64 exec, exec, s[14:15]
BB17_16:
s_or_b64 exec, exec, s[8:9]
v_mov_b32 v1, 0
v_cmp_eq_i32_e32 vcc, 0, v0
s_and_saveexec_b64 s[8:9], vcc
s_xor_b64 s[8:9], exec, s[8:9]
s_cbranch_execz BB17_18
s_mul_i32 s13, s12, 0x55555555
s_lshr_b32 s14, s12, 1
s_add_i32 s13, s13, s14
s_lshr_b32 s14, s12, 3
s_sub_i32 s13, s13, s14
s_lshr_b32 s13, s13, 30
s_sub_i32 s14, s12, s13
s_mul_i32 s14, s14, 0xaaaaaaab
s_ashr_i32 s15, s14, 31
s_lshl_b64 s[14:15], s[14:15], 2
s_add_u32 s10, s10, s14
s_addc_u32 s11, s11, s15
v_mov_b32 v2, s11
v_mov_b32 v1, s10
flat_load_dword v1, v[1:2]
v_mul_u32_u24 v3, 10, s13
v_and_b32 v3, 30, v3
v_mov_b32 v2, 0
s_mov_b32 m0, -1
s_waitcnt vmcnt(0) lgkmcnt(0)
v_bfe_u32 v1, v1, v3, 10
v_min_u32 v1, 0x2ac, v1
ds_write_b32 v2, v1 offset:2392
s_waitcnt lgkmcnt(0)
BB17_18:
s_or_b64 exec, exec, s[8:9]
BB17_19:
s_or_b64 exec, exec, s[0:1]
s_barrier
v_cmp_ne_i32_e32 vcc, 0, v0
s_and_saveexec_b64 s[0:1], vcc
s_xor_b64 s[0:1], exec, s[0:1]
v_mov_b32 v1, 0
s_mov_b32 m0, -1
ds_read_b32 v1, v1 offset:2392
s_waitcnt lgkmcnt(0)
BB17_21:
s_or_b64 exec, exec, s[0:1]
s_barrier
v_cmp_eq_i32_e32 vcc, 0, v0
s_and_saveexec_b64 s[0:1], vcc
s_xor_b64 s[0:1], exec, s[0:1]
v_mov_b32 v2, 0
s_mov_b32 m0, -1
ds_write_b32 v2, v2 offset:2392
s_waitcnt lgkmcnt(0)
BB17_23:
s_or_b64 exec, exec, s[0:1]
s_barrier
v_cmp_lt_u32_e32 vcc, v0, v1
s_and_saveexec_b64 s[8:9], vcc
s_xor_b64 s[8:9], exec, s[8:9]
s_cbranch_execz BB17_27
v_lshlrev_b32 v3, 2, v0
v_lshlrev_b32 v2, 1, v0
s_movk_i32 s10, 0x400
s_mul_i32 s0, s12, 0x5580
v_lshlrev_b32 v4, 5, v0
v_add_i32 v2, vcc, s10, v2
v_add_i32 v3, vcc, 0x95c, v3
v_add_i32 v4, vcc, s0, v4
s_mov_b64 s[14:15], 0
v_mov_b32 v5, v0
s_mov_b32 m0, -1
BB17_25:
v_ashrrev_i32 v7, 31, v4
v_add_i32 v6, vcc, s6, v4
v_mov_b32 v8, s7
v_addc_u32 v7, vcc, v7, v8, vcc
v_add_i32 v8, vcc, 4, v6
v_addc_u32 v9, vcc, 0, v7, vcc
flat_load_dword v11, v[8:9]
v_add_i32 v8, vcc, 8, v6
v_addc_u32 v9, vcc, 0, v7, vcc
flat_load_dword v12, v[8:9]
v_add_i32 v8, vcc, 12, v6
v_addc_u32 v9, vcc, 0, v7, vcc
flat_load_dword v10, v[6:7]
s_nop 0
flat_load_dword v13, v[8:9]
v_add_i32 v8, vcc, 16, v6
v_addc_u32 v9, vcc, 0, v7, vcc
flat_load_dword v6, v[8:9]
v_add_i32 v4, vcc, 0x2000, v4
s_waitcnt vmcnt(4) lgkmcnt(0)
ds_write_b32 v3, v11 offset:2736
s_waitcnt vmcnt(3)
ds_write_b32 v3, v12 offset:5472
s_waitcnt vmcnt(2)
v_and_b32 v8, 0xf000, v10
v_bfe_u32 v7, v10, 16, 4
v_lshrrev_b32 v8, 8, v8
v_or_b32 v7, v8, v7
ds_write_b32 v3, v10
v_lshlrev_b32 v7, 2, v7
s_waitcnt vmcnt(1)
ds_write_b32 v3, v13 offset:8208
s_waitcnt vmcnt(0)
ds_write_b32 v3, v6 offset:10944
s_waitcnt lgkmcnt(0)
ds_wrxchg_rtn_b32 v6, v7, v5
s_waitcnt lgkmcnt(0)
v_add_i32 v5, vcc, 0x100, v5
v_add_i32 v3, vcc, s10, v3
v_cmp_ge_u32 s[0:1], v5, v1
ds_write_b16 v2, v6
v_add_i32 v2, vcc, 0x200, v2
s_or_b64 s[14:15], s[0:1], s[14:15]
s_waitcnt lgkmcnt(0)
s_andn2_b64 exec, exec, s[14:15]
s_cbranch_execnz BB17_25
s_or_b64 exec, exec, s[14:15]
BB17_27:
s_or_b64 exec, exec, s[8:9]
s_barrier
v_mov_b32 v1, 0x2ac
v_cmp_gt_u32_e32 vcc, v1, v0
s_and_saveexec_b64 s[0:1], vcc
s_xor_b64 s[0:1], exec, s[0:1]
s_cbranch_execz BB17_32
s_mov_b64 s[6:7], 0
v_mov_b32 v1, v0
BB17_34:
v_lshlrev_b32 v2, 1, v1
s_mov_b32 m0, -1
ds_read_u16 v2, v2 offset:1024
v_mov_b32 v3, 0x2ac
s_waitcnt lgkmcnt(0)
v_cmp_gt_u32_e32 vcc, v3, v2
s_and_saveexec_b64 s[8:9], vcc
s_xor_b64 s[8:9], exec, s[8:9]
s_cbranch_execz BB17_40
s_mov_b64 s[10:11], 0
BB17_36:
v_mov_b32 v3, 1
v_mov_b32 v4, 0
s_mov_b32 m0, -1
ds_add_rtn_u32 v3, v4, v3 offset:2392
v_mov_b32 v4, 0x31a
s_waitcnt lgkmcnt(0)
v_cmp_gt_u32_e32 vcc, v4, v3
s_and_saveexec_b64 s[14:15], vcc
s_xor_b64 s[14:15], exec, s[14:15]
v_lshlrev_b32 v3, 1, v3
s_mov_b32 m0, -1
ds_write_b16 v3, v2 offset:16076
s_waitcnt lgkmcnt(0)
v_lshlrev_b32 v2, 1, v2
ds_read_u16 v2, v2 offset:1024
ds_write_b16 v3, v1 offset:17664
v_mov_b32 v3, 0x2ab
s_waitcnt lgkmcnt(0)
v_cmp_lt_u32_e32 vcc, v3, v2
s_or_b64 s[10:11], vcc, s[10:11]
BB17_38:
s_or_b64 exec, exec, s[14:15]
s_or_b64 s[10:11], s[14:15], s[10:11]
s_andn2_b64 exec, exec, s[10:11]
s_cbranch_execnz BB17_36
s_or_b64 exec, exec, s[10:11]
BB17_40:
s_or_b64 exec, exec, s[8:9]
v_add_i32 v1, vcc, 0x100, v1
v_mov_b32 v2, 0x2ab
v_cmp_lt_u32_e32 vcc, v2, v1
s_or_b64 s[6:7], vcc, s[6:7]
s_andn2_b64 exec, exec, s[6:7]
s_cbranch_execnz BB17_34
s_or_b64 exec, exec, s[6:7]
BB17_32:
s_or_b64 exec, exec, s[0:1]
s_barrier
v_mov_b32 v1, 0
s_mov_b32 m0, -1
ds_read_b32 v1, v1 offset:2392
s_mov_b32 s16, 0
s_waitcnt lgkmcnt(0)
v_min_u32 v1, 0x31a, v1
v_cmp_eq_i32_e32 vcc, 0, v1
s_and_b64 vcc, exec, vcc
s_cbranch_vccnz BB17_51
s_mov_b32 s17, s16
s_mov_b32 s18, s16
s_mov_b32 s19, s16
s_mov_b32 s20, s16
s_mov_b32 s21, s16
s_mov_b32 s22, s16
s_mov_b32 s23, s16
v_mov_b32 v3, s16
v_mov_b32 v4, s17
v_mov_b32 v5, s18
v_not_b32 v2, v0
v_mov_b32 v6, s19
v_mov_b32 v7, s20
v_mov_b32 v8, s21
v_mov_b32 v9, s22
v_mov_b32 v10, s23
s_movk_i32 s0, 0x95c
s_lshl_b32 s1, s12, 20
s_mov_b32 s6, 0x55555555
s_mov_b32 s7, 0xaaaaaaab
BB17_30:
v_mov_b32 v6, 0x2ac
v_cmp_lt_u32_e32 vcc, v0, v1
s_and_saveexec_b64 s[8:9], vcc
s_xor_b64 s[8:9], exec, s[8:9]
v_add_i32 v3, vcc, v1, v2
v_lshlrev_b32 v3, 1, v3
s_mov_b32 m0, -1
ds_read_u16 v6, v3 offset:17664
ds_read_u16 v3, v3 offset:16076
s_waitcnt lgkmcnt(0)
v_lshlrev_b32 v4, 2, v6
v_lshlrev_b32 v5, 2, v3
v_add_i32 v4, vcc, s0, v4
v_add_i32 v5, vcc, s0, v5
BB17_42:
s_or_b64 exec, exec, s[8:9]
v_mov_b32 v7, 0x2ac
v_cmp_gt_u32_e32 vcc, v7, v6
s_and_saveexec_b64 s[8:9], vcc
s_xor_b64 s[8:9], exec, s[8:9]
s_cbranch_execz BB17_50
s_mov_b32 m0, -1
ds_read_b32 v7, v4
ds_read_b32 v15, v5
ds_read_b32 v11, v4 offset:2736
ds_read_b32 v16, v5 offset:2736
ds_read_b32 v12, v4 offset:5472
ds_read_b32 v17, v5 offset:5472
ds_read_b32 v13, v4 offset:8208
ds_read_b32 v18, v5 offset:8208
ds_read_b32 v14, v4 offset:10944
ds_read_b32 v19, v5 offset:10944
s_waitcnt lgkmcnt(0)
v_xor_b32 v7, v7, v15
v_xor_b32 v11, v11, v16
v_lshrrev_b32 v7, 24, v7
v_lshlrev_b32 v15, 8, v11
v_or_b32 v15, v15, v7
v_lshlrev_b32 v7, 10, v3
v_and_b32 v6, 0x3ff, v6
v_and_b32 v7, 0xffc00, v7
v_or_b32 v6, s1, v6
v_or_b32 v16, v11, v15
v_xor_b32 v12, v12, v17
v_xor_b32 v13, v13, v18
v_xor_b32 v14, v14, v19
v_or_b32 v7, v7, v6
v_cmp_ne_i32_e32 vcc, 0, v16
s_and_saveexec_b64 s[10:11], vcc
s_xor_b64 s[10:11], exec, s[10:11]
s_cbranch_execz BB17_49
v_and_b32 v6, 0xfff, v15
v_mul_lo_i32 v16, s6, v6
v_bfe_u32 v17, v15, 1, 11
v_bfe_u32 v15, v15, 3, 9
v_add_i32 v16, vcc, v16, v17
v_sub_i32 v15, vcc, v16, v15
v_lshrrev_b32 v16, 30, v15
v_sub_i32 v15, vcc, v6, v16
v_mul_lo_i32 v15, s7, v15
v_mul_u32_u24 v19, 10, v16
v_ashrrev_i32 v16, 31, v15
v_lshlrev_b64 v[15:16], 2, v[15:16]
v_add_i32 v17, vcc, s4, v15
v_mov_b32 v15, s5
v_addc_u32 v18, vcc, v16, v15, vcc
v_and_b32 v15, 30, v19
v_lshlrev_b32 v16, v15, 1
flat_atomic_add v16, v[17:18], v16 glc
s_waitcnt vmcnt(0) lgkmcnt(0)
v_bfe_u32 v15, v16, v15, 10
v_mov_b32 v16, 0x2ac
v_cmp_gt_u32_e32 vcc, v16, v15
s_and_saveexec_b64 s[12:13], vcc
s_xor_b64 s[12:13], exec, s[12:13]
s_cbranch_execz BB17_48
v_mov_b32 v16, 0x2ac
v_mad_i32_i24 v6, v16, v6, v15
v_lshlrev_b32 v6, 5, v6
v_ashrrev_i32 v16, 31, v6
v_add_i32 v15, vcc, s2, v6
v_mov_b32 v6, s3
v_addc_u32 v16, vcc, v16, v6, vcc
v_cmp_ne_i64_e32 vcc, 0, v[15:16]
s_and_saveexec_b64 s[14:15], vcc
s_xor_b64 s[14:15], exec, s[14:15]
flat_store_dwordx4 v[15:16], v[11:14]
s_waitcnt vmcnt(0) lgkmcnt(0)
v_add_i32 v11, vcc, 16, v15
v_addc_u32 v12, vcc, 0, v16, vcc
flat_store_dwordx4 v[11:12], v[7:10]
s_waitcnt vmcnt(0) lgkmcnt(0)
BB17_47:
s_or_b64 exec, exec, s[14:15]
BB17_48:
s_or_b64 exec, exec, s[12:13]
BB17_49:
s_or_b64 exec, exec, s[10:11]
BB17_50:
s_or_b64 exec, exec, s[8:9]
v_min_u32 v6, 0x100, v1
v_subrev_i32 v1, vcc, v6, v1
v_cmp_ne_i32_e32 vcc, 0, v1
s_and_b64 vcc, exec, vcc
s_cbranch_vccnz BB17_30
BB17_51:
s_endpgm
.section .AMDGPU.csdata
.section .AMDGPU.runtime_metadata
.byte 4
.byte 6
.long 13
.ascii "kernel_round4"
.byte 7
.byte 9
.long 4
.byte 10
.long 4
.byte 11
.long 4
.ascii "uint"
.byte 13
.byte 0
.byte 14
.short 7
.byte 16
.byte 0
.byte 8
.byte 7
.byte 9
.long 8
.byte 10
.long 8
.byte 11
.long 5
.ascii "char*"
.byte 13
.byte 1
.byte 14
.short 1
.byte 16
.byte 0
.byte 15
.byte 1
.byte 8
.byte 7
.byte 9
.long 8
.byte 10
.long 8
.byte 11
.long 5
.ascii "char*"
.byte 13
.byte 1
.byte 14
.short 1
.byte 16
.byte 0
.byte 15
.byte 1
.byte 8
.byte 7
.byte 9
.long 8
.byte 10
.long 8
.byte 11
.long 5
.ascii "uint*"
.byte 13
.byte 1
.byte 14
.short 7
.byte 16
.byte 0
.byte 15
.byte 1
.byte 8
.byte 7
.byte 9
.long 8
.byte 10
.long 8
.byte 11
.long 5
.ascii "uint*"
.byte 13
.byte 1
.byte 14
.short 7
.byte 16
.byte 0
.byte 15
.byte 1
.byte 8
.byte 7
.byte 9
.long 8
.byte 10
.long 8
.byte 11
.long 5
.ascii "uint*"
.byte 13
.byte 1
.byte 14
.short 7
.byte 16
.byte 0
.byte 15
.byte 1
.byte 8
.byte 5
.section .AMDGPU.config
.text
.globl kernel_round5
.p2align 8
.type kernel_round5,@function
.amdgpu_hsa_kernel kernel_round5
kernel_round5:
.amd_kernel_code_t
max_scratch_backing_memory_byte_size = 0
.dx10clamp
enable_ordered_append_gds = 0
private_element_size = 1
workitem_private_segment_byte_size = 28
workgroup_group_segment_byte_size = 16516
gds_segment_byte_size = 0
workgroup_fbarrier_count = 0
wavefront_sgpr_count = 30
workitem_vgpr_count = 20
group_segment_alignment = 4
private_segment_alignment = 4
.end_amd_kernel_code_t
s_add_u32 s10, s10, s13
s_lshr_b32 flat_scratch_hi, s10, 8
s_mov_b32 flat_scratch_lo, s11
s_cmp_gt_u32 s12, 0xfff
s_cbranch_scc1 BB18_54
v_mov_b32 v1, 0x100
v_cmp_gt_u32_e32 vcc, v1, v0
s_and_saveexec_b64 s[16:17], vcc
s_xor_b64 s[16:17], exec, s[16:17]
s_cbranch_execz BB18_10
v_add_i32 v1, vcc, 0xffffff00, v0
v_lshlrev_b32 v2, 2, v0
s_mov_b64 s[4:5], 0
s_mov_b32 m0, -1
BB18_12:
v_mov_b32 v3, 0x2ac
ds_write_b32 v2, v3
v_add_i32 v1, vcc, 0x100, v1
v_add_i32 v2, vcc, 0x400, v2
s_waitcnt lgkmcnt(0)
v_mov_b32 v3, 0xffffff00
v_cmp_gt_u32_e32 vcc, v3, v1
s_or_b64 s[4:5], vcc, s[4:5]
s_andn2_b64 exec, exec, s[4:5]
s_cbranch_execnz BB18_12
s_or_b64 exec, exec, s[4:5]
BB18_10:
s_or_b64 exec, exec, s[16:17]
s_load_dwordx2 s[10:11], s[8:9], 0x38
s_load_dwordx2 s[4:5], s[8:9], 0x40
s_load_dwordx2 s[14:15], s[8:9], 0x48
s_load_dwordx2 s[6:7], s[8:9], 0x50
v_mov_b32 v1, 0x2ac
v_cmp_gt_u32_e32 vcc, v1, v0
v_mov_b32 v1, 0
s_waitcnt lgkmcnt(0)
s_and_saveexec_b64 s[8:9], vcc
s_xor_b64 s[8:9], exec, s[8:9]
s_cbranch_execz BB18_19
v_sub_i32 v1, vcc, 0x2ab, v0
v_lshrrev_b32 v5, 8, v1
v_add_i32 v3, vcc, 1, v5
v_cmp_gt_u32_e32 vcc, 64, v3
v_cndmask_b32 v4, 0, -1, vcc
v_mov_b32 v1, v0
v_cmp_lt_u32_e32 vcc, 63, v3
s_and_saveexec_b64 s[16:17], vcc
s_xor_b64 s[16:17], exec, s[16:17]
s_cbranch_execz BB18_6
v_and_b32 v2, 63, v3
v_subrev_i32 v3, vcc, v2, v3
v_mov_b32 v4, -1
v_mov_b32 v1, v0
v_cmp_ne_i32_e32 vcc, 0, v3
s_and_saveexec_b64 s[18:19], vcc
s_xor_b64 s[18:19], exec, s[18:19]
s_cbranch_execz BB18_5
v_lshlrev_b32 v1, 8, v5
v_add_i32 v1, vcc, v1, v0
v_add_i32 v1, vcc, 0x100, v1
v_lshlrev_b32 v4, 8, v2
v_subrev_i32 v1, vcc, v4, v1
s_mov_b64 s[20:21], 0
v_mov_b32 v4, 0
s_mov_b32 m0, -1
BB18_8:
v_or_b32 v5, v4, v0
v_mov_b32 v6, 0x2ac
v_lshlrev_b32 v5, 1, v5
v_add_i32 v3, vcc, 0xffffffc0, v3
v_add_i32 v4, vcc, 0x4000, v4
v_cmp_eq_i32_e32 vcc, 0, v3
ds_write_b16 v5, v6 offset:1024
ds_write_b16 v5, v6 offset:1536
ds_write_b16 v5, v6 offset:2048
ds_write_b16 v5, v6 offset:2560
ds_write_b16 v5, v6 offset:3072
ds_write_b16 v5, v6 offset:3584
ds_write_b16 v5, v6 offset:4096
ds_write_b16 v5, v6 offset:4608
ds_write_b16 v5, v6 offset:5120
ds_write_b16 v5, v6 offset:5632
ds_write_b16 v5, v6 offset:6144
ds_write_b16 v5, v6 offset:6656
ds_write_b16 v5, v6 offset:7168
ds_write_b16 v5, v6 offset:7680
ds_write_b16 v5, v6 offset:8192
ds_write_b16 v5, v6 offset:8704
ds_write_b16 v5, v6 offset:9216
ds_write_b16 v5, v6 offset:9728
ds_write_b16 v5, v6 offset:10240
ds_write_b16 v5, v6 offset:10752
ds_write_b16 v5, v6 offset:11264
ds_write_b16 v5, v6 offset:11776
ds_write_b16 v5, v6 offset:12288
ds_write_b16 v5, v6 offset:12800
ds_write_b16 v5, v6 offset:13312
ds_write_b16 v5, v6 offset:13824
ds_write_b16 v5, v6 offset:14336
ds_write_b16 v5, v6 offset:14848
ds_write_b16 v5, v6 offset:15360
ds_write_b16 v5, v6 offset:15872
ds_write_b16 v5, v6 offset:16384
ds_write_b16 v5, v6 offset:16896
ds_write_b16 v5, v6 offset:17408
ds_write_b16 v5, v6 offset:17920
ds_write_b16 v5, v6 offset:18432
ds_write_b16 v5, v6 offset:18944
ds_write_b16 v5, v6 offset:19456
ds_write_b16 v5, v6 offset:19968
ds_write_b16 v5, v6 offset:20480
ds_write_b16 v5, v6 offset:20992
ds_write_b16 v5, v6 offset:21504
ds_write_b16 v5, v6 offset:22016
ds_write_b16 v5, v6 offset:22528
ds_write_b16 v5, v6 offset:23040
ds_write_b16 v5, v6 offset:23552
ds_write_b16 v5, v6 offset:24064
ds_write_b16 v5, v6 offset:24576
ds_write_b16 v5, v6 offset:25088
ds_write_b16 v5, v6 offset:25600
ds_write_b16 v5, v6 offset:26112
ds_write_b16 v5, v6 offset:26624
ds_write_b16 v5, v6 offset:27136
ds_write_b16 v5, v6 offset:27648
ds_write_b16 v5, v6 offset:28160
ds_write_b16 v5, v6 offset:28672
ds_write_b16 v5, v6 offset:29184
ds_write_b16 v5, v6 offset:29696
ds_write_b16 v5, v6 offset:30208
ds_write_b16 v5, v6 offset:30720
ds_write_b16 v5, v6 offset:31232
ds_write_b16 v5, v6 offset:31744
ds_write_b16 v5, v6 offset:32256
ds_write_b16 v5, v6 offset:32768
ds_write_b16 v5, v6 offset:33280
s_or_b64 s[20:21], vcc, s[20:21]
s_waitcnt lgkmcnt(0)
s_andn2_b64 exec, exec, s[20:21]
s_cbranch_execnz BB18_8
s_or_b64 exec, exec, s[20:21]
v_cmp_ne_i32_e32 vcc, 0, v2
v_cndmask_b32 v4, 0, -1, vcc
BB18_5:
s_or_b64 exec, exec, s[18:19]
BB18_6:
s_or_b64 exec, exec, s[16:17]
v_cmp_ne_i32_e32 vcc, 0, v4
s_and_saveexec_b64 s[16:17], vcc
s_xor_b64 s[16:17], exec, s[16:17]
s_cbranch_execz BB18_16
v_lshlrev_b32 v2, 1, v1
v_add_i32 v2, vcc, 0x400, v2
s_mov_b64 s[18:19], 0
s_mov_b32 m0, -1
BB18_14:
v_mov_b32 v3, 0x2ac
ds_write_b16 v2, v3
v_add_i32 v1, vcc, 0x100, v1
v_add_i32 v2, vcc, 0x200, v2
s_waitcnt lgkmcnt(0)
v_mov_b32 v3, 0x2ab
v_cmp_lt_u32_e32 vcc, v3, v1
s_or_b64 s[18:19], vcc, s[18:19]
s_andn2_b64 exec, exec, s[18:19]
s_cbranch_execnz BB18_14
s_or_b64 exec, exec, s[18:19]
BB18_16:
s_or_b64 exec, exec, s[16:17]
v_mov_b32 v1, 0
v_cmp_eq_i32_e32 vcc, 0, v0
s_and_saveexec_b64 s[16:17], vcc
s_xor_b64 s[16:17], exec, s[16:17]
s_cbranch_execz BB18_18
s_mul_i32 s18, s12, 0x55555555
s_lshr_b32 s19, s12, 1
s_add_i32 s18, s18, s19
s_lshr_b32 s19, s12, 3
s_sub_i32 s18, s18, s19
s_lshr_b32 s20, s18, 30
s_sub_i32 s18, s12, s20
s_mul_i32 s18, s18, 0xaaaaaaab
s_ashr_i32 s19, s18, 31
s_lshl_b64 s[18:19], s[18:19], 2
s_add_u32 s14, s14, s18
s_addc_u32 s15, s15, s19
v_mov_b32 v2, s15
v_mov_b32 v1, s14
flat_load_dword v1, v[1:2]
v_mul_u32_u24 v3, 10, s20
v_and_b32 v3, 30, v3
v_mov_b32 v2, 0
s_mov_b32 m0, -1
s_waitcnt vmcnt(0) lgkmcnt(0)
v_bfe_u32 v1, v1, v3, 10
v_min_u32 v1, 0x2ac, v1
ds_write_b32 v2, v1 offset:2392
s_waitcnt lgkmcnt(0)
BB18_18:
s_or_b64 exec, exec, s[16:17]
BB18_19:
s_or_b64 exec, exec, s[8:9]
s_barrier
v_cmp_ne_i32_e32 vcc, 0, v0
s_and_saveexec_b64 s[8:9], vcc
s_xor_b64 s[8:9], exec, s[8:9]
v_mov_b32 v1, 0
s_mov_b32 m0, -1
ds_read_b32 v1, v1 offset:2392
s_waitcnt lgkmcnt(0)
BB18_21:
s_or_b64 exec, exec, s[8:9]
s_barrier
v_cmp_eq_i32_e32 vcc, 0, v0
s_and_saveexec_b64 s[8:9], vcc
s_xor_b64 s[8:9], exec, s[8:9]
v_mov_b32 v2, 0
s_mov_b32 m0, -1
ds_write_b32 v2, v2 offset:2392
s_waitcnt lgkmcnt(0)
BB18_23:
s_or_b64 exec, exec, s[8:9]
s_barrier
v_cmp_lt_u32_e32 vcc, v0, v1
s_and_saveexec_b64 s[8:9], vcc
s_xor_b64 s[8:9], exec, s[8:9]
s_cbranch_execz BB18_30
v_lshlrev_b32 v2, 2, v0
s_mul_i32 s14, s12, 0x2ac
v_add_i32 v2, vcc, 0x95c, v2
s_mov_b64 s[16:17], 0
v_mov_b32 v3, v0
BB18_25:
v_add_i32 v4, vcc, s14, v3
v_lshlrev_b32 v4, 5, v4
v_ashrrev_i32 v6, 31, v4
v_add_i32 v5, vcc, s10, v4
v_mov_b32 v4, s11
v_addc_u32 v6, vcc, v6, v4, vcc
flat_load_dword v4, v[5:6]
v_add_i32 v7, vcc, 4, v5
v_mov_b32 v10, 0
v_addc_u32 v8, vcc, 0, v6, vcc
s_mov_b32 s15, 0
s_waitcnt vmcnt(0) lgkmcnt(0)
buffer_store_dword v4, v10, s[0:3], s13 offen
s_nop 0
flat_load_dword v9, v[7:8]
v_add_i32 v7, vcc, 8, v5
v_mov_b32 v10, 0
v_addc_u32 v8, vcc, 0, v6, vcc
s_waitcnt vmcnt(0) lgkmcnt(0)
buffer_store_dword v9, v10, s[0:3], s13 offen offset:4
s_waitcnt vmcnt(0) expcnt(0)
flat_load_dword v9, v[7:8]
v_add_i32 v7, vcc, 12, v5
v_mov_b32 v10, 0
v_addc_u32 v8, vcc, 0, v6, vcc
v_mov_b32 v5, 0
v_mov_b32 v6, v2
s_waitcnt vmcnt(0) lgkmcnt(0)
buffer_store_dword v9, v10, s[0:3], s13 offen offset:8
s_nop 0
flat_load_dword v8, v[7:8]
s_waitcnt vmcnt(1) expcnt(0)
v_mov_b32 v9, 0
v_mov_b32 v7, s15
s_waitcnt vmcnt(0) lgkmcnt(0)
buffer_store_dword v8, v9, s[0:3], s13 offen offset:12
s_waitcnt vmcnt(0) expcnt(0)
v_mov_b32 v8, v4
s_branch BB18_26
BB18_27:
buffer_load_dword v8, v7, s[0:3], s13 offen offset:4
v_add_i32 v6, vcc, 0xab0, v6
v_add_i32 v7, vcc, 4, v7
s_waitcnt vmcnt(0)
BB18_26:
v_add_i32 v5, vcc, 1, v5
v_cmp_lt_u32_e32 vcc, 3, v5
s_mov_b32 m0, -1
ds_write_b32 v6, v8
s_and_b64 vcc, exec, vcc
s_waitcnt lgkmcnt(0)
s_cbranch_vccz BB18_27
v_bfe_u32 v5, v4, 12, 4
v_and_b32 v4, 0xf0, v4
v_or_b32 v4, v5, v4
v_lshlrev_b32 v4, 2, v4
s_mov_b32 m0, -1
ds_wrxchg_rtn_b32 v4, v4, v3
v_lshlrev_b32 v5, 1, v3
s_waitcnt lgkmcnt(0)
v_add_i32 v3, vcc, 0x100, v3
v_add_i32 v2, vcc, 0x400, v2
v_cmp_ge_u32_e32 vcc, v3, v1
ds_write_b16 v5, v4 offset:1024
s_or_b64 s[16:17], vcc, s[16:17]
s_waitcnt lgkmcnt(0)
s_andn2_b64 exec, exec, s[16:17]
s_cbranch_execnz BB18_25
s_or_b64 exec, exec, s[16:17]
BB18_30:
s_or_b64 exec, exec, s[8:9]
s_barrier
v_mov_b32 v1, 0x2ac
v_cmp_gt_u32_e32 vcc, v1, v0
s_and_saveexec_b64 s[8:9], vcc
s_xor_b64 s[8:9], exec, s[8:9]
s_cbranch_execz BB18_35
s_mov_b64 s[10:11], 0
v_mov_b32 v1, v0
BB18_37:
v_lshlrev_b32 v2, 1, v1
s_mov_b32 m0, -1
ds_read_u16 v2, v2 offset:1024
v_mov_b32 v3, 0x2ac
s_waitcnt lgkmcnt(0)
v_cmp_gt_u32_e32 vcc, v3, v2
s_and_saveexec_b64 s[14:15], vcc
s_xor_b64 s[14:15], exec, s[14:15]
s_cbranch_execz BB18_43
s_mov_b64 s[16:17], 0
BB18_39:
v_mov_b32 v3, 1
v_mov_b32 v4, 0
s_mov_b32 m0, -1
ds_add_rtn_u32 v3, v4, v3 offset:2392
v_mov_b32 v4, 0x31a
s_waitcnt lgkmcnt(0)
v_cmp_gt_u32_e32 vcc, v4, v3
s_and_saveexec_b64 s[18:19], vcc
s_xor_b64 s[18:19], exec, s[18:19]
v_lshlrev_b32 v3, 1, v3
s_mov_b32 m0, -1
ds_write_b16 v3, v2 offset:13340
s_waitcnt lgkmcnt(0)
v_lshlrev_b32 v2, 1, v2
ds_read_u16 v2, v2 offset:1024
ds_write_b16 v3, v1 offset:14928
v_mov_b32 v3, 0x2ab
s_waitcnt lgkmcnt(0)
v_cmp_lt_u32_e32 vcc, v3, v2
s_or_b64 s[16:17], vcc, s[16:17]
BB18_41:
s_or_b64 exec, exec, s[18:19]
s_or_b64 s[16:17], s[18:19], s[16:17]
s_andn2_b64 exec, exec, s[16:17]
s_cbranch_execnz BB18_39
s_or_b64 exec, exec, s[16:17]
BB18_43:
s_or_b64 exec, exec, s[14:15]
v_add_i32 v1, vcc, 0x100, v1
v_mov_b32 v2, 0x2ab
v_cmp_lt_u32_e32 vcc, v2, v1
s_or_b64 s[10:11], vcc, s[10:11]
s_andn2_b64 exec, exec, s[10:11]
s_cbranch_execnz BB18_37
s_or_b64 exec, exec, s[10:11]
BB18_35:
s_or_b64 exec, exec, s[8:9]
s_barrier
v_mov_b32 v1, 0
s_mov_b32 m0, -1
ds_read_b32 v1, v1 offset:2392
s_mov_b32 s16, 0
s_waitcnt lgkmcnt(0)
v_min_u32 v1, 0x31a, v1
v_cmp_eq_i32_e32 vcc, 0, v1
s_and_b64 vcc, exec, vcc
s_cbranch_vccnz BB18_54
s_mov_b32 s17, s16
s_mov_b32 s18, s16
s_mov_b32 s19, s16
s_mov_b32 s20, s16
s_mov_b32 s21, s16
s_mov_b32 s22, s16
s_mov_b32 s23, s16
v_mov_b32 v3, s16
v_mov_b32 v4, s17
v_mov_b32 v5, s18
v_not_b32 v2, v0
v_mov_b32 v6, s19
v_mov_b32 v7, s20
v_mov_b32 v8, s21
v_mov_b32 v9, s22
v_mov_b32 v10, s23
s_movk_i32 s8, 0x95c
s_lshl_b32 s9, s12, 20
s_mov_b32 s10, 0x55555555
s_mov_b32 s11, 0xaaaaaaab
BB18_33:
v_mov_b32 v6, 0x2ac
v_cmp_lt_u32_e32 vcc, v0, v1
s_and_saveexec_b64 s[14:15], vcc
s_xor_b64 s[14:15], exec, s[14:15]
v_add_i32 v3, vcc, v1, v2
v_lshlrev_b32 v3, 1, v3
s_mov_b32 m0, -1
ds_read_u16 v6, v3 offset:14928
ds_read_u16 v3, v3 offset:13340
s_waitcnt lgkmcnt(0)
v_lshlrev_b32 v4, 2, v6
v_lshlrev_b32 v5, 2, v3
v_add_i32 v4, vcc, s8, v4
v_add_i32 v5, vcc, s8, v5
BB18_45:
s_or_b64 exec, exec, s[14:15]
v_mov_b32 v7, 0x2ac
v_cmp_gt_u32_e32 vcc, v7, v6
s_and_saveexec_b64 s[14:15], vcc
s_xor_b64 s[14:15], exec, s[14:15]
s_cbranch_execz BB18_53
s_mov_b32 m0, -1
ds_read_b32 v7, v4
ds_read_b32 v14, v5
ds_read_b32 v11, v4 offset:2736
ds_read_b32 v16, v5 offset:2736
ds_read_b32 v12, v4 offset:5472
ds_read_b32 v17, v5 offset:5472
ds_read_b32 v13, v4 offset:8208
ds_read_b32 v18, v5 offset:8208
s_waitcnt lgkmcnt(0)
v_xor_b32 v15, v7, v14
v_xor_b32 v19, v11, v16
v_xor_b32 v7, v12, v17
v_lshlrev_b32 v12, 24, v7
v_xor_b32 v14, v13, v18
v_lshrrev_b32 v13, 8, v19
v_or_b32 v12, v12, v13
v_lshlrev_b32 v13, 24, v14
v_lshrrev_b32 v7, 8, v7
v_and_b32 v6, 0x3ff, v6
v_or_b32 v13, v13, v7
v_lshlrev_b32 v7, 10, v3
v_lshlrev_b32 v11, 24, v19
v_lshrrev_b32 v16, 8, v15
v_and_b32 v7, 0xffc00, v7
v_or_b32 v6, s9, v6
v_or_b32 v7, v7, v6
v_or_b32 v6, v19, v15
v_or_b32 v11, v11, v16
v_lshrrev_b32 v14, 8, v14
v_cmp_ne_i32_e32 vcc, 0, v6
s_and_saveexec_b64 s[16:17], vcc
s_xor_b64 s[16:17], exec, s[16:17]
s_cbranch_execz BB18_52
v_lshrrev_b32 v15, 24, v15
v_and_b32 v6, 0xf0f, v16
v_and_b32 v15, 0xf0, v15
v_or_b32 v6, v6, v15
v_mul_lo_i32 v15, s10, v6
v_lshrrev_b32 v16, 1, v6
v_add_i32 v15, vcc, v15, v16
v_lshrrev_b32 v16, 3, v6
v_sub_i32 v15, vcc, v15, v16
v_lshrrev_b32 v16, 30, v15
v_subrev_i32 v15, vcc, v16, v6
v_mul_lo_i32 v15, s11, v15
v_mul_u32_u24 v19, 10, v16
v_ashrrev_i32 v16, 31, v15
v_lshlrev_b64 v[15:16], 2, v[15:16]
v_add_i32 v17, vcc, s6, v15
v_mov_b32 v15, s7
v_addc_u32 v18, vcc, v16, v15, vcc
v_and_b32 v15, 30, v19
v_lshlrev_b32 v16, v15, 1
flat_atomic_add v16, v[17:18], v16 glc
s_waitcnt vmcnt(0) lgkmcnt(0)
v_bfe_u32 v15, v16, v15, 10
v_mov_b32 v16, 0x2ac
v_cmp_gt_u32_e32 vcc, v16, v15
s_and_saveexec_b64 s[18:19], vcc
s_xor_b64 s[18:19], exec, s[18:19]
s_cbranch_execz BB18_51
v_mov_b32 v16, 0x2ac
v_mad_i32_i24 v6, v16, v6, v15
v_lshlrev_b32 v6, 5, v6
v_ashrrev_i32 v16, 31, v6
v_add_i32 v15, vcc, s4, v6
v_mov_b32 v6, s5
v_addc_u32 v16, vcc, v16, v6, vcc
v_cmp_ne_i64_e32 vcc, 0, v[15:16]
s_and_saveexec_b64 s[20:21], vcc
s_xor_b64 s[20:21], exec, s[20:21]
flat_store_dwordx4 v[15:16], v[11:14]
s_waitcnt vmcnt(0) lgkmcnt(0)
v_add_i32 v11, vcc, 16, v15
v_addc_u32 v12, vcc, 0, v16, vcc
flat_store_dwordx4 v[11:12], v[7:10]
s_waitcnt vmcnt(0) lgkmcnt(0)
BB18_50:
s_or_b64 exec, exec, s[20:21]
BB18_51:
s_or_b64 exec, exec, s[18:19]
BB18_52:
s_or_b64 exec, exec, s[16:17]
BB18_53:
s_or_b64 exec, exec, s[14:15]
v_min_u32 v6, 0x100, v1
v_subrev_i32 v1, vcc, v6, v1
v_cmp_ne_i32_e32 vcc, 0, v1
s_and_b64 vcc, exec, vcc
s_cbranch_vccnz BB18_33
BB18_54:
s_endpgm
.section .AMDGPU.csdata
.section .AMDGPU.runtime_metadata
.byte 4
.byte 6
.long 13
.ascii "kernel_round5"
.byte 7
.byte 9
.long 4
.byte 10
.long 4
.byte 11
.long 4
.ascii "uint"
.byte 13
.byte 0
.byte 14
.short 7
.byte 16
.byte 0
.byte 8
.byte 7
.byte 9
.long 8
.byte 10
.long 8
.byte 11
.long 5
.ascii "char*"
.byte 13
.byte 1
.byte 14
.short 1
.byte 16
.byte 0
.byte 15
.byte 1
.byte 8
.byte 7
.byte 9
.long 8
.byte 10
.long 8
.byte 11
.long 5
.ascii "char*"
.byte 13
.byte 1
.byte 14
.short 1
.byte 16
.byte 0
.byte 15
.byte 1
.byte 8
.byte 7
.byte 9
.long 8
.byte 10
.long 8
.byte 11
.long 5
.ascii "uint*"
.byte 13
.byte 1
.byte 14
.short 7
.byte 16
.byte 0
.byte 15
.byte 1
.byte 8
.byte 7
.byte 9
.long 8
.byte 10
.long 8
.byte 11
.long 5
.ascii "uint*"
.byte 13
.byte 1
.byte 14
.short 7
.byte 16
.byte 0
.byte 15
.byte 1
.byte 8
.byte 7
.byte 9
.long 8
.byte 10
.long 8
.byte 11
.long 5
.ascii "uint*"
.byte 13
.byte 1
.byte 14
.short 7
.byte 16
.byte 0
.byte 15
.byte 1
.byte 8
.byte 5
.section .AMDGPU.config
.text
.globl kernel_round6
.p2align 8
.type kernel_round6,@function
.amdgpu_hsa_kernel kernel_round6
kernel_round6:
.amd_kernel_code_t
max_scratch_backing_memory_byte_size = 0
.dx10clamp
enable_ordered_append_gds = 0
private_element_size = 1
workitem_private_segment_byte_size = 28
workgroup_group_segment_byte_size = 16516
gds_segment_byte_size = 0
workgroup_fbarrier_count = 0
wavefront_sgpr_count = 28
workitem_vgpr_count = 16
group_segment_alignment = 4
private_segment_alignment = 4
.end_amd_kernel_code_t
s_add_u32 s10, s10, s13
s_lshr_b32 flat_scratch_hi, s10, 8
s_mov_b32 flat_scratch_lo, s11
s_cmp_gt_u32 s12, 0xfff
s_cbranch_scc1 BB19_54
v_mov_b32 v1, 0x100
v_cmp_gt_u32_e32 vcc, v1, v0
s_and_saveexec_b64 s[16:17], vcc
s_xor_b64 s[16:17], exec, s[16:17]
s_cbranch_execz BB19_10
v_add_i32 v1, vcc, 0xffffff00, v0
v_lshlrev_b32 v2, 2, v0
s_mov_b64 s[4:5], 0
s_mov_b32 m0, -1
BB19_12:
v_mov_b32 v3, 0x2ac
ds_write_b32 v2, v3
v_add_i32 v1, vcc, 0x100, v1
v_add_i32 v2, vcc, 0x400, v2
s_waitcnt lgkmcnt(0)
v_mov_b32 v3, 0xffffff00
v_cmp_gt_u32_e32 vcc, v3, v1
s_or_b64 s[4:5], vcc, s[4:5]
s_andn2_b64 exec, exec, s[4:5]
s_cbranch_execnz BB19_12
s_or_b64 exec, exec, s[4:5]
BB19_10:
s_or_b64 exec, exec, s[16:17]
s_load_dwordx2 s[10:11], s[8:9], 0x38
s_load_dwordx2 s[4:5], s[8:9], 0x40
s_load_dwordx2 s[14:15], s[8:9], 0x48
s_load_dwordx2 s[6:7], s[8:9], 0x50
v_mov_b32 v1, 0x2ac
v_cmp_gt_u32_e32 vcc, v1, v0
v_mov_b32 v1, 0
s_waitcnt lgkmcnt(0)
s_and_saveexec_b64 s[8:9], vcc
s_xor_b64 s[8:9], exec, s[8:9]
s_cbranch_execz BB19_19
v_sub_i32 v1, vcc, 0x2ab, v0
v_lshrrev_b32 v5, 8, v1
v_add_i32 v3, vcc, 1, v5
v_cmp_gt_u32_e32 vcc, 64, v3
v_cndmask_b32 v4, 0, -1, vcc
v_mov_b32 v1, v0
v_cmp_lt_u32_e32 vcc, 63, v3
s_and_saveexec_b64 s[16:17], vcc
s_xor_b64 s[16:17], exec, s[16:17]
s_cbranch_execz BB19_6
v_and_b32 v2, 63, v3
v_subrev_i32 v3, vcc, v2, v3
v_mov_b32 v4, -1
v_mov_b32 v1, v0
v_cmp_ne_i32_e32 vcc, 0, v3
s_and_saveexec_b64 s[18:19], vcc
s_xor_b64 s[18:19], exec, s[18:19]
s_cbranch_execz BB19_5
v_lshlrev_b32 v1, 8, v5
v_add_i32 v1, vcc, v1, v0
v_add_i32 v1, vcc, 0x100, v1
v_lshlrev_b32 v4, 8, v2
v_subrev_i32 v1, vcc, v4, v1
s_mov_b64 s[20:21], 0
v_mov_b32 v4, 0
s_mov_b32 m0, -1
BB19_8:
v_or_b32 v5, v4, v0
v_mov_b32 v6, 0x2ac
v_lshlrev_b32 v5, 1, v5
v_add_i32 v3, vcc, 0xffffffc0, v3
v_add_i32 v4, vcc, 0x4000, v4
v_cmp_eq_i32_e32 vcc, 0, v3
ds_write_b16 v5, v6 offset:1024
ds_write_b16 v5, v6 offset:1536
ds_write_b16 v5, v6 offset:2048
ds_write_b16 v5, v6 offset:2560
ds_write_b16 v5, v6 offset:3072
ds_write_b16 v5, v6 offset:3584
ds_write_b16 v5, v6 offset:4096
ds_write_b16 v5, v6 offset:4608
ds_write_b16 v5, v6 offset:5120
ds_write_b16 v5, v6 offset:5632
ds_write_b16 v5, v6 offset:6144
ds_write_b16 v5, v6 offset:6656
ds_write_b16 v5, v6 offset:7168
ds_write_b16 v5, v6 offset:7680
ds_write_b16 v5, v6 offset:8192
ds_write_b16 v5, v6 offset:8704
ds_write_b16 v5, v6 offset:9216
ds_write_b16 v5, v6 offset:9728
ds_write_b16 v5, v6 offset:10240
ds_write_b16 v5, v6 offset:10752
ds_write_b16 v5, v6 offset:11264
ds_write_b16 v5, v6 offset:11776
ds_write_b16 v5, v6 offset:12288
ds_write_b16 v5, v6 offset:12800
ds_write_b16 v5, v6 offset:13312
ds_write_b16 v5, v6 offset:13824
ds_write_b16 v5, v6 offset:14336
ds_write_b16 v5, v6 offset:14848
ds_write_b16 v5, v6 offset:15360
ds_write_b16 v5, v6 offset:15872
ds_write_b16 v5, v6 offset:16384
ds_write_b16 v5, v6 offset:16896
ds_write_b16 v5, v6 offset:17408
ds_write_b16 v5, v6 offset:17920
ds_write_b16 v5, v6 offset:18432
ds_write_b16 v5, v6 offset:18944
ds_write_b16 v5, v6 offset:19456
ds_write_b16 v5, v6 offset:19968
ds_write_b16 v5, v6 offset:20480
ds_write_b16 v5, v6 offset:20992
ds_write_b16 v5, v6 offset:21504
ds_write_b16 v5, v6 offset:22016
ds_write_b16 v5, v6 offset:22528
ds_write_b16 v5, v6 offset:23040
ds_write_b16 v5, v6 offset:23552
ds_write_b16 v5, v6 offset:24064
ds_write_b16 v5, v6 offset:24576
ds_write_b16 v5, v6 offset:25088
ds_write_b16 v5, v6 offset:25600
ds_write_b16 v5, v6 offset:26112
ds_write_b16 v5, v6 offset:26624
ds_write_b16 v5, v6 offset:27136
ds_write_b16 v5, v6 offset:27648
ds_write_b16 v5, v6 offset:28160
ds_write_b16 v5, v6 offset:28672
ds_write_b16 v5, v6 offset:29184
ds_write_b16 v5, v6 offset:29696
ds_write_b16 v5, v6 offset:30208
ds_write_b16 v5, v6 offset:30720
ds_write_b16 v5, v6 offset:31232
ds_write_b16 v5, v6 offset:31744
ds_write_b16 v5, v6 offset:32256
ds_write_b16 v5, v6 offset:32768
ds_write_b16 v5, v6 offset:33280
s_or_b64 s[20:21], vcc, s[20:21]
s_waitcnt lgkmcnt(0)
s_andn2_b64 exec, exec, s[20:21]
s_cbranch_execnz BB19_8
s_or_b64 exec, exec, s[20:21]
v_cmp_ne_i32_e32 vcc, 0, v2
v_cndmask_b32 v4, 0, -1, vcc
BB19_5:
s_or_b64 exec, exec, s[18:19]
BB19_6:
s_or_b64 exec, exec, s[16:17]
v_cmp_ne_i32_e32 vcc, 0, v4
s_and_saveexec_b64 s[16:17], vcc
s_xor_b64 s[16:17], exec, s[16:17]
s_cbranch_execz BB19_16
v_lshlrev_b32 v2, 1, v1
v_add_i32 v2, vcc, 0x400, v2
s_mov_b64 s[18:19], 0
s_mov_b32 m0, -1
BB19_14:
v_mov_b32 v3, 0x2ac
ds_write_b16 v2, v3
v_add_i32 v1, vcc, 0x100, v1
v_add_i32 v2, vcc, 0x200, v2
s_waitcnt lgkmcnt(0)
v_mov_b32 v3, 0x2ab
v_cmp_lt_u32_e32 vcc, v3, v1
s_or_b64 s[18:19], vcc, s[18:19]
s_andn2_b64 exec, exec, s[18:19]
s_cbranch_execnz BB19_14
s_or_b64 exec, exec, s[18:19]
BB19_16:
s_or_b64 exec, exec, s[16:17]
v_mov_b32 v1, 0
v_cmp_eq_i32_e32 vcc, 0, v0
s_and_saveexec_b64 s[16:17], vcc
s_xor_b64 s[16:17], exec, s[16:17]
s_cbranch_execz BB19_18
s_mul_i32 s18, s12, 0x55555555
s_lshr_b32 s19, s12, 1
s_add_i32 s18, s18, s19
s_lshr_b32 s19, s12, 3
s_sub_i32 s18, s18, s19
s_lshr_b32 s20, s18, 30
s_sub_i32 s18, s12, s20
s_mul_i32 s18, s18, 0xaaaaaaab
s_ashr_i32 s19, s18, 31
s_lshl_b64 s[18:19], s[18:19], 2
s_add_u32 s14, s14, s18
s_addc_u32 s15, s15, s19
v_mov_b32 v2, s15
v_mov_b32 v1, s14
flat_load_dword v1, v[1:2]
v_mul_u32_u24 v3, 10, s20
v_and_b32 v3, 30, v3
v_mov_b32 v2, 0
s_mov_b32 m0, -1
s_waitcnt vmcnt(0) lgkmcnt(0)
v_bfe_u32 v1, v1, v3, 10
v_min_u32 v1, 0x2ac, v1
ds_write_b32 v2, v1 offset:2392
s_waitcnt lgkmcnt(0)
BB19_18:
s_or_b64 exec, exec, s[16:17]
BB19_19:
s_or_b64 exec, exec, s[8:9]
s_barrier
v_cmp_ne_i32_e32 vcc, 0, v0
s_and_saveexec_b64 s[8:9], vcc
s_xor_b64 s[8:9], exec, s[8:9]
v_mov_b32 v1, 0
s_mov_b32 m0, -1
ds_read_b32 v1, v1 offset:2392
s_waitcnt lgkmcnt(0)
BB19_21:
s_or_b64 exec, exec, s[8:9]
s_barrier
v_cmp_eq_i32_e32 vcc, 0, v0
s_and_saveexec_b64 s[8:9], vcc
s_xor_b64 s[8:9], exec, s[8:9]
v_mov_b32 v2, 0
s_mov_b32 m0, -1
ds_write_b32 v2, v2 offset:2392
s_waitcnt lgkmcnt(0)
BB19_23:
s_or_b64 exec, exec, s[8:9]
s_barrier
v_cmp_lt_u32_e32 vcc, v0, v1
s_and_saveexec_b64 s[8:9], vcc
s_xor_b64 s[8:9], exec, s[8:9]
s_cbranch_execz BB19_30
v_lshlrev_b32 v2, 2, v0
s_mul_i32 s14, s12, 0x2ac
v_add_i32 v2, vcc, 0x95c, v2
s_mov_b64 s[16:17], 0
v_mov_b32 v3, v0
BB19_25:
v_add_i32 v4, vcc, s14, v3
v_lshlrev_b32 v4, 5, v4
v_ashrrev_i32 v6, 31, v4
v_add_i32 v5, vcc, s10, v4
v_mov_b32 v4, s11
v_addc_u32 v6, vcc, v6, v4, vcc
flat_load_dword v4, v[5:6]
v_add_i32 v7, vcc, 4, v5
v_mov_b32 v10, 0
v_addc_u32 v8, vcc, 0, v6, vcc
s_mov_b32 s15, 0
s_waitcnt vmcnt(0) lgkmcnt(0)
buffer_store_dword v4, v10, s[0:3], s13 offen
s_nop 0
flat_load_dword v9, v[7:8]
v_add_i32 v7, vcc, 8, v5
v_mov_b32 v10, 0
v_addc_u32 v8, vcc, 0, v6, vcc
s_waitcnt vmcnt(0) lgkmcnt(0)
buffer_store_dword v9, v10, s[0:3], s13 offen offset:4
s_waitcnt vmcnt(0) expcnt(0)
flat_load_dword v9, v[7:8]
v_add_i32 v7, vcc, 12, v5
v_mov_b32 v10, 0
v_addc_u32 v8, vcc, 0, v6, vcc
v_mov_b32 v5, 0
v_mov_b32 v6, v2
s_waitcnt vmcnt(0) lgkmcnt(0)
buffer_store_dword v9, v10, s[0:3], s13 offen offset:8
s_nop 0
flat_load_dword v8, v[7:8]
s_waitcnt vmcnt(1) expcnt(0)
v_mov_b32 v9, 0
v_mov_b32 v7, s15
s_waitcnt vmcnt(0) lgkmcnt(0)
buffer_store_dword v8, v9, s[0:3], s13 offen offset:12
s_waitcnt vmcnt(0) expcnt(0)
v_mov_b32 v8, v4
s_branch BB19_26
BB19_27:
buffer_load_dword v8, v7, s[0:3], s13 offen offset:4
v_add_i32 v6, vcc, 0xab0, v6
v_add_i32 v7, vcc, 4, v7
s_waitcnt vmcnt(0)
BB19_26:
v_add_i32 v5, vcc, 1, v5
v_cmp_lt_u32_e32 vcc, 3, v5
s_mov_b32 m0, -1
ds_write_b32 v6, v8
s_and_b64 vcc, exec, vcc
s_waitcnt lgkmcnt(0)
s_cbranch_vccz BB19_27
v_bfe_u32 v5, v4, 16, 4
v_and_b32 v4, 0xf000, v4
v_lshrrev_b32 v4, 8, v4
v_or_b32 v4, v5, v4
v_lshlrev_b32 v4, 2, v4
s_mov_b32 m0, -1
ds_wrxchg_rtn_b32 v4, v4, v3
v_lshlrev_b32 v5, 1, v3
s_waitcnt lgkmcnt(0)
v_add_i32 v3, vcc, 0x100, v3
v_add_i32 v2, vcc, 0x400, v2
v_cmp_ge_u32_e32 vcc, v3, v1
ds_write_b16 v5, v4 offset:1024
s_or_b64 s[16:17], vcc, s[16:17]
s_waitcnt lgkmcnt(0)
s_andn2_b64 exec, exec, s[16:17]
s_cbranch_execnz BB19_25
s_or_b64 exec, exec, s[16:17]
BB19_30:
s_or_b64 exec, exec, s[8:9]
s_barrier
v_mov_b32 v1, 0x2ac
v_cmp_gt_u32_e32 vcc, v1, v0
s_and_saveexec_b64 s[8:9], vcc
s_xor_b64 s[8:9], exec, s[8:9]
s_cbranch_execz BB19_35
s_mov_b64 s[10:11], 0
v_mov_b32 v1, v0
BB19_37:
v_lshlrev_b32 v2, 1, v1
s_mov_b32 m0, -1
ds_read_u16 v2, v2 offset:1024
v_mov_b32 v3, 0x2ac
s_waitcnt lgkmcnt(0)
v_cmp_gt_u32_e32 vcc, v3, v2
s_and_saveexec_b64 s[14:15], vcc
s_xor_b64 s[14:15], exec, s[14:15]
s_cbranch_execz BB19_43
s_mov_b64 s[16:17], 0
BB19_39:
v_mov_b32 v3, 1
v_mov_b32 v4, 0
s_mov_b32 m0, -1
ds_add_rtn_u32 v3, v4, v3 offset:2392
v_mov_b32 v4, 0x31a
s_waitcnt lgkmcnt(0)
v_cmp_gt_u32_e32 vcc, v4, v3
s_and_saveexec_b64 s[18:19], vcc
s_xor_b64 s[18:19], exec, s[18:19]
v_lshlrev_b32 v3, 1, v3
s_mov_b32 m0, -1
ds_write_b16 v3, v2 offset:13340
s_waitcnt lgkmcnt(0)
v_lshlrev_b32 v2, 1, v2
ds_read_u16 v2, v2 offset:1024
ds_write_b16 v3, v1 offset:14928
v_mov_b32 v3, 0x2ab
s_waitcnt lgkmcnt(0)
v_cmp_lt_u32_e32 vcc, v3, v2
s_or_b64 s[16:17], vcc, s[16:17]
BB19_41:
s_or_b64 exec, exec, s[18:19]
s_or_b64 s[16:17], s[18:19], s[16:17]
s_andn2_b64 exec, exec, s[16:17]
s_cbranch_execnz BB19_39
s_or_b64 exec, exec, s[16:17]
BB19_43:
s_or_b64 exec, exec, s[14:15]
v_add_i32 v1, vcc, 0x100, v1
v_mov_b32 v2, 0x2ab
v_cmp_lt_u32_e32 vcc, v2, v1
s_or_b64 s[10:11], vcc, s[10:11]
s_andn2_b64 exec, exec, s[10:11]
s_cbranch_execnz BB19_37
s_or_b64 exec, exec, s[10:11]
BB19_35:
s_or_b64 exec, exec, s[8:9]
s_barrier
v_mov_b32 v1, 0
s_mov_b32 m0, -1
ds_read_b32 v1, v1 offset:2392
s_waitcnt lgkmcnt(0)
v_min_u32 v1, 0x31a, v1
v_cmp_eq_i32_e32 vcc, 0, v1
s_and_b64 vcc, exec, vcc
s_cbranch_vccnz BB19_54
v_not_b32 v2, v0
s_movk_i32 s8, 0x95c
s_lshl_b32 s9, s12, 20
s_mov_b32 s10, 0x55555555
s_mov_b32 s11, 0xaaaaaaab
BB19_33:
v_mov_b32 v9, 0x2ac
v_cmp_lt_u32_e32 vcc, v0, v1
s_and_saveexec_b64 s[14:15], vcc
s_xor_b64 s[14:15], exec, s[14:15]
v_add_i32 v3, vcc, v1, v2
v_lshlrev_b32 v3, 1, v3
s_mov_b32 m0, -1
ds_read_u16 v9, v3 offset:14928
ds_read_u16 v3, v3 offset:13340
s_waitcnt lgkmcnt(0)
v_lshlrev_b32 v4, 2, v9
v_lshlrev_b32 v5, 2, v3
v_add_i32 v4, vcc, s8, v4
v_add_i32 v5, vcc, s8, v5
BB19_45:
s_or_b64 exec, exec, s[14:15]
v_mov_b32 v6, 0x2ac
v_cmp_gt_u32_e32 vcc, v6, v9
s_and_saveexec_b64 s[14:15], vcc
s_xor_b64 s[14:15], exec, s[14:15]
s_cbranch_execz BB19_53
s_mov_b32 m0, -1
ds_read_b32 v6, v4
ds_read_b32 v11, v5
ds_read_b32 v7, v4 offset:2736
ds_read_b32 v12, v5 offset:2736
ds_read_b32 v8, v4 offset:5472
ds_read_b32 v10, v4 offset:8208
ds_read_b32 v13, v5 offset:5472
ds_read_b32 v14, v5 offset:8208
s_waitcnt lgkmcnt(0)
v_xor_b32 v11, v6, v11
v_xor_b32 v6, v7, v12
v_and_b32 v9, 0x3ff, v9
v_xor_b32 v7, v8, v13
v_xor_b32 v8, v10, v14
v_lshrrev_b32 v10, 24, v11
v_lshlrev_b32 v11, 8, v6
v_or_b32 v11, v11, v10
v_lshlrev_b32 v10, 10, v3
v_and_b32 v10, 0xffc00, v10
v_or_b32 v9, s9, v9
v_or_b32 v9, v10, v9
v_or_b32 v10, v6, v11
v_cmp_ne_i32_e32 vcc, 0, v10
s_and_saveexec_b64 s[16:17], vcc
s_xor_b64 s[16:17], exec, s[16:17]
s_cbranch_execz BB19_52
v_and_b32 v10, 0xfff, v11
v_mul_lo_i32 v12, s10, v10
v_bfe_u32 v13, v11, 1, 11
v_bfe_u32 v11, v11, 3, 9
v_add_i32 v12, vcc, v12, v13
v_sub_i32 v11, vcc, v12, v11
v_lshrrev_b32 v12, 30, v11
v_sub_i32 v11, vcc, v10, v12
v_mul_lo_i32 v11, s11, v11
v_mul_u32_u24 v15, 10, v12
v_ashrrev_i32 v12, 31, v11
v_lshlrev_b64 v[11:12], 2, v[11:12]
v_add_i32 v13, vcc, s6, v11
v_mov_b32 v11, s7
v_addc_u32 v14, vcc, v12, v11, vcc
v_and_b32 v11, 30, v15
v_lshlrev_b32 v12, v11, 1
flat_atomic_add v12, v[13:14], v12 glc
s_waitcnt vmcnt(0) lgkmcnt(0)
v_bfe_u32 v11, v12, v11, 10
v_mov_b32 v12, 0x2ac
v_cmp_gt_u32_e32 vcc, v12, v11
s_and_saveexec_b64 s[18:19], vcc
s_xor_b64 s[18:19], exec, s[18:19]
s_cbranch_execz BB19_51
v_mov_b32 v12, 0x2ac
v_mad_i32_i24 v10, v12, v10, v11
v_lshlrev_b32 v10, 4, v10
v_ashrrev_i32 v11, 31, v10
v_add_i32 v10, vcc, s4, v10
v_mov_b32 v12, s5
v_addc_u32 v11, vcc, v11, v12, vcc
v_cmp_ne_i64_e32 vcc, 0, v[10:11]
s_and_saveexec_b64 s[20:21], vcc
s_xor_b64 s[20:21], exec, s[20:21]
flat_store_dwordx4 v[10:11], v[6:9]
s_waitcnt vmcnt(0) lgkmcnt(0)
BB19_50:
s_or_b64 exec, exec, s[20:21]
BB19_51:
s_or_b64 exec, exec, s[18:19]
BB19_52:
s_or_b64 exec, exec, s[16:17]
BB19_53:
s_or_b64 exec, exec, s[14:15]
v_min_u32 v6, 0x100, v1
v_subrev_i32 v1, vcc, v6, v1
v_cmp_ne_i32_e32 vcc, 0, v1
s_and_b64 vcc, exec, vcc
s_cbranch_vccnz BB19_33
BB19_54:
s_endpgm
.section .AMDGPU.csdata
.section .AMDGPU.runtime_metadata
.byte 4
.byte 6
.long 13
.ascii "kernel_round6"
.byte 7
.byte 9
.long 4
.byte 10
.long 4
.byte 11
.long 4
.ascii "uint"
.byte 13
.byte 0
.byte 14
.short 7
.byte 16
.byte 0
.byte 8
.byte 7
.byte 9
.long 8
.byte 10
.long 8
.byte 11
.long 5
.ascii "char*"
.byte 13
.byte 1
.byte 14
.short 1
.byte 16
.byte 0
.byte 15
.byte 1
.byte 8
.byte 7
.byte 9
.long 8
.byte 10
.long 8
.byte 11
.long 5
.ascii "char*"
.byte 13
.byte 1
.byte 14
.short 1
.byte 16
.byte 0
.byte 15
.byte 1
.byte 8
.byte 7
.byte 9
.long 8
.byte 10
.long 8
.byte 11
.long 5
.ascii "uint*"
.byte 13
.byte 1
.byte 14
.short 7
.byte 16
.byte 0
.byte 15
.byte 1
.byte 8
.byte 7
.byte 9
.long 8
.byte 10
.long 8
.byte 11
.long 5
.ascii "uint*"
.byte 13
.byte 1
.byte 14
.short 7
.byte 16
.byte 0
.byte 15
.byte 1
.byte 8
.byte 7
.byte 9
.long 8
.byte 10
.long 8
.byte 11
.long 5
.ascii "uint*"
.byte 13
.byte 1
.byte 14
.short 7
.byte 16
.byte 0
.byte 15
.byte 1
.byte 8
.byte 5
.section .AMDGPU.config
.text
.globl kernel_round7
.p2align 8
.type kernel_round7,@function
.amdgpu_hsa_kernel kernel_round7
kernel_round7:
.amd_kernel_code_t
max_scratch_backing_memory_byte_size = 0
.dx10clamp
enable_ordered_append_gds = 0
private_element_size = 1
workitem_private_segment_byte_size = 28
workgroup_group_segment_byte_size = 13780
gds_segment_byte_size = 0
workgroup_fbarrier_count = 0
wavefront_sgpr_count = 28
workitem_vgpr_count = 16
group_segment_alignment = 4
private_segment_alignment = 4
.end_amd_kernel_code_t
s_add_u32 s10, s10, s13
s_lshr_b32 flat_scratch_hi, s10, 8
s_mov_b32 flat_scratch_lo, s11
s_cmp_gt_u32 s12, 0xfff
s_cbranch_scc1 BB20_55
v_mov_b32 v1, 0x100
v_cmp_gt_u32_e32 vcc, v1, v0
s_and_saveexec_b64 s[16:17], vcc
s_xor_b64 s[16:17], exec, s[16:17]
s_cbranch_execz BB20_10
v_add_i32 v1, vcc, 0xffffff00, v0
v_lshlrev_b32 v2, 2, v0
s_mov_b64 s[4:5], 0
s_mov_b32 m0, -1
BB20_12:
v_mov_b32 v3, 0x2ac
ds_write_b32 v2, v3
v_add_i32 v1, vcc, 0x100, v1
v_add_i32 v2, vcc, 0x400, v2
s_waitcnt lgkmcnt(0)
v_mov_b32 v3, 0xffffff00
v_cmp_gt_u32_e32 vcc, v3, v1
s_or_b64 s[4:5], vcc, s[4:5]
s_andn2_b64 exec, exec, s[4:5]
s_cbranch_execnz BB20_12
s_or_b64 exec, exec, s[4:5]
BB20_10:
s_or_b64 exec, exec, s[16:17]
s_load_dwordx2 s[10:11], s[8:9], 0x38
s_load_dwordx2 s[4:5], s[8:9], 0x40
s_load_dwordx2 s[14:15], s[8:9], 0x48
s_load_dwordx2 s[6:7], s[8:9], 0x50
v_mov_b32 v1, 0x2ac
v_cmp_gt_u32_e32 vcc, v1, v0
v_mov_b32 v1, 0
s_waitcnt lgkmcnt(0)
s_and_saveexec_b64 s[8:9], vcc
s_xor_b64 s[8:9], exec, s[8:9]
s_cbranch_execz BB20_19
v_sub_i32 v1, vcc, 0x2ab, v0
v_lshrrev_b32 v5, 8, v1
v_add_i32 v3, vcc, 1, v5
v_cmp_gt_u32_e32 vcc, 64, v3
v_cndmask_b32 v4, 0, -1, vcc
v_mov_b32 v1, v0
v_cmp_lt_u32_e32 vcc, 63, v3
s_and_saveexec_b64 s[16:17], vcc
s_xor_b64 s[16:17], exec, s[16:17]
s_cbranch_execz BB20_6
v_and_b32 v2, 63, v3
v_subrev_i32 v3, vcc, v2, v3
v_mov_b32 v4, -1
v_mov_b32 v1, v0
v_cmp_ne_i32_e32 vcc, 0, v3
s_and_saveexec_b64 s[18:19], vcc
s_xor_b64 s[18:19], exec, s[18:19]
s_cbranch_execz BB20_5
v_lshlrev_b32 v1, 8, v5
v_add_i32 v1, vcc, v1, v0
v_add_i32 v1, vcc, 0x100, v1
v_lshlrev_b32 v4, 8, v2
v_subrev_i32 v1, vcc, v4, v1
s_mov_b64 s[20:21], 0
v_mov_b32 v4, 0
s_mov_b32 m0, -1
BB20_8:
v_or_b32 v5, v4, v0
v_mov_b32 v6, 0x2ac
v_lshlrev_b32 v5, 1, v5
v_add_i32 v3, vcc, 0xffffffc0, v3
v_add_i32 v4, vcc, 0x4000, v4
v_cmp_eq_i32_e32 vcc, 0, v3
ds_write_b16 v5, v6 offset:1024
ds_write_b16 v5, v6 offset:1536
ds_write_b16 v5, v6 offset:2048
ds_write_b16 v5, v6 offset:2560
ds_write_b16 v5, v6 offset:3072
ds_write_b16 v5, v6 offset:3584
ds_write_b16 v5, v6 offset:4096
ds_write_b16 v5, v6 offset:4608
ds_write_b16 v5, v6 offset:5120
ds_write_b16 v5, v6 offset:5632
ds_write_b16 v5, v6 offset:6144
ds_write_b16 v5, v6 offset:6656
ds_write_b16 v5, v6 offset:7168
ds_write_b16 v5, v6 offset:7680
ds_write_b16 v5, v6 offset:8192
ds_write_b16 v5, v6 offset:8704
ds_write_b16 v5, v6 offset:9216
ds_write_b16 v5, v6 offset:9728
ds_write_b16 v5, v6 offset:10240
ds_write_b16 v5, v6 offset:10752
ds_write_b16 v5, v6 offset:11264
ds_write_b16 v5, v6 offset:11776
ds_write_b16 v5, v6 offset:12288
ds_write_b16 v5, v6 offset:12800
ds_write_b16 v5, v6 offset:13312
ds_write_b16 v5, v6 offset:13824
ds_write_b16 v5, v6 offset:14336
ds_write_b16 v5, v6 offset:14848
ds_write_b16 v5, v6 offset:15360
ds_write_b16 v5, v6 offset:15872
ds_write_b16 v5, v6 offset:16384
ds_write_b16 v5, v6 offset:16896
ds_write_b16 v5, v6 offset:17408
ds_write_b16 v5, v6 offset:17920
ds_write_b16 v5, v6 offset:18432
ds_write_b16 v5, v6 offset:18944
ds_write_b16 v5, v6 offset:19456
ds_write_b16 v5, v6 offset:19968
ds_write_b16 v5, v6 offset:20480
ds_write_b16 v5, v6 offset:20992
ds_write_b16 v5, v6 offset:21504
ds_write_b16 v5, v6 offset:22016
ds_write_b16 v5, v6 offset:22528
ds_write_b16 v5, v6 offset:23040
ds_write_b16 v5, v6 offset:23552
ds_write_b16 v5, v6 offset:24064
ds_write_b16 v5, v6 offset:24576
ds_write_b16 v5, v6 offset:25088
ds_write_b16 v5, v6 offset:25600
ds_write_b16 v5, v6 offset:26112
ds_write_b16 v5, v6 offset:26624
ds_write_b16 v5, v6 offset:27136
ds_write_b16 v5, v6 offset:27648
ds_write_b16 v5, v6 offset:28160
ds_write_b16 v5, v6 offset:28672
ds_write_b16 v5, v6 offset:29184
ds_write_b16 v5, v6 offset:29696
ds_write_b16 v5, v6 offset:30208
ds_write_b16 v5, v6 offset:30720
ds_write_b16 v5, v6 offset:31232
ds_write_b16 v5, v6 offset:31744
ds_write_b16 v5, v6 offset:32256
ds_write_b16 v5, v6 offset:32768
ds_write_b16 v5, v6 offset:33280
s_or_b64 s[20:21], vcc, s[20:21]
s_waitcnt lgkmcnt(0)
s_andn2_b64 exec, exec, s[20:21]
s_cbranch_execnz BB20_8
s_or_b64 exec, exec, s[20:21]
v_cmp_ne_i32_e32 vcc, 0, v2
v_cndmask_b32 v4, 0, -1, vcc
BB20_5:
s_or_b64 exec, exec, s[18:19]
BB20_6:
s_or_b64 exec, exec, s[16:17]
v_cmp_ne_i32_e32 vcc, 0, v4
s_and_saveexec_b64 s[16:17], vcc
s_xor_b64 s[16:17], exec, s[16:17]
s_cbranch_execz BB20_16
v_lshlrev_b32 v2, 1, v1
v_add_i32 v2, vcc, 0x400, v2
s_mov_b64 s[18:19], 0
s_mov_b32 m0, -1
BB20_14:
v_mov_b32 v3, 0x2ac
ds_write_b16 v2, v3
v_add_i32 v1, vcc, 0x100, v1
v_add_i32 v2, vcc, 0x200, v2
s_waitcnt lgkmcnt(0)
v_mov_b32 v3, 0x2ab
v_cmp_lt_u32_e32 vcc, v3, v1
s_or_b64 s[18:19], vcc, s[18:19]
s_andn2_b64 exec, exec, s[18:19]
s_cbranch_execnz BB20_14
s_or_b64 exec, exec, s[18:19]
BB20_16:
s_or_b64 exec, exec, s[16:17]
v_mov_b32 v1, 0
v_cmp_eq_i32_e32 vcc, 0, v0
s_and_saveexec_b64 s[16:17], vcc
s_xor_b64 s[16:17], exec, s[16:17]
s_cbranch_execz BB20_18
s_mul_i32 s18, s12, 0x55555555
s_lshr_b32 s19, s12, 1
s_add_i32 s18, s18, s19
s_lshr_b32 s19, s12, 3
s_sub_i32 s18, s18, s19
s_lshr_b32 s20, s18, 30
s_sub_i32 s18, s12, s20
s_mul_i32 s18, s18, 0xaaaaaaab
s_ashr_i32 s19, s18, 31
s_lshl_b64 s[18:19], s[18:19], 2
s_add_u32 s14, s14, s18
s_addc_u32 s15, s15, s19
v_mov_b32 v2, s15
v_mov_b32 v1, s14
flat_load_dword v1, v[1:2]
v_mul_u32_u24 v3, 10, s20
v_and_b32 v3, 30, v3
v_mov_b32 v2, 0
s_mov_b32 m0, -1
s_waitcnt vmcnt(0) lgkmcnt(0)
v_bfe_u32 v1, v1, v3, 10
v_min_u32 v1, 0x2ac, v1
ds_write_b32 v2, v1 offset:2392
s_waitcnt lgkmcnt(0)
BB20_18:
s_or_b64 exec, exec, s[16:17]
BB20_19:
s_or_b64 exec, exec, s[8:9]
s_barrier
v_cmp_ne_i32_e32 vcc, 0, v0
s_and_saveexec_b64 s[8:9], vcc
s_xor_b64 s[8:9], exec, s[8:9]
v_mov_b32 v1, 0
s_mov_b32 m0, -1
ds_read_b32 v1, v1 offset:2392
s_waitcnt lgkmcnt(0)
BB20_21:
s_or_b64 exec, exec, s[8:9]
s_barrier
v_cmp_eq_i32_e32 vcc, 0, v0
s_and_saveexec_b64 s[8:9], vcc
s_xor_b64 s[8:9], exec, s[8:9]
v_mov_b32 v2, 0
s_mov_b32 m0, -1
ds_write_b32 v2, v2 offset:2392
s_waitcnt lgkmcnt(0)
BB20_23:
s_or_b64 exec, exec, s[8:9]
s_barrier
v_cmp_lt_u32_e32 vcc, v0, v1
s_and_saveexec_b64 s[8:9], vcc
s_xor_b64 s[8:9], exec, s[8:9]
s_cbranch_execz BB20_31
v_lshlrev_b32 v3, 2, v0
s_mul_i32 s14, s12, 0x2ac0
v_lshlrev_b32 v2, 4, v0
v_add_i32 v2, vcc, s14, v2
v_add_i32 v3, vcc, 0x95c, v3
s_mov_b64 s[14:15], 0
v_mov_b32 v4, v0
BB20_25:
s_mov_b32 s16, 0
v_ashrrev_i32 v6, 31, v2
v_add_i32 v5, vcc, s10, v2
v_mov_b32 v7, s11
v_addc_u32 v6, vcc, v6, v7, vcc
v_mov_b32 v7, 0
v_mov_b32 v8, s16
BB20_26:
flat_load_dword v9, v[5:6]
v_add_i32 v7, vcc, 1, v7
s_waitcnt vmcnt(0) lgkmcnt(0)
buffer_store_dword v9, v8, s[0:3], s13 offen
v_add_i32 v8, vcc, 4, v8
v_add_i32 v5, vcc, 4, v5
v_addc_u32 v6, vcc, 0, v6, vcc
v_cmp_gt_u32_e32 vcc, 3, v7
s_and_b64 vcc, exec, vcc
s_waitcnt vmcnt(0) expcnt(0)
s_cbranch_vccnz BB20_26
s_mov_b32 s16, 0
v_mov_b32 v5, 0
v_mov_b32 v6, s16
v_mov_b32 v7, v3
BB20_28:
buffer_load_dword v8, v6, s[0:3], s13 offen
s_mov_b32 m0, -1
v_add_i32 v5, vcc, 1, v5
v_add_i32 v6, vcc, 4, v6
s_waitcnt vmcnt(0)
ds_write_b32 v7, v8
v_add_i32 v7, vcc, 0xab0, v7
v_cmp_gt_u32_e32 vcc, 3, v5
s_and_b64 vcc, exec, vcc
s_waitcnt lgkmcnt(0)
s_cbranch_vccnz BB20_28
v_mov_b32 v7, 0
buffer_load_dword v5, v7, s[0:3], s13 offen
s_mov_b32 m0, -1
v_add_i32 v2, vcc, 0x1000, v2
v_add_i32 v3, vcc, 0x400, v3
s_waitcnt vmcnt(0)
v_bfe_u32 v6, v5, 12, 4
v_and_b32 v5, 0xf0, v5
v_or_b32 v5, v5, v6
v_lshlrev_b32 v5, 2, v5
ds_wrxchg_rtn_b32 v5, v5, v4
v_lshlrev_b32 v6, 1, v4
s_waitcnt lgkmcnt(0)
v_add_i32 v4, vcc, 0x100, v4
v_cmp_ge_u32_e32 vcc, v4, v1
ds_write_b16 v6, v5 offset:1024
s_or_b64 s[14:15], vcc, s[14:15]
s_waitcnt lgkmcnt(0)
s_andn2_b64 exec, exec, s[14:15]
s_cbranch_execnz BB20_25
s_or_b64 exec, exec, s[14:15]
BB20_31:
s_or_b64 exec, exec, s[8:9]
s_barrier
v_mov_b32 v1, 0x2ac
v_cmp_gt_u32_e32 vcc, v1, v0
s_and_saveexec_b64 s[8:9], vcc
s_xor_b64 s[8:9], exec, s[8:9]
s_cbranch_execz BB20_36
s_mov_b64 s[10:11], 0
v_mov_b32 v1, v0
BB20_38:
v_lshlrev_b32 v2, 1, v1
s_mov_b32 m0, -1
ds_read_u16 v2, v2 offset:1024
v_mov_b32 v3, 0x2ac
s_waitcnt lgkmcnt(0)
v_cmp_gt_u32_e32 vcc, v3, v2
s_and_saveexec_b64 s[14:15], vcc
s_xor_b64 s[14:15], exec, s[14:15]
s_cbranch_execz BB20_44
s_mov_b64 s[16:17], 0
BB20_40:
v_mov_b32 v3, 1
v_mov_b32 v4, 0
s_mov_b32 m0, -1
ds_add_rtn_u32 v3, v4, v3 offset:2392
v_mov_b32 v4, 0x31a
s_waitcnt lgkmcnt(0)
v_cmp_gt_u32_e32 vcc, v4, v3
s_and_saveexec_b64 s[18:19], vcc
s_xor_b64 s[18:19], exec, s[18:19]
v_lshlrev_b32 v3, 1, v3
s_mov_b32 m0, -1
ds_write_b16 v3, v2 offset:10604
s_waitcnt lgkmcnt(0)
v_lshlrev_b32 v2, 1, v2
ds_read_u16 v2, v2 offset:1024
ds_write_b16 v3, v1 offset:12192
v_mov_b32 v3, 0x2ab
s_waitcnt lgkmcnt(0)
v_cmp_lt_u32_e32 vcc, v3, v2
s_or_b64 s[16:17], vcc, s[16:17]
BB20_42:
s_or_b64 exec, exec, s[18:19]
s_or_b64 s[16:17], s[18:19], s[16:17]
s_andn2_b64 exec, exec, s[16:17]
s_cbranch_execnz BB20_40
s_or_b64 exec, exec, s[16:17]
BB20_44:
s_or_b64 exec, exec, s[14:15]
v_add_i32 v1, vcc, 0x100, v1
v_mov_b32 v2, 0x2ab
v_cmp_lt_u32_e32 vcc, v2, v1
s_or_b64 s[10:11], vcc, s[10:11]
s_andn2_b64 exec, exec, s[10:11]
s_cbranch_execnz BB20_38
s_or_b64 exec, exec, s[10:11]
BB20_36:
s_or_b64 exec, exec, s[8:9]
s_barrier
v_mov_b32 v1, 0
s_mov_b32 m0, -1
ds_read_b32 v1, v1 offset:2392
s_waitcnt lgkmcnt(0)
v_min_u32 v1, 0x31a, v1
v_cmp_eq_i32_e32 vcc, 0, v1
s_and_b64 vcc, exec, vcc
s_cbranch_vccnz BB20_55
v_not_b32 v2, v0
s_movk_i32 s8, 0x95c
s_lshl_b32 s9, s12, 20
s_mov_b32 s10, 0x55555555
s_mov_b32 s11, 0xaaaaaaab
BB20_34:
v_mov_b32 v5, 0x2ac
v_cmp_lt_u32_e32 vcc, v0, v1
s_and_saveexec_b64 s[14:15], vcc
s_xor_b64 s[14:15], exec, s[14:15]
v_add_i32 v3, vcc, v1, v2
v_lshlrev_b32 v3, 1, v3
s_mov_b32 m0, -1
ds_read_u16 v5, v3 offset:12192
ds_read_u16 v7, v3 offset:10604
s_waitcnt lgkmcnt(0)
v_lshlrev_b32 v3, 2, v5
v_add_i32 v8, vcc, s8, v3
v_lshlrev_b32 v3, 2, v7
v_add_i32 v9, vcc, s8, v3
BB20_46:
s_or_b64 exec, exec, s[14:15]
v_mov_b32 v3, 0x2ac
v_cmp_gt_u32_e32 vcc, v3, v5
s_and_saveexec_b64 s[14:15], vcc
s_xor_b64 s[14:15], exec, s[14:15]
s_cbranch_execz BB20_54
s_mov_b32 m0, -1
ds_read_b32 v4, v8 offset:2736
ds_read_b32 v12, v9 offset:2736
ds_read_b32 v11, v8 offset:5472
ds_read_b32 v13, v9 offset:5472
ds_read_b32 v3, v8
ds_read_b32 v10, v9
s_waitcnt lgkmcnt(0)
v_xor_b32 v12, v4, v12
v_and_b32 v5, 0x3ff, v5
v_xor_b32 v4, v11, v13
v_lshlrev_b32 v4, 24, v4
v_lshrrev_b32 v13, 8, v12
v_xor_b32 v10, v3, v10
v_or_b32 v4, v4, v13
v_lshlrev_b32 v13, 10, v7
v_lshlrev_b32 v3, 24, v12
v_lshrrev_b32 v11, 8, v10
v_and_b32 v13, 0xffc00, v13
v_or_b32 v5, s9, v5
v_or_b32 v12, v12, v10
v_or_b32 v3, v3, v11
v_or_b32 v5, v13, v5
v_cmp_ne_i32_e32 vcc, 0, v12
s_and_saveexec_b64 s[16:17], vcc
s_xor_b64 s[16:17], exec, s[16:17]
s_cbranch_execz BB20_53
v_lshrrev_b32 v10, 24, v10
v_and_b32 v11, 0xf0f, v11
v_and_b32 v10, 0xf0, v10
v_or_b32 v10, v11, v10
v_mul_lo_i32 v11, s10, v10
v_lshrrev_b32 v12, 1, v10
v_add_i32 v11, vcc, v11, v12
v_lshrrev_b32 v12, 3, v10
v_sub_i32 v11, vcc, v11, v12
v_lshrrev_b32 v12, 30, v11
v_subrev_i32 v11, vcc, v12, v10
v_mul_lo_i32 v11, s11, v11
v_mul_u32_u24 v15, 10, v12
v_ashrrev_i32 v12, 31, v11
v_lshlrev_b64 v[11:12], 2, v[11:12]
v_add_i32 v13, vcc, s6, v11
v_mov_b32 v11, s7
v_addc_u32 v14, vcc, v12, v11, vcc
v_and_b32 v11, 30, v15
v_lshlrev_b32 v12, v11, 1
flat_atomic_add v12, v[13:14], v12 glc
s_waitcnt vmcnt(0) lgkmcnt(0)
v_bfe_u32 v11, v12, v11, 10
v_mov_b32 v12, 0x2ac
v_cmp_gt_u32_e32 vcc, v12, v11
s_and_saveexec_b64 s[18:19], vcc
s_xor_b64 s[18:19], exec, s[18:19]
s_cbranch_execz BB20_52
v_mov_b32 v12, 0x2ac
v_mad_i32_i24 v10, v12, v10, v11
v_lshlrev_b32 v10, 4, v10
v_ashrrev_i32 v11, 31, v10
v_add_i32 v10, vcc, s4, v10
v_mov_b32 v12, s5
v_addc_u32 v11, vcc, v11, v12, vcc
v_cmp_ne_i64_e32 vcc, 0, v[10:11]
s_and_saveexec_b64 s[20:21], vcc
s_xor_b64 s[20:21], exec, s[20:21]
flat_store_dwordx4 v[10:11], v[3:6]
s_waitcnt vmcnt(0) lgkmcnt(0)
BB20_51:
s_or_b64 exec, exec, s[20:21]
BB20_52:
s_or_b64 exec, exec, s[18:19]
BB20_53:
s_or_b64 exec, exec, s[16:17]
BB20_54:
s_or_b64 exec, exec, s[14:15]
v_min_u32 v3, 0x100, v1
v_subrev_i32 v1, vcc, v3, v1
v_cmp_ne_i32_e32 vcc, 0, v1
s_and_b64 vcc, exec, vcc
s_cbranch_vccnz BB20_34
BB20_55:
s_endpgm
.section .AMDGPU.csdata
.section .AMDGPU.runtime_metadata
.byte 4
.byte 6
.long 13
.ascii "kernel_round7"
.byte 7
.byte 9
.long 4
.byte 10
.long 4
.byte 11
.long 4
.ascii "uint"
.byte 13
.byte 0
.byte 14
.short 7
.byte 16
.byte 0
.byte 8
.byte 7
.byte 9
.long 8
.byte 10
.long 8
.byte 11
.long 5
.ascii "char*"
.byte 13
.byte 1
.byte 14
.short 1
.byte 16
.byte 0
.byte 15
.byte 1
.byte 8
.byte 7
.byte 9
.long 8
.byte 10
.long 8
.byte 11
.long 5
.ascii "char*"
.byte 13
.byte 1
.byte 14
.short 1
.byte 16
.byte 0
.byte 15
.byte 1
.byte 8
.byte 7
.byte 9
.long 8
.byte 10
.long 8
.byte 11
.long 5
.ascii "uint*"
.byte 13
.byte 1
.byte 14
.short 7
.byte 16
.byte 0
.byte 15
.byte 1
.byte 8
.byte 7
.byte 9
.long 8
.byte 10
.long 8
.byte 11
.long 5
.ascii "uint*"
.byte 13
.byte 1
.byte 14
.short 7
.byte 16
.byte 0
.byte 15
.byte 1
.byte 8
.byte 7
.byte 9
.long 8
.byte 10
.long 8
.byte 11
.long 5
.ascii "uint*"
.byte 13
.byte 1
.byte 14
.short 7
.byte 16
.byte 0
.byte 15
.byte 1
.byte 8
.byte 5
.section .AMDGPU.config
.text
.globl kernel_round8
.p2align 8
.type kernel_round8,@function
.amdgpu_hsa_kernel kernel_round8
kernel_round8:
.amd_kernel_code_t
max_scratch_backing_memory_byte_size = 0
.dx10clamp
enable_ordered_append_gds = 0
private_element_size = 1
workitem_private_segment_byte_size = 28
workgroup_group_segment_byte_size = 11044
gds_segment_byte_size = 0
workgroup_fbarrier_count = 0
wavefront_sgpr_count = 28
workitem_vgpr_count = 14
group_segment_alignment = 4
private_segment_alignment = 4
.end_amd_kernel_code_t
s_add_u32 s10, s10, s13
s_lshr_b32 flat_scratch_hi, s10, 8
s_mov_b32 flat_scratch_lo, s11
s_cmp_gt_u32 s12, 0xfff
s_cbranch_scc1 BB21_55
v_mov_b32 v1, 0x100
v_cmp_gt_u32_e32 vcc, v1, v0
s_and_saveexec_b64 s[16:17], vcc
s_xor_b64 s[16:17], exec, s[16:17]
s_cbranch_execz BB21_10
v_add_i32 v1, vcc, 0xffffff00, v0
v_lshlrev_b32 v2, 2, v0
s_mov_b64 s[4:5], 0
s_mov_b32 m0, -1
BB21_12:
v_mov_b32 v3, 0x2ac
ds_write_b32 v2, v3
v_add_i32 v1, vcc, 0x100, v1
v_add_i32 v2, vcc, 0x400, v2
s_waitcnt lgkmcnt(0)
v_mov_b32 v3, 0xffffff00
v_cmp_gt_u32_e32 vcc, v3, v1
s_or_b64 s[4:5], vcc, s[4:5]
s_andn2_b64 exec, exec, s[4:5]
s_cbranch_execnz BB21_12
s_or_b64 exec, exec, s[4:5]
BB21_10:
s_or_b64 exec, exec, s[16:17]
s_load_dwordx2 s[10:11], s[8:9], 0x38
s_load_dwordx2 s[4:5], s[8:9], 0x40
s_load_dwordx2 s[14:15], s[8:9], 0x48
s_load_dwordx2 s[6:7], s[8:9], 0x50
v_mov_b32 v1, 0x2ac
v_cmp_gt_u32_e32 vcc, v1, v0
v_mov_b32 v1, 0
s_waitcnt lgkmcnt(0)
s_and_saveexec_b64 s[8:9], vcc
s_xor_b64 s[8:9], exec, s[8:9]
s_cbranch_execz BB21_19
v_sub_i32 v1, vcc, 0x2ab, v0
v_lshrrev_b32 v5, 8, v1
v_add_i32 v3, vcc, 1, v5
v_cmp_gt_u32_e32 vcc, 64, v3
v_cndmask_b32 v4, 0, -1, vcc
v_mov_b32 v1, v0
v_cmp_lt_u32_e32 vcc, 63, v3
s_and_saveexec_b64 s[16:17], vcc
s_xor_b64 s[16:17], exec, s[16:17]
s_cbranch_execz BB21_6
v_and_b32 v2, 63, v3
v_subrev_i32 v3, vcc, v2, v3
v_mov_b32 v4, -1
v_mov_b32 v1, v0
v_cmp_ne_i32_e32 vcc, 0, v3
s_and_saveexec_b64 s[18:19], vcc
s_xor_b64 s[18:19], exec, s[18:19]
s_cbranch_execz BB21_5
v_lshlrev_b32 v1, 8, v5
v_add_i32 v1, vcc, v1, v0
v_add_i32 v1, vcc, 0x100, v1
v_lshlrev_b32 v4, 8, v2
v_subrev_i32 v1, vcc, v4, v1
s_mov_b64 s[20:21], 0
v_mov_b32 v4, 0
s_mov_b32 m0, -1
BB21_8:
v_or_b32 v5, v4, v0
v_mov_b32 v6, 0x2ac
v_lshlrev_b32 v5, 1, v5
v_add_i32 v3, vcc, 0xffffffc0, v3
v_add_i32 v4, vcc, 0x4000, v4
v_cmp_eq_i32_e32 vcc, 0, v3
ds_write_b16 v5, v6 offset:1024
ds_write_b16 v5, v6 offset:1536
ds_write_b16 v5, v6 offset:2048
ds_write_b16 v5, v6 offset:2560
ds_write_b16 v5, v6 offset:3072
ds_write_b16 v5, v6 offset:3584
ds_write_b16 v5, v6 offset:4096
ds_write_b16 v5, v6 offset:4608
ds_write_b16 v5, v6 offset:5120
ds_write_b16 v5, v6 offset:5632
ds_write_b16 v5, v6 offset:6144
ds_write_b16 v5, v6 offset:6656
ds_write_b16 v5, v6 offset:7168
ds_write_b16 v5, v6 offset:7680
ds_write_b16 v5, v6 offset:8192
ds_write_b16 v5, v6 offset:8704
ds_write_b16 v5, v6 offset:9216
ds_write_b16 v5, v6 offset:9728
ds_write_b16 v5, v6 offset:10240
ds_write_b16 v5, v6 offset:10752
ds_write_b16 v5, v6 offset:11264
ds_write_b16 v5, v6 offset:11776
ds_write_b16 v5, v6 offset:12288
ds_write_b16 v5, v6 offset:12800
ds_write_b16 v5, v6 offset:13312
ds_write_b16 v5, v6 offset:13824
ds_write_b16 v5, v6 offset:14336
ds_write_b16 v5, v6 offset:14848
ds_write_b16 v5, v6 offset:15360
ds_write_b16 v5, v6 offset:15872
ds_write_b16 v5, v6 offset:16384
ds_write_b16 v5, v6 offset:16896
ds_write_b16 v5, v6 offset:17408
ds_write_b16 v5, v6 offset:17920
ds_write_b16 v5, v6 offset:18432
ds_write_b16 v5, v6 offset:18944
ds_write_b16 v5, v6 offset:19456
ds_write_b16 v5, v6 offset:19968
ds_write_b16 v5, v6 offset:20480
ds_write_b16 v5, v6 offset:20992
ds_write_b16 v5, v6 offset:21504
ds_write_b16 v5, v6 offset:22016
ds_write_b16 v5, v6 offset:22528
ds_write_b16 v5, v6 offset:23040
ds_write_b16 v5, v6 offset:23552
ds_write_b16 v5, v6 offset:24064
ds_write_b16 v5, v6 offset:24576
ds_write_b16 v5, v6 offset:25088
ds_write_b16 v5, v6 offset:25600
ds_write_b16 v5, v6 offset:26112
ds_write_b16 v5, v6 offset:26624
ds_write_b16 v5, v6 offset:27136
ds_write_b16 v5, v6 offset:27648
ds_write_b16 v5, v6 offset:28160
ds_write_b16 v5, v6 offset:28672
ds_write_b16 v5, v6 offset:29184
ds_write_b16 v5, v6 offset:29696
ds_write_b16 v5, v6 offset:30208
ds_write_b16 v5, v6 offset:30720
ds_write_b16 v5, v6 offset:31232
ds_write_b16 v5, v6 offset:31744
ds_write_b16 v5, v6 offset:32256
ds_write_b16 v5, v6 offset:32768
ds_write_b16 v5, v6 offset:33280
s_or_b64 s[20:21], vcc, s[20:21]
s_waitcnt lgkmcnt(0)
s_andn2_b64 exec, exec, s[20:21]
s_cbranch_execnz BB21_8
s_or_b64 exec, exec, s[20:21]
v_cmp_ne_i32_e32 vcc, 0, v2
v_cndmask_b32 v4, 0, -1, vcc
BB21_5:
s_or_b64 exec, exec, s[18:19]
BB21_6:
s_or_b64 exec, exec, s[16:17]
v_cmp_ne_i32_e32 vcc, 0, v4
s_and_saveexec_b64 s[16:17], vcc
s_xor_b64 s[16:17], exec, s[16:17]
s_cbranch_execz BB21_16
v_lshlrev_b32 v2, 1, v1
v_add_i32 v2, vcc, 0x400, v2
s_mov_b64 s[18:19], 0
s_mov_b32 m0, -1
BB21_14:
v_mov_b32 v3, 0x2ac
ds_write_b16 v2, v3
v_add_i32 v1, vcc, 0x100, v1
v_add_i32 v2, vcc, 0x200, v2
s_waitcnt lgkmcnt(0)
v_mov_b32 v3, 0x2ab
v_cmp_lt_u32_e32 vcc, v3, v1
s_or_b64 s[18:19], vcc, s[18:19]
s_andn2_b64 exec, exec, s[18:19]
s_cbranch_execnz BB21_14
s_or_b64 exec, exec, s[18:19]
BB21_16:
s_or_b64 exec, exec, s[16:17]
v_mov_b32 v1, 0
v_cmp_eq_i32_e32 vcc, 0, v0
s_and_saveexec_b64 s[16:17], vcc
s_xor_b64 s[16:17], exec, s[16:17]
s_cbranch_execz BB21_18
s_mul_i32 s18, s12, 0x55555555
s_lshr_b32 s19, s12, 1
s_add_i32 s18, s18, s19
s_lshr_b32 s19, s12, 3
s_sub_i32 s18, s18, s19
s_lshr_b32 s20, s18, 30
s_sub_i32 s18, s12, s20
s_mul_i32 s18, s18, 0xaaaaaaab
s_ashr_i32 s19, s18, 31
s_lshl_b64 s[18:19], s[18:19], 2
s_add_u32 s14, s14, s18
s_addc_u32 s15, s15, s19
v_mov_b32 v2, s15
v_mov_b32 v1, s14
flat_load_dword v1, v[1:2]
v_mul_u32_u24 v3, 10, s20
v_and_b32 v3, 30, v3
v_mov_b32 v2, 0
s_mov_b32 m0, -1
s_waitcnt vmcnt(0) lgkmcnt(0)
v_bfe_u32 v1, v1, v3, 10
v_min_u32 v1, 0x2ac, v1
ds_write_b32 v2, v1 offset:2392
s_waitcnt lgkmcnt(0)
BB21_18:
s_or_b64 exec, exec, s[16:17]
BB21_19:
s_or_b64 exec, exec, s[8:9]
s_barrier
v_cmp_ne_i32_e32 vcc, 0, v0
s_and_saveexec_b64 s[8:9], vcc
s_xor_b64 s[8:9], exec, s[8:9]
v_mov_b32 v1, 0
s_mov_b32 m0, -1
ds_read_b32 v1, v1 offset:2392
s_waitcnt lgkmcnt(0)
BB21_21:
s_or_b64 exec, exec, s[8:9]
s_barrier
v_cmp_eq_i32_e32 vcc, 0, v0
s_and_saveexec_b64 s[8:9], vcc
s_xor_b64 s[8:9], exec, s[8:9]
v_mov_b32 v2, 0
s_mov_b32 m0, -1
ds_write_b32 v2, v2 offset:2392
s_waitcnt lgkmcnt(0)
BB21_23:
s_or_b64 exec, exec, s[8:9]
s_barrier
v_cmp_lt_u32_e32 vcc, v0, v1
s_and_saveexec_b64 s[8:9], vcc
s_xor_b64 s[8:9], exec, s[8:9]
s_cbranch_execz BB21_31
v_lshlrev_b32 v3, 2, v0
s_mul_i32 s14, s12, 0x2ac0
v_lshlrev_b32 v2, 4, v0
v_add_i32 v2, vcc, s14, v2
v_add_i32 v3, vcc, 0x95c, v3
s_mov_b64 s[14:15], 0
v_mov_b32 v4, v0
BB21_25:
s_mov_b32 s16, 0
v_ashrrev_i32 v6, 31, v2
v_add_i32 v5, vcc, s10, v2
v_mov_b32 v7, s11
v_addc_u32 v6, vcc, v6, v7, vcc
v_mov_b32 v7, 0
v_mov_b32 v8, s16
BB21_26:
flat_load_dword v9, v[5:6]
v_add_i32 v7, vcc, 1, v7
s_waitcnt vmcnt(0) lgkmcnt(0)
buffer_store_dword v9, v8, s[0:3], s13 offen
v_add_i32 v8, vcc, 4, v8
v_add_i32 v5, vcc, 4, v5
v_addc_u32 v6, vcc, 0, v6, vcc
v_cmp_gt_u32_e32 vcc, 2, v7
s_and_b64 vcc, exec, vcc
s_waitcnt vmcnt(0) expcnt(0)
s_cbranch_vccnz BB21_26
s_mov_b32 s16, 0
v_mov_b32 v5, 0
v_mov_b32 v6, s16
v_mov_b32 v7, v3
BB21_28:
buffer_load_dword v8, v6, s[0:3], s13 offen
s_mov_b32 m0, -1
v_add_i32 v5, vcc, 1, v5
v_add_i32 v6, vcc, 4, v6
s_waitcnt vmcnt(0)
ds_write_b32 v7, v8
v_add_i32 v7, vcc, 0xab0, v7
v_cmp_gt_u32_e32 vcc, 2, v5
s_and_b64 vcc, exec, vcc
s_waitcnt lgkmcnt(0)
s_cbranch_vccnz BB21_28
v_mov_b32 v7, 0
buffer_load_dword v5, v7, s[0:3], s13 offen
s_mov_b32 m0, -1
v_add_i32 v2, vcc, 0x1000, v2
v_add_i32 v3, vcc, 0x400, v3
s_waitcnt vmcnt(0)
v_bfe_u32 v6, v5, 16, 4
v_and_b32 v5, 0xf000, v5
v_lshrrev_b32 v5, 8, v5
v_or_b32 v5, v5, v6
v_lshlrev_b32 v5, 2, v5
ds_wrxchg_rtn_b32 v5, v5, v4
v_lshlrev_b32 v6, 1, v4
s_waitcnt lgkmcnt(0)
v_add_i32 v4, vcc, 0x100, v4
v_cmp_ge_u32_e32 vcc, v4, v1
ds_write_b16 v6, v5 offset:1024
s_or_b64 s[14:15], vcc, s[14:15]
s_waitcnt lgkmcnt(0)
s_andn2_b64 exec, exec, s[14:15]
s_cbranch_execnz BB21_25
s_or_b64 exec, exec, s[14:15]
BB21_31:
s_or_b64 exec, exec, s[8:9]
s_barrier
v_mov_b32 v1, 0x2ac
v_cmp_gt_u32_e32 vcc, v1, v0
s_and_saveexec_b64 s[8:9], vcc
s_xor_b64 s[8:9], exec, s[8:9]
s_cbranch_execz BB21_36
s_mov_b64 s[10:11], 0
v_mov_b32 v1, v0
BB21_38:
v_lshlrev_b32 v2, 1, v1
s_mov_b32 m0, -1
ds_read_u16 v2, v2 offset:1024
v_mov_b32 v3, 0x2ac
s_waitcnt lgkmcnt(0)
v_cmp_gt_u32_e32 vcc, v3, v2
s_and_saveexec_b64 s[14:15], vcc
s_xor_b64 s[14:15], exec, s[14:15]
s_cbranch_execz BB21_44
s_mov_b64 s[16:17], 0
BB21_40:
v_mov_b32 v3, 1
v_mov_b32 v4, 0
s_mov_b32 m0, -1
ds_add_rtn_u32 v3, v4, v3 offset:2392
v_mov_b32 v4, 0x31a
s_waitcnt lgkmcnt(0)
v_cmp_gt_u32_e32 vcc, v4, v3
s_and_saveexec_b64 s[18:19], vcc
s_xor_b64 s[18:19], exec, s[18:19]
v_lshlrev_b32 v3, 1, v3
s_mov_b32 m0, -1
ds_write_b16 v3, v2 offset:7868
s_waitcnt lgkmcnt(0)
v_lshlrev_b32 v2, 1, v2
ds_read_u16 v2, v2 offset:1024
ds_write_b16 v3, v1 offset:9456
v_mov_b32 v3, 0x2ab
s_waitcnt lgkmcnt(0)
v_cmp_lt_u32_e32 vcc, v3, v2
s_or_b64 s[16:17], vcc, s[16:17]
BB21_42:
s_or_b64 exec, exec, s[18:19]
s_or_b64 s[16:17], s[18:19], s[16:17]
s_andn2_b64 exec, exec, s[16:17]
s_cbranch_execnz BB21_40
s_or_b64 exec, exec, s[16:17]
BB21_44:
s_or_b64 exec, exec, s[14:15]
v_add_i32 v1, vcc, 0x100, v1
v_mov_b32 v2, 0x2ab
v_cmp_lt_u32_e32 vcc, v2, v1
s_or_b64 s[10:11], vcc, s[10:11]
s_andn2_b64 exec, exec, s[10:11]
s_cbranch_execnz BB21_38
s_or_b64 exec, exec, s[10:11]
BB21_36:
s_or_b64 exec, exec, s[8:9]
s_barrier
v_mov_b32 v1, 0
s_mov_b32 m0, -1
ds_read_b32 v1, v1 offset:2392
s_waitcnt lgkmcnt(0)
v_min_u32 v1, 0x31a, v1
v_cmp_eq_i32_e32 vcc, 0, v1
s_and_b64 vcc, exec, vcc
s_cbranch_vccnz BB21_55
v_not_b32 v2, v0
s_movk_i32 s8, 0x95c
s_mov_b32 s9, 0x55555555
s_mov_b32 s10, 0xaaaaaaab
s_lshl_b32 s11, s12, 20
BB21_34:
v_mov_b32 v6, 0x2ac
v_cmp_lt_u32_e32 vcc, v0, v1
s_and_saveexec_b64 s[14:15], vcc
s_xor_b64 s[14:15], exec, s[14:15]
v_add_i32 v3, vcc, v1, v2
v_lshlrev_b32 v3, 1, v3
s_mov_b32 m0, -1
ds_read_u16 v6, v3 offset:9456
ds_read_u16 v3, v3 offset:7868
s_waitcnt lgkmcnt(0)
v_lshlrev_b32 v4, 2, v6
v_lshlrev_b32 v5, 2, v3
v_add_i32 v4, vcc, s8, v4
v_add_i32 v5, vcc, s8, v5
BB21_46:
s_or_b64 exec, exec, s[14:15]
v_mov_b32 v7, 0x2ac
v_cmp_gt_u32_e32 vcc, v7, v6
s_and_saveexec_b64 s[14:15], vcc
s_xor_b64 s[14:15], exec, s[14:15]
s_cbranch_execz BB21_54
s_mov_b32 m0, -1
ds_read_b32 v7, v4
ds_read_b32 v9, v5
ds_read_b32 v8, v4 offset:2736
ds_read_b32 v10, v5 offset:2736
s_waitcnt lgkmcnt(0)
v_xor_b32 v9, v7, v9
v_xor_b32 v7, v8, v10
v_lshrrev_b32 v8, 24, v9
v_lshlrev_b32 v9, 8, v7
v_or_b32 v9, v9, v8
v_or_b32 v8, v7, v9
v_cmp_ne_i32_e32 vcc, 0, v8
s_and_saveexec_b64 s[16:17], vcc
s_xor_b64 s[16:17], exec, s[16:17]
s_cbranch_execz BB21_53
v_and_b32 v8, 0xfff, v9
v_mul_lo_i32 v10, s9, v8
v_bfe_u32 v11, v9, 1, 11
v_bfe_u32 v9, v9, 3, 9
v_add_i32 v10, vcc, v10, v11
v_sub_i32 v9, vcc, v10, v9
v_lshrrev_b32 v10, 30, v9
v_sub_i32 v9, vcc, v8, v10
v_mul_lo_i32 v9, s10, v9
v_mul_u32_u24 v13, 10, v10
v_ashrrev_i32 v10, 31, v9
v_lshlrev_b64 v[9:10], 2, v[9:10]
v_add_i32 v11, vcc, s6, v9
v_mov_b32 v9, s7
v_addc_u32 v12, vcc, v10, v9, vcc
v_and_b32 v9, 30, v13
v_lshlrev_b32 v10, v9, 1
flat_atomic_add v10, v[11:12], v10 glc
s_waitcnt vmcnt(0) lgkmcnt(0)
v_bfe_u32 v9, v10, v9, 10
v_mov_b32 v10, 0x2ac
v_cmp_gt_u32_e32 vcc, v10, v9
s_and_saveexec_b64 s[18:19], vcc
s_xor_b64 s[18:19], exec, s[18:19]
s_cbranch_execz BB21_52
v_mov_b32 v10, 0x2ac
v_mad_i32_i24 v8, v10, v8, v9
v_lshlrev_b32 v8, 3, v8
v_ashrrev_i32 v10, 31, v8
v_add_i32 v9, vcc, s4, v8
v_mov_b32 v8, s5
v_addc_u32 v10, vcc, v10, v8, vcc
v_cmp_ne_i64_e32 vcc, 0, v[9:10]
s_and_saveexec_b64 s[20:21], vcc
s_xor_b64 s[20:21], exec, s[20:21]
v_lshlrev_b32 v8, 10, v3
v_and_b32 v6, 0x3ff, v6
v_and_b32 v8, 0xffc00, v8
v_or_b32 v6, s11, v6
v_or_b32 v8, v8, v6
flat_store_dwordx2 v[9:10], v[7:8]
s_waitcnt vmcnt(0) lgkmcnt(0)
BB21_51:
s_or_b64 exec, exec, s[20:21]
BB21_52:
s_or_b64 exec, exec, s[18:19]
BB21_53:
s_or_b64 exec, exec, s[16:17]
BB21_54:
s_or_b64 exec, exec, s[14:15]
v_min_u32 v6, 0x100, v1
v_subrev_i32 v1, vcc, v6, v1
v_cmp_ne_i32_e32 vcc, 0, v1
s_and_b64 vcc, exec, vcc
s_cbranch_vccnz BB21_34
BB21_55:
s_endpgm
.section .AMDGPU.csdata
.section .AMDGPU.runtime_metadata
.byte 4
.byte 6
.long 13
.ascii "kernel_round8"
.byte 7
.byte 9
.long 4
.byte 10
.long 4
.byte 11
.long 4
.ascii "uint"
.byte 13
.byte 0
.byte 14
.short 7
.byte 16
.byte 0
.byte 8
.byte 7
.byte 9
.long 8
.byte 10
.long 8
.byte 11
.long 5
.ascii "char*"
.byte 13
.byte 1
.byte 14
.short 1
.byte 16
.byte 0
.byte 15
.byte 1
.byte 8
.byte 7
.byte 9
.long 8
.byte 10
.long 8
.byte 11
.long 5
.ascii "char*"
.byte 13
.byte 1
.byte 14
.short 1
.byte 16
.byte 0
.byte 15
.byte 1
.byte 8
.byte 7
.byte 9
.long 8
.byte 10
.long 8
.byte 11
.long 5
.ascii "uint*"
.byte 13
.byte 1
.byte 14
.short 7
.byte 16
.byte 0
.byte 15
.byte 1
.byte 8
.byte 7
.byte 9
.long 8
.byte 10
.long 8
.byte 11
.long 5
.ascii "uint*"
.byte 13
.byte 1
.byte 14
.short 7
.byte 16
.byte 0
.byte 15
.byte 1
.byte 8
.byte 7
.byte 9
.long 8
.byte 10
.long 8
.byte 11
.long 5
.ascii "uint*"
.byte 13
.byte 1
.byte 14
.short 7
.byte 16
.byte 0
.byte 15
.byte 1
.byte 8
.byte 5
.section .AMDGPU.config
.text
.globl mark_potential_sol
.p2align 8
.type mark_potential_sol,@function
mark_potential_sol:
.amd_kernel_code_t
max_scratch_backing_memory_byte_size = 0
.dx10clamp
enable_ordered_append_gds = 0
private_element_size = 1
workitem_private_segment_byte_size = 0
workgroup_group_segment_byte_size = 0
gds_segment_byte_size = 0
workgroup_fbarrier_count = 0
wavefront_sgpr_count = 16
workitem_vgpr_count = 5
group_segment_alignment = 4
private_segment_alignment = 4
.end_amd_kernel_code_t
s_load_dwordx2 s[2:3], s[8:9], 0x30
v_mov_b32 v2, 1
s_waitcnt lgkmcnt(0)
v_mov_b32 v0, s2
v_mov_b32 v1, s3
flat_atomic_add v0, v[0:1], v2 glc
s_waitcnt vmcnt(0) lgkmcnt(0)
v_mov_b32 v1, 0x1000
v_cmp_gt_u32_e32 vcc, v1, v0
s_and_saveexec_b64 s[0:1], vcc
s_xor_b64 s[0:1], exec, s[0:1]
s_cbranch_execz BB22_2
v_ashrrev_i32 v1, 31, v0
v_lshlrev_b64 v[0:1], 3, v[0:1]
s_load_dword s4, s[8:9], 0x38
v_add_i32 v2, vcc, s2, v0
v_mov_b32 v0, s3
v_addc_u32 v3, vcc, v1, v0, vcc
s_load_dword s5, s[8:9], 0x3c
v_add_i32 v0, vcc, 8, v2
v_addc_u32 v1, vcc, 0, v3, vcc
v_add_i32 v2, vcc, 4, v2
v_addc_u32 v3, vcc, 0, v3, vcc
s_waitcnt lgkmcnt(0)
v_mov_b32 v4, s4
flat_store_dword v[2:3], v4
s_waitcnt vmcnt(0) lgkmcnt(0)
v_mov_b32 v2, s5
flat_store_dword v[0:1], v2
s_waitcnt vmcnt(0) lgkmcnt(0)
BB22_2:
s_or_b64 exec, exec, s[0:1]
s_endpgm
.section .AMDGPU.csdata
.section .AMDGPU.config
.text
.globl kernel_potential_sols
.p2align 8
.type kernel_potential_sols,@function
.amdgpu_hsa_kernel kernel_potential_sols
kernel_potential_sols:
.amd_kernel_code_t
max_scratch_backing_memory_byte_size = 0
.dx10clamp
enable_ordered_append_gds = 0
private_element_size = 1
workitem_private_segment_byte_size = 0
workgroup_group_segment_byte_size = 7868
gds_segment_byte_size = 0
workgroup_fbarrier_count = 0
wavefront_sgpr_count = 22
workitem_vgpr_count = 10
group_segment_alignment = 4
private_segment_alignment = 4
.end_amd_kernel_code_t
s_load_dword s0, s[4:5], 0x4
s_load_dword s1, s[8:9], 0x4
s_nop 0
s_load_dwordx2 s[4:5], s[8:9], 0x40
s_waitcnt lgkmcnt(0)
s_and_b32 s0, s0, 0xffff
s_mul_i32 s0, s0, s12
v_add_i32 v1, vcc, s0, v0
v_sub_i32 v2, vcc, 0, v1
v_cmp_eq_i32_e32 vcc, s1, v2
s_and_saveexec_b64 s[0:1], vcc
s_xor_b64 s[0:1], exec, s[0:1]
v_mov_b32 v2, s4
v_mov_b32 v4, 0
v_mov_b32 v3, s5
flat_store_dword v[2:3], v4
s_waitcnt vmcnt(0) lgkmcnt(0)
BB23_2:
s_or_b64 exec, exec, s[0:1]
s_barrier
s_load_dword s0, s[8:9], 0x4
s_waitcnt lgkmcnt(0)
v_add_i32 v2, vcc, s0, v1
v_mov_b32 v1, 0x100000
v_cmp_gt_u32_e32 vcc, v1, v2
s_and_saveexec_b64 s[2:3], vcc
s_xor_b64 s[2:3], exec, s[2:3]
s_cbranch_execz BB23_29
v_mov_b32 v1, 0x100
v_cmp_gt_u32_e32 vcc, v1, v0
s_and_saveexec_b64 s[10:11], vcc
s_xor_b64 s[10:11], exec, s[10:11]
s_cbranch_execz BB23_12
v_add_i32 v1, vcc, 0xffffff00, v0
v_lshlrev_b32 v3, 2, v0
s_mov_b64 s[0:1], 0
s_mov_b32 m0, -1
BB23_14:
v_mov_b32 v4, 0x2ac
ds_write_b32 v3, v4
v_add_i32 v1, vcc, 0x100, v1
v_add_i32 v3, vcc, 0x400, v3
s_waitcnt lgkmcnt(0)
v_mov_b32 v4, 0xffffff00
v_cmp_gt_u32_e32 vcc, v4, v1
s_or_b64 s[0:1], vcc, s[0:1]
s_andn2_b64 exec, exec, s[0:1]
s_cbranch_execnz BB23_14
s_or_b64 exec, exec, s[0:1]
BB23_12:
s_or_b64 exec, exec, s[10:11]
s_load_dwordx2 s[6:7], s[8:9], 0x38
s_load_dwordx2 s[0:1], s[8:9], 0x48
v_mov_b32 v3, 0x2ac
v_cmp_gt_u32_e32 vcc, v3, v0
v_lshrrev_b32 v1, 8, v2
v_mov_b32 v3, -1
v_mov_b32 v4, 0
s_waitcnt lgkmcnt(0)
s_and_saveexec_b64 s[8:9], vcc
s_xor_b64 s[8:9], exec, s[8:9]
s_cbranch_execz BB23_19
v_sub_i32 v3, vcc, 0x2ab, v0
v_lshrrev_b32 v7, 8, v3
v_add_i32 v5, vcc, 1, v7
v_cmp_gt_u32_e32 vcc, 64, v5
v_cndmask_b32 v6, 0, -1, vcc
v_mov_b32 v3, v0
v_cmp_lt_u32_e32 vcc, 63, v5
s_and_saveexec_b64 s[10:11], vcc
s_xor_b64 s[10:11], exec, s[10:11]
s_cbranch_execz BB23_8
v_and_b32 v4, 63, v5
v_subrev_i32 v5, vcc, v4, v5
v_mov_b32 v6, -1
v_mov_b32 v3, v0
v_cmp_ne_i32_e32 vcc, 0, v5
s_and_saveexec_b64 s[12:13], vcc
s_xor_b64 s[12:13], exec, s[12:13]
s_cbranch_execz BB23_7
v_lshlrev_b32 v3, 8, v7
v_add_i32 v3, vcc, v3, v0
v_add_i32 v3, vcc, 0x100, v3
v_lshlrev_b32 v6, 8, v4
v_subrev_i32 v3, vcc, v6, v3
s_mov_b64 s[14:15], 0
v_mov_b32 v6, 0
s_mov_b32 m0, -1
BB23_10:
v_or_b32 v7, v6, v0
v_mov_b32 v8, 0x2ac
v_lshlrev_b32 v7, 1, v7
v_add_i32 v6, vcc, 0x4000, v6
v_add_i32 v5, vcc, 0xffffffc0, v5
v_cmp_eq_i32_e32 vcc, 0, v5
ds_write_b16 v7, v8 offset:1024
ds_write_b16 v7, v8 offset:1536
ds_write_b16 v7, v8 offset:2048
ds_write_b16 v7, v8 offset:2560
ds_write_b16 v7, v8 offset:3072
ds_write_b16 v7, v8 offset:3584
ds_write_b16 v7, v8 offset:4096
ds_write_b16 v7, v8 offset:4608
ds_write_b16 v7, v8 offset:5120
ds_write_b16 v7, v8 offset:5632
ds_write_b16 v7, v8 offset:6144
ds_write_b16 v7, v8 offset:6656
ds_write_b16 v7, v8 offset:7168
ds_write_b16 v7, v8 offset:7680
ds_write_b16 v7, v8 offset:8192
ds_write_b16 v7, v8 offset:8704
ds_write_b16 v7, v8 offset:9216
ds_write_b16 v7, v8 offset:9728
ds_write_b16 v7, v8 offset:10240
ds_write_b16 v7, v8 offset:10752
ds_write_b16 v7, v8 offset:11264
ds_write_b16 v7, v8 offset:11776
ds_write_b16 v7, v8 offset:12288
ds_write_b16 v7, v8 offset:12800
ds_write_b16 v7, v8 offset:13312
ds_write_b16 v7, v8 offset:13824
ds_write_b16 v7, v8 offset:14336
ds_write_b16 v7, v8 offset:14848
ds_write_b16 v7, v8 offset:15360
ds_write_b16 v7, v8 offset:15872
ds_write_b16 v7, v8 offset:16384
ds_write_b16 v7, v8 offset:16896
ds_write_b16 v7, v8 offset:17408
ds_write_b16 v7, v8 offset:17920
ds_write_b16 v7, v8 offset:18432
ds_write_b16 v7, v8 offset:18944
ds_write_b16 v7, v8 offset:19456
ds_write_b16 v7, v8 offset:19968
ds_write_b16 v7, v8 offset:20480
ds_write_b16 v7, v8 offset:20992
ds_write_b16 v7, v8 offset:21504
ds_write_b16 v7, v8 offset:22016
ds_write_b16 v7, v8 offset:22528
ds_write_b16 v7, v8 offset:23040
ds_write_b16 v7, v8 offset:23552
ds_write_b16 v7, v8 offset:24064
ds_write_b16 v7, v8 offset:24576
ds_write_b16 v7, v8 offset:25088
ds_write_b16 v7, v8 offset:25600
ds_write_b16 v7, v8 offset:26112
ds_write_b16 v7, v8 offset:26624
ds_write_b16 v7, v8 offset:27136
ds_write_b16 v7, v8 offset:27648
ds_write_b16 v7, v8 offset:28160
ds_write_b16 v7, v8 offset:28672
ds_write_b16 v7, v8 offset:29184
ds_write_b16 v7, v8 offset:29696
ds_write_b16 v7, v8 offset:30208
ds_write_b16 v7, v8 offset:30720
ds_write_b16 v7, v8 offset:31232
ds_write_b16 v7, v8 offset:31744
ds_write_b16 v7, v8 offset:32256
ds_write_b16 v7, v8 offset:32768
ds_write_b16 v7, v8 offset:33280
s_or_b64 s[14:15], vcc, s[14:15]
s_waitcnt lgkmcnt(0)
s_andn2_b64 exec, exec, s[14:15]
s_cbranch_execnz BB23_10
s_or_b64 exec, exec, s[14:15]
v_cmp_ne_i32_e32 vcc, 0, v4
v_cndmask_b32 v6, 0, -1, vcc
BB23_7:
s_or_b64 exec, exec, s[12:13]
BB23_8:
s_or_b64 exec, exec, s[10:11]
v_cmp_ne_i32_e32 vcc, 0, v6
s_and_saveexec_b64 s[10:11], vcc
s_xor_b64 s[10:11], exec, s[10:11]
s_cbranch_execz BB23_18
v_lshlrev_b32 v4, 1, v3
v_add_i32 v4, vcc, 0x400, v4
s_mov_b64 s[12:13], 0
s_mov_b32 m0, -1
BB23_16:
v_mov_b32 v5, 0x2ac
ds_write_b16 v4, v5
v_add_i32 v3, vcc, 0x100, v3
v_add_i32 v4, vcc, 0x200, v4
s_waitcnt lgkmcnt(0)
v_mov_b32 v5, 0x2ab
v_cmp_lt_u32_e32 vcc, v5, v3
s_or_b64 s[12:13], vcc, s[12:13]
s_andn2_b64 exec, exec, s[12:13]
s_cbranch_execnz BB23_16
s_or_b64 exec, exec, s[12:13]
BB23_18:
s_or_b64 exec, exec, s[10:11]
v_cmp_ne_i32_e32 vcc, 0, v0
v_mov_b32 v4, -1
v_cndmask_b32 v3, 0, -1, vcc
BB23_19:
s_or_b64 exec, exec, s[8:9]
v_cmp_ne_i32_e32 vcc, 0, v3
s_and_saveexec_b64 s[8:9], vcc
s_xor_b64 s[8:9], exec, s[8:9]
v_mov_b32 v4, 0
s_mov_b32 m0, -1
ds_read_b32 v3, v4 offset:2392
s_waitcnt lgkmcnt(0)
BB23_21:
s_or_b64 exec, exec, s[8:9]
v_cmp_ne_i32_e32 vcc, 0, v4
s_and_saveexec_b64 s[8:9], vcc
s_xor_b64 s[8:9], exec, s[8:9]
s_cbranch_execz BB23_23
s_mov_b32 s10, 0x55555555
v_mul_lo_i32 v3, s10, v1
v_lshrrev_b32 v4, 9, v2
v_lshrrev_b32 v2, 11, v2
v_sub_i32 v2, vcc, v4, v2
v_add_i32 v2, vcc, v3, v2
v_lshrrev_b32 v6, 30, v2
v_sub_i32 v2, vcc, v1, v6
s_mov_b32 s10, 0xaaaaaaab
v_mul_lo_i32 v2, s10, v2
s_mov_b32 m0, -1
v_ashrrev_i32 v3, 31, v2
v_lshlrev_b64 v[2:3], 2, v[2:3]
v_add_i32 v4, vcc, s0, v2
v_mov_b32 v2, s1
v_addc_u32 v5, vcc, v3, v2, vcc
flat_load_dword v2, v[4:5]
v_mul_u32_u24 v3, 10, v6
v_and_b32 v3, 30, v3
v_mov_b32 v4, 0
s_waitcnt vmcnt(0) lgkmcnt(0)
v_bfe_u32 v2, v2, v3, 10
v_min_u32 v3, 0x2ac, v2
ds_write_b32 v4, v3 offset:2392
s_waitcnt lgkmcnt(0)
BB23_23:
s_or_b64 exec, exec, s[8:9]
s_barrier
s_barrier
v_mov_b32 v2, 0
v_cmp_lt_u32_e32 vcc, v0, v3
s_and_saveexec_b64 s[8:9], vcc
s_xor_b64 s[8:9], exec, s[8:9]
s_cbranch_execz BB23_27
s_movk_i32 s0, 0x1560
v_mul_lo_i32 v6, s0, v1
v_lshlrev_b32 v5, 1, v0
s_movk_i32 s10, 0x400
v_lshlrev_b32 v4, 2, v0
v_add_i32 v1, vcc, s10, v5
v_lshlrev_b32 v5, 3, v0
v_add_i32 v2, vcc, 0x140c, v4
v_add_i32 v5, vcc, v6, v5
v_add_i32 v4, vcc, 0x95c, v4
s_mov_b64 s[12:13], 0
v_mov_b32 v6, v0
s_mov_b32 m0, -1
BB23_25:
v_ashrrev_i32 v8, 31, v5
v_add_i32 v7, vcc, s6, v5
v_mov_b32 v9, s7
v_addc_u32 v8, vcc, v8, v9, vcc
flat_load_dwordx2 v[7:8], v[7:8]
v_add_i32 v5, vcc, 0x800, v5
s_waitcnt vmcnt(0) lgkmcnt(0)
ds_write_b32 v2, v8
ds_write_b32 v4, v7
s_waitcnt lgkmcnt(0)
v_bfe_u32 v8, v7, 12, 4
v_and_b32 v7, 0xf0, v7
v_or_b32 v7, v8, v7
v_lshlrev_b32 v7, 2, v7
ds_wrxchg_rtn_b32 v7, v7, v6
s_waitcnt lgkmcnt(0)
v_add_i32 v6, vcc, 0x100, v6
v_add_i32 v2, vcc, s10, v2
v_add_i32 v4, vcc, s10, v4
v_cmp_ge_u32 s[0:1], v6, v3
ds_write_b16 v1, v7
v_add_i32 v1, vcc, 0x200, v1
s_or_b64 s[12:13], s[0:1], s[12:13]
s_waitcnt lgkmcnt(0)
s_andn2_b64 exec, exec, s[12:13]
s_cbranch_execnz BB23_25
s_or_b64 exec, exec, s[12:13]
v_mov_b32 v2, -1
BB23_27:
s_or_b64 exec, exec, s[8:9]
s_barrier
v_cmp_ne_i32_e32 vcc, 0, v2
s_and_saveexec_b64 s[0:1], vcc
s_xor_b64 s[0:1], exec, s[0:1]
s_cbranch_execz BB23_28
s_mov_b64 s[6:7], 0
BB23_31:
v_mov_b32 v1, v0
v_lshlrev_b32 v0, 2, v1
s_mov_b32 m0, -1
ds_read_b32 v0, v0 offset:2396
s_mov_b64 s[8:9], 0
v_mov_b32 v2, v1
s_waitcnt lgkmcnt(0)
BB23_32:
v_lshlrev_b32 v2, 1, v2
s_mov_b32 m0, -1
ds_read_u16 v2, v2 offset:1024
v_mov_b32 v4, 0x2ac
v_mov_b32 v5, -1
s_waitcnt lgkmcnt(0)
v_cmp_gt_u32_e32 vcc, v4, v2
v_mov_b32 v4, 0
s_and_saveexec_b64 s[10:11], vcc
s_xor_b64 s[10:11], exec, s[10:11]
v_lshlrev_b32 v4, 2, v2
s_mov_b32 m0, -1
ds_read_b32 v4, v4 offset:2396
s_waitcnt lgkmcnt(0)
v_cmp_eq_i32_e32 vcc, v0, v4
v_cndmask_b32 v4, 0, -1, vcc
s_or_b64 s[8:9], vcc, s[8:9]
v_mov_b32 v5, 0
BB23_36:
s_or_b64 exec, exec, s[10:11]
s_or_b64 s[8:9], s[10:11], s[8:9]
s_andn2_b64 exec, exec, s[8:9]
s_cbranch_execnz BB23_32
s_or_b64 exec, exec, s[8:9]
v_cmp_ne_i32_e32 vcc, 0, v5
s_and_saveexec_b64 s[8:9], vcc
s_xor_b64 s[8:9], exec, s[8:9]
v_add_i32 v0, vcc, 0x100, v1
v_cmp_ge_u32_e32 vcc, v0, v3
s_or_b64 s[6:7], vcc, s[6:7]
BB23_39:
s_or_b64 exec, exec, s[8:9]
s_or_b64 s[6:7], s[8:9], s[6:7]
s_andn2_b64 exec, exec, s[6:7]
s_cbranch_execnz BB23_31
s_or_b64 exec, exec, s[6:7]
v_cmp_ne_i32_e32 vcc, 0, v4
s_and_saveexec_b64 s[6:7], vcc
s_xor_b64 s[6:7], exec, s[6:7]
s_cbranch_execz BB23_42
v_lshlrev_b32 v0, 2, v1
v_lshlrev_b32 v1, 2, v2
v_mov_b32 v2, s4
s_mov_b32 m0, -1
v_mov_b32 v4, 1
v_mov_b32 v3, s5
ds_read_b32 v0, v0 offset:5132
ds_read_b32 v1, v1 offset:5132
flat_atomic_add v2, v[2:3], v4 glc
s_waitcnt vmcnt(0) lgkmcnt(0)
v_mov_b32 v3, 0x1000
v_cmp_gt_u32_e32 vcc, v3, v2
s_and_saveexec_b64 s[8:9], vcc
s_xor_b64 s[8:9], exec, s[8:9]
s_cbranch_execz BB23_41
v_ashrrev_i32 v3, 31, v2
v_lshlrev_b64 v[2:3], 3, v[2:3]
v_add_i32 v4, vcc, s4, v2
v_mov_b32 v2, s5
v_addc_u32 v5, vcc, v3, v2, vcc
v_add_i32 v2, vcc, 4, v4
v_addc_u32 v3, vcc, 0, v5, vcc
v_add_i32 v4, vcc, 8, v4
v_addc_u32 v5, vcc, 0, v5, vcc
flat_store_dword v[2:3], v0
s_nop 0
flat_store_dword v[4:5], v1
s_waitcnt vmcnt(0) lgkmcnt(0)
BB23_41:
s_or_b64 exec, exec, s[8:9]
BB23_42:
s_or_b64 exec, exec, s[6:7]
BB23_28:
s_or_b64 exec, exec, s[0:1]
BB23_29:
s_or_b64 exec, exec, s[2:3]
s_endpgm
.section .AMDGPU.csdata
.section .AMDGPU.runtime_metadata
.byte 4
.byte 6
.long 21
.ascii "kernel_potential_sols"
.byte 7
.byte 9
.long 4
.byte 10
.long 4
.byte 11
.long 4
.ascii "uint"
.byte 13
.byte 0
.byte 14
.short 7
.byte 16
.byte 0
.byte 8
.byte 7
.byte 9
.long 8
.byte 10
.long 8
.byte 11
.long 5
.ascii "char*"
.byte 13
.byte 1
.byte 14
.short 1
.byte 16
.byte 0
.byte 15
.byte 1
.byte 8
.byte 7
.byte 9
.long 8
.byte 10
.long 8
.byte 11
.long 17
.ascii "potential_sols_t*"
.byte 13
.byte 1
.byte 14
.short 0
.byte 16
.byte 0
.byte 15
.byte 1
.byte 8
.byte 7
.byte 9
.long 8
.byte 10
.long 8
.byte 11
.long 5
.ascii "uint*"
.byte 13
.byte 1
.byte 14
.short 7
.byte 16
.byte 0
.byte 15
.byte 1
.byte 8
.byte 5
.section .AMDGPU.config
.text
.globl kernel_sols
.p2align 8
.type kernel_sols,@function
.amdgpu_hsa_kernel kernel_sols
kernel_sols:
.amd_kernel_code_t
max_scratch_backing_memory_byte_size = 0
.dx10clamp
enable_ordered_append_gds = 0
private_element_size = 1
workitem_private_segment_byte_size = 80
workgroup_group_segment_byte_size = 3080
gds_segment_byte_size = 0
workgroup_fbarrier_count = 0
wavefront_sgpr_count = 34
workitem_vgpr_count = 25
group_segment_alignment = 4
private_segment_alignment = 4
.end_amd_kernel_code_t
s_load_dwordx4 s[16:19], s[8:9], 0x30
s_load_dwordx4 s[20:23], s[8:9], 0x58
s_add_u32 s10, s10, s13
s_load_dwordx4 s[24:27], s[8:9], 0x78
v_mov_b32 v6, 0
s_waitcnt lgkmcnt(0)
v_mov_b32 v5, s19
v_mov_b32 v2, s18
v_mov_b32 v3, s17
v_mov_b32 v4, s16
s_load_dwordx4 s[16:19], s[8:9], 0x68
buffer_store_dword v5, v6, s[0:3], s13 offen offset:12
v_mov_b32 v6, 0
s_mov_b32 flat_scratch_lo, s11
s_lshr_b32 flat_scratch_hi, s10, 8
s_load_dwordx2 s[10:11], s[8:9], 0x88
buffer_store_dword v2, v6, s[0:3], s13 offen offset:8
v_mov_b32 v6, 0
s_load_dwordx2 s[6:7], s[8:9], 0x90
buffer_store_dword v3, v6, s[0:3], s13 offen offset:4
v_mov_b32 v1, 0
s_waitcnt vmcnt(1) expcnt(0)
v_mov_b32 v2, s22
s_waitcnt vmcnt(0)
v_mov_b32 v3, s21
v_mov_b32 v5, s23
buffer_store_dword v4, v1, s[0:3], s13 offen
s_nop 0
buffer_store_dword v5, v1, s[0:3], s13 offen offset:28
s_nop 0
buffer_store_dword v2, v1, s[0:3], s13 offen offset:24
s_nop 0
buffer_store_dword v3, v1, s[0:3], s13 offen offset:20
s_waitcnt vmcnt(3) expcnt(0)
v_mov_b32 v4, s20
s_waitcnt vmcnt(1) lgkmcnt(0)
v_mov_b32 v2, s18
s_waitcnt vmcnt(0)
v_mov_b32 v3, s17
v_mov_b32 v5, s19
buffer_store_dword v4, v1, s[0:3], s13 offen offset:16
s_nop 0
buffer_store_dword v5, v1, s[0:3], s13 offen offset:44
s_nop 0
buffer_store_dword v2, v1, s[0:3], s13 offen offset:40
s_nop 0
buffer_store_dword v3, v1, s[0:3], s13 offen offset:36
s_waitcnt vmcnt(3) expcnt(0)
v_mov_b32 v4, s16
s_waitcnt vmcnt(1)
v_mov_b32 v2, s26
s_waitcnt vmcnt(0)
v_mov_b32 v3, s25
v_mov_b32 v5, s27
buffer_store_dword v4, v1, s[0:3], s13 offen offset:32
s_nop 0
buffer_store_dword v5, v1, s[0:3], s13 offen offset:60
s_nop 0
buffer_store_dword v2, v1, s[0:3], s13 offen offset:56
s_nop 0
buffer_store_dword v3, v1, s[0:3], s13 offen offset:52
s_waitcnt vmcnt(3) expcnt(0)
v_mov_b32 v4, s24
s_waitcnt vmcnt(1)
v_mov_b32 v2, s10
s_waitcnt vmcnt(0)
v_mov_b32 v3, s11
buffer_store_dword v4, v1, s[0:3], s13 offen offset:48
s_nop 0
buffer_store_dword v3, v1, s[0:3], s13 offen offset:68
s_nop 0
buffer_store_dword v2, v1, s[0:3], s13 offen offset:64
s_waitcnt vmcnt(0) expcnt(0)
v_mov_b32 v1, s6
v_mov_b32 v2, s7
flat_load_dword v2, v[1:2]
s_load_dword s4, s[4:5], 0x4
s_load_dword s5, s[8:9], 0x4
v_mov_b32 v3, 0x100000
s_waitcnt lgkmcnt(0)
s_and_b32 s4, s4, 0xffff
s_mul_i32 s4, s4, s12
v_add_i32 v1, vcc, s4, v0
v_add_i32 v4, vcc, s5, v1
v_lshrrev_b32 v1, 8, v4
v_cmp_gt_u32 s[4:5], v3, v4
s_waitcnt vmcnt(0)
v_cmp_lt_u32_e32 vcc, v1, v2
s_and_b64 s[4:5], s[4:5], vcc
s_and_saveexec_b64 s[10:11], s[4:5]
s_xor_b64 s[10:11], exec, s[10:11]
s_cbranch_execz BB24_56
v_cmp_eq_i32_e32 vcc, 0, v0
s_and_saveexec_b64 s[4:5], vcc
s_xor_b64 s[4:5], exec, s[4:5]
s_cbranch_execz BB24_3
v_mov_b32 v2, 0
v_lshlrev_b64 v[1:2], 3, v[1:2]
v_add_i32 v4, vcc, s6, v1
v_mov_b32 v1, s7
v_addc_u32 v5, vcc, v2, v1, vcc
v_add_i32 v1, vcc, 4, v4
v_mov_b32 v3, 0
s_mov_b32 m0, -1
ds_write_b32 v3, v3 offset:2048
v_addc_u32 v2, vcc, 0, v5, vcc
flat_load_dword v2, v[1:2]
v_add_i32 v1, vcc, 8, v4
s_waitcnt vmcnt(0) lgkmcnt(0)
ds_write_b32 v3, v2
s_waitcnt lgkmcnt(0)
v_addc_u32 v2, vcc, 0, v5, vcc
flat_load_dword v1, v[1:2]
s_waitcnt vmcnt(0) lgkmcnt(0)
ds_write_b32 v3, v1 offset:4
s_waitcnt lgkmcnt(0)
BB24_3:
s_or_b64 exec, exec, s[4:5]
s_load_dwordx2 s[8:9], s[8:9], 0x40
s_waitcnt lgkmcnt(0)
s_barrier
v_lshlrev_b32 v1, 3, v0
s_movk_i32 s4, 0x804
v_lshlrev_b32 v2, 2, v0
v_add_i32 v3, vcc, s4, v1
v_add_i32 v4, vcc, s4, v2
v_mov_b32 v5, 7
s_movk_i32 s12, 0x3ff
s_movk_i32 s14, 0x100
s_movk_i32 s15, 0x800
s_movk_i32 s16, 0x400
BB24_4:
v_sub_i32 v6, vcc, 8, v5
v_and_b32 v8, 1, v5
v_cmp_eq_i32_e32 vcc, 0, v8
v_lshlrev_b32 v6, v6, 1
v_mov_b32 v7, -1
s_and_b64 vcc, exec, vcc
s_cbranch_vccnz BB24_13
v_cmp_lt_u32_e32 vcc, v0, v6
s_and_saveexec_b64 s[18:19], vcc
s_xor_b64 s[18:19], exec, s[18:19]
s_cbranch_execz BB24_27
v_lshlrev_b32 v7, 3, v5
v_add_i32 v8, vcc, 0, v7
buffer_load_dword v7, v8, s[0:3], s13 offen
s_nop 0
buffer_load_dword v9, v8, s[0:3], s13 offen offset:4
v_or_b32 v8, 7, v5
v_cmp_eq_i32 s[4:5], 7, v8
v_cmp_gt_u32_e32 vcc, 6, v5
v_cndmask_b32 v8, 8, 16, s[4:5]
v_cndmask_b32 v8, v8, 32, vcc
v_cmp_eq_i32_e32 vcc, 7, v5
v_or_b32 v11, 1, v5
v_cndmask_b32 v10, 1, 2, vcc
v_cmp_gt_i32_e32 vcc, 3, v11
v_mov_b32 v12, 0
s_and_b64 vcc, exec, vcc
s_waitcnt vmcnt(0)
s_cbranch_vccz BB24_7
v_cmp_ne_i32_e32 vcc, 1, v11
s_and_b64 vcc, exec, vcc
s_cbranch_vccnz BB24_22
s_mov_b64 s[6:7], 0
v_mov_b32 v10, v2
v_mov_b32 v11, v3
v_mov_b32 v12, v0
BB24_12:
s_mov_b32 m0, -1
ds_read_b32 v15, v10
v_mov_b32 v16, 0x2ac
s_waitcnt lgkmcnt(0)
v_lshrrev_b32 v17, 20, v15
v_bfe_u32 v13, v15, 10, 10
v_mad_u32_u24 v13, v17, v16, v13
v_mul_i32_i24 v13, v8, v13
v_add_i32 v13, vcc, v13, v7
v_addc_u32 v14, vcc, 0, v9, vcc
v_add_i32 v13, vcc, 24, v13
v_addc_u32 v14, vcc, 0, v14, vcc
flat_load_dword v18, v[13:14]
v_and_b32 v13, s12, v15
v_mad_u32_u24 v13, v17, v16, v13
v_mul_i32_i24 v13, v8, v13
v_add_i32 v13, vcc, v13, v7
v_addc_u32 v15, vcc, 0, v9, vcc
v_mov_b32 v14, 0
v_add_i32 v13, vcc, 24, v13
v_addc_u32 v14, vcc, v15, v14, vcc
v_add_i32 v12, vcc, s14, v12
v_add_i32 v10, vcc, s16, v10
v_cmp_ge_u32 s[4:5], v12, v6
s_waitcnt vmcnt(0) lgkmcnt(0)
ds_write_b32 v11, v18 offset:4
flat_load_dword v13, v[13:14]
s_waitcnt vmcnt(0) lgkmcnt(0)
ds_write_b32 v11, v13
v_add_i32 v11, vcc, s15, v11
s_or_b64 s[6:7], s[4:5], s[6:7]
s_waitcnt lgkmcnt(0)
s_andn2_b64 exec, exec, s[6:7]
s_cbranch_execnz BB24_12
s_or_b64 exec, exec, s[6:7]
s_branch BB24_27
BB24_7:
v_cmp_eq_i32_e32 vcc, 3, v11
s_and_b64 vcc, exec, vcc
s_cbranch_vccz BB24_22
v_cmp_eq_i32_e32 vcc, 3, v11
v_cmp_eq_i32 s[4:5], 6, v5
v_cndmask_b32 v11, 4, 5, vcc
v_add_i32 v13, vcc, -2, v5
v_cmp_gt_u32_e32 vcc, 4, v13
v_cndmask_b32 v10, v10, 3, s[4:5]
v_cndmask_b32 v12, v12, 0, s[4:5]
v_cndmask_b32 v10, v10, v11, vcc
v_cndmask_b32 v11, v12, 0, vcc
s_mov_b64 s[6:7], 0
v_mov_b32 v12, v2
v_mov_b32 v13, v3
v_mov_b32 v14, v0
BB24_9:
s_mov_b32 m0, -1
ds_read_b32 v17, v12
v_mov_b32 v18, 0x2ac
s_waitcnt lgkmcnt(0)
v_lshrrev_b32 v19, 20, v17
v_bfe_u32 v15, v17, 10, 10
v_mad_u32_u24 v15, v19, v18, v15
v_mul_i32_i24 v15, v8, v15
v_add_i32 v15, vcc, v15, v7
v_addc_u32 v16, vcc, 0, v9, vcc
v_add_i32 v15, vcc, 20, v15
v_addc_u32 v16, vcc, 0, v16, vcc
flat_load_dword v20, v[15:16]
v_and_b32 v17, s12, v17
v_mad_u32_u24 v17, v19, v18, v17
v_mul_i32_i24 v17, v8, v17
v_add_i32 v17, vcc, v17, v7
v_lshlrev_b64 v[15:16], 2, v[10:11]
v_addc_u32 v18, vcc, 0, v9, vcc
v_add_i32 v17, vcc, v15, v17
v_addc_u32 v18, vcc, v18, v16, vcc
v_add_i32 v14, vcc, s14, v14
v_add_i32 v12, vcc, s16, v12
v_cmp_ge_u32 s[4:5], v14, v6
s_waitcnt vmcnt(0) lgkmcnt(0)
ds_write_b32 v13, v20 offset:4
flat_load_dword v15, v[17:18]
s_waitcnt vmcnt(0) lgkmcnt(0)
ds_write_b32 v13, v15
v_add_i32 v13, vcc, s15, v13
s_or_b64 s[6:7], s[4:5], s[6:7]
s_waitcnt lgkmcnt(0)
s_andn2_b64 exec, exec, s[6:7]
s_cbranch_execnz BB24_9
s_or_b64 exec, exec, s[6:7]
s_branch BB24_27
BB24_22:
v_cmp_eq_i32_e32 vcc, 6, v5
v_cmp_eq_i32 s[4:5], 3, v11
v_cndmask_b32 v14, v12, 0, vcc
v_cndmask_b32 v13, v10, 3, vcc
v_add_i32 v15, vcc, -2, v5
v_cmp_eq_i32 s[6:7], 5, v11
v_cmp_gt_u32_e32 vcc, 4, v15
v_cndmask_b32 v12, 4, 5, s[4:5]
v_cndmask_b32 v11, v14, 0, s[6:7]
v_cndmask_b32 v10, v13, 4, s[6:7]
v_cndmask_b32 v12, v13, v12, vcc
v_cndmask_b32 v13, v14, 0, vcc
s_mov_b64 s[6:7], 0
v_mov_b32 v14, v3
v_mov_b32 v15, v2
v_mov_b32 v16, v0
BB24_23:
s_mov_b32 m0, -1
ds_read_b32 v21, v15
v_mov_b32 v22, 0x2ac
v_lshlrev_b64 v[17:18], 2, v[10:11]
s_waitcnt lgkmcnt(0)
v_lshrrev_b32 v23, 20, v21
v_bfe_u32 v19, v21, 10, 10
v_mad_u32_u24 v19, v23, v22, v19
v_mul_i32_i24 v19, v8, v19
v_add_i32 v19, vcc, v19, v7
v_addc_u32 v20, vcc, 0, v9, vcc
v_add_i32 v19, vcc, v17, v19
v_addc_u32 v20, vcc, v20, v18, vcc
flat_load_dword v24, v[19:20]
v_and_b32 v19, s12, v21
v_mad_u32_u24 v19, v23, v22, v19
v_mul_i32_i24 v19, v8, v19
v_add_i32 v19, vcc, v19, v7
v_lshlrev_b64 v[17:18], 2, v[12:13]
v_addc_u32 v20, vcc, 0, v9, vcc
v_add_i32 v19, vcc, v17, v19
v_addc_u32 v20, vcc, v20, v18, vcc
v_add_i32 v16, vcc, s14, v16
v_add_i32 v15, vcc, s16, v15
v_cmp_ge_u32 s[4:5], v16, v6
s_waitcnt vmcnt(0) lgkmcnt(0)
ds_write_b32 v14, v24 offset:4
flat_load_dword v17, v[19:20]
s_waitcnt vmcnt(0) lgkmcnt(0)
ds_write_b32 v14, v17
v_add_i32 v14, vcc, s15, v14
s_or_b64 s[6:7], s[4:5], s[6:7]
s_waitcnt lgkmcnt(0)
s_andn2_b64 exec, exec, s[6:7]
s_cbranch_execnz BB24_23
s_or_b64 exec, exec, s[6:7]
BB24_27:
s_or_b64 exec, exec, s[18:19]
v_mov_b32 v7, 0
BB24_13:
v_cmp_ne_i32_e32 vcc, 0, v7
v_cndmask_b32 v7, 0, 1, vcc
v_cmp_ne_i32_e32 vcc, 1, v7
s_and_b64 vcc, exec, vcc
s_cbranch_vccnz BB24_32
v_cmp_lt_u32_e32 vcc, v0, v6
s_and_saveexec_b64 s[18:19], vcc
s_xor_b64 s[18:19], exec, s[18:19]
s_cbranch_execz BB24_31
v_lshlrev_b32 v7, 3, v5
v_add_i32 v8, vcc, 0, v7
buffer_load_dword v7, v8, s[0:3], s13 offen
s_nop 0
buffer_load_dword v9, v8, s[0:3], s13 offen offset:4
v_or_b32 v8, 7, v5
v_cmp_eq_i32 s[4:5], 7, v8
v_cmp_gt_u32_e32 vcc, 6, v5
v_cndmask_b32 v8, 8, 16, s[4:5]
v_cndmask_b32 v8, v8, 32, vcc
v_cmp_eq_i32_e32 vcc, 7, v5
v_or_b32 v11, 1, v5
v_cndmask_b32 v10, 1, 2, vcc
v_cmp_gt_i32_e32 vcc, 3, v11
v_mov_b32 v12, 0
s_and_b64 vcc, exec, vcc
s_waitcnt vmcnt(0)
s_cbranch_vccz BB24_16
v_cmp_ne_i32_e32 vcc, 1, v11
s_and_b64 vcc, exec, vcc
s_cbranch_vccnz BB24_24
s_mov_b64 s[6:7], 0
v_mov_b32 v10, v4
v_mov_b32 v11, v1
v_mov_b32 v12, v0
BB24_21:
s_mov_b32 m0, -1
ds_read_b32 v15, v10
v_mov_b32 v16, 0x2ac
s_waitcnt lgkmcnt(0)
v_lshrrev_b32 v17, 20, v15
v_bfe_u32 v13, v15, 10, 10
v_mad_u32_u24 v13, v17, v16, v13
v_mul_i32_i24 v13, v8, v13
v_add_i32 v13, vcc, v13, v7
v_addc_u32 v14, vcc, 0, v9, vcc
v_add_i32 v13, vcc, 24, v13
v_addc_u32 v14, vcc, 0, v14, vcc
flat_load_dword v18, v[13:14]
v_and_b32 v13, s12, v15
v_mad_u32_u24 v13, v17, v16, v13
v_mul_i32_i24 v13, v8, v13
v_add_i32 v13, vcc, v13, v7
v_addc_u32 v15, vcc, 0, v9, vcc
v_mov_b32 v14, 0
v_add_i32 v13, vcc, 24, v13
v_addc_u32 v14, vcc, v15, v14, vcc
v_add_i32 v12, vcc, s14, v12
v_add_i32 v10, vcc, s16, v10
v_cmp_ge_u32 s[4:5], v12, v6
s_waitcnt vmcnt(0) lgkmcnt(0)
ds_write_b32 v11, v18 offset:4
flat_load_dword v13, v[13:14]
s_waitcnt vmcnt(0) lgkmcnt(0)
ds_write_b32 v11, v13
v_add_i32 v11, vcc, s15, v11
s_or_b64 s[6:7], s[4:5], s[6:7]
s_waitcnt lgkmcnt(0)
s_andn2_b64 exec, exec, s[6:7]
s_cbranch_execnz BB24_21
s_or_b64 exec, exec, s[6:7]
s_branch BB24_31
BB24_16:
v_cmp_eq_i32_e32 vcc, 3, v11
s_and_b64 vcc, exec, vcc
s_cbranch_vccz BB24_24
v_cmp_eq_i32_e32 vcc, 3, v11
v_cmp_eq_i32 s[4:5], 6, v5
v_cndmask_b32 v11, 4, 5, vcc
v_add_i32 v13, vcc, -2, v5
v_cmp_gt_u32_e32 vcc, 4, v13
v_cndmask_b32 v10, v10, 3, s[4:5]
v_cndmask_b32 v12, v12, 0, s[4:5]
v_cndmask_b32 v10, v10, v11, vcc
v_cndmask_b32 v11, v12, 0, vcc
s_mov_b64 s[6:7], 0
v_mov_b32 v12, v4
v_mov_b32 v13, v1
v_mov_b32 v14, v0
BB24_18:
s_mov_b32 m0, -1
ds_read_b32 v17, v12
v_mov_b32 v18, 0x2ac
s_waitcnt lgkmcnt(0)
v_lshrrev_b32 v19, 20, v17
v_bfe_u32 v15, v17, 10, 10
v_mad_u32_u24 v15, v19, v18, v15
v_mul_i32_i24 v15, v8, v15
v_add_i32 v15, vcc, v15, v7
v_addc_u32 v16, vcc, 0, v9, vcc
v_add_i32 v15, vcc, 20, v15
v_addc_u32 v16, vcc, 0, v16, vcc
flat_load_dword v20, v[15:16]
v_and_b32 v17, s12, v17
v_mad_u32_u24 v17, v19, v18, v17
v_mul_i32_i24 v17, v8, v17
v_add_i32 v17, vcc, v17, v7
v_lshlrev_b64 v[15:16], 2, v[10:11]
v_addc_u32 v18, vcc, 0, v9, vcc
v_add_i32 v17, vcc, v15, v17
v_addc_u32 v18, vcc, v18, v16, vcc
v_add_i32 v14, vcc, s14, v14
v_add_i32 v12, vcc, s16, v12
v_cmp_ge_u32 s[4:5], v14, v6
s_waitcnt vmcnt(0) lgkmcnt(0)
ds_write_b32 v13, v20 offset:4
flat_load_dword v15, v[17:18]
s_waitcnt vmcnt(0) lgkmcnt(0)
ds_write_b32 v13, v15
v_add_i32 v13, vcc, s15, v13
s_or_b64 s[6:7], s[4:5], s[6:7]
s_waitcnt lgkmcnt(0)
s_andn2_b64 exec, exec, s[6:7]
s_cbranch_execnz BB24_18
s_or_b64 exec, exec, s[6:7]
s_branch BB24_31
BB24_24:
v_cmp_eq_i32_e32 vcc, 6, v5
v_cmp_eq_i32 s[4:5], 3, v11
v_cndmask_b32 v14, v12, 0, vcc
v_cndmask_b32 v13, v10, 3, vcc
v_add_i32 v15, vcc, -2, v5
v_cmp_eq_i32 s[6:7], 5, v11
v_cmp_gt_u32_e32 vcc, 4, v15
v_cndmask_b32 v12, 4, 5, s[4:5]
v_cndmask_b32 v11, v14, 0, s[6:7]
v_cndmask_b32 v10, v13, 4, s[6:7]
v_cndmask_b32 v12, v13, v12, vcc
v_cndmask_b32 v13, v14, 0, vcc
s_mov_b64 s[6:7], 0
v_mov_b32 v14, v1
v_mov_b32 v15, v4
v_mov_b32 v16, v0
BB24_25:
s_mov_b32 m0, -1
ds_read_b32 v21, v15
v_mov_b32 v22, 0x2ac
v_lshlrev_b64 v[17:18], 2, v[10:11]
s_waitcnt lgkmcnt(0)
v_lshrrev_b32 v23, 20, v21
v_bfe_u32 v19, v21, 10, 10
v_mad_u32_u24 v19, v23, v22, v19
v_mul_i32_i24 v19, v8, v19
v_add_i32 v19, vcc, v19, v7
v_addc_u32 v20, vcc, 0, v9, vcc
v_add_i32 v19, vcc, v17, v19
v_addc_u32 v20, vcc, v20, v18, vcc
flat_load_dword v24, v[19:20]
v_and_b32 v19, s12, v21
v_mad_u32_u24 v19, v23, v22, v19
v_mul_i32_i24 v19, v8, v19
v_add_i32 v19, vcc, v19, v7
v_lshlrev_b64 v[17:18], 2, v[12:13]
v_addc_u32 v20, vcc, 0, v9, vcc
v_add_i32 v19, vcc, v17, v19
v_addc_u32 v20, vcc, v20, v18, vcc
v_add_i32 v16, vcc, s14, v16
v_add_i32 v15, vcc, s16, v15
v_cmp_ge_u32 s[4:5], v16, v6
s_waitcnt vmcnt(0) lgkmcnt(0)
ds_write_b32 v14, v24 offset:4
flat_load_dword v17, v[19:20]
s_waitcnt vmcnt(0) lgkmcnt(0)
ds_write_b32 v14, v17
v_add_i32 v14, vcc, s15, v14
s_or_b64 s[6:7], s[4:5], s[6:7]
s_waitcnt lgkmcnt(0)
s_andn2_b64 exec, exec, s[6:7]
s_cbranch_execnz BB24_25
s_or_b64 exec, exec, s[6:7]
BB24_31:
s_or_b64 exec, exec, s[18:19]
BB24_32:
s_barrier
v_add_i32 v6, vcc, -1, v5
v_cmp_gt_i32_e32 vcc, 1, v5
v_mov_b32 v5, v6
s_and_b64 vcc, exec, vcc
s_cbranch_vccz BB24_4
v_add_i32 v1, vcc, 3, v0
v_mov_b32 v3, 0x1fe
v_cmp_gt_u32_e32 vcc, v3, v1
s_and_saveexec_b64 s[4:5], vcc
s_xor_b64 s[4:5], exec, s[4:5]
s_cbranch_execz BB24_37
v_mov_b32 v3, 0
s_mov_b32 m0, -1
ds_read_b32 v3, v3 offset:2044
s_mov_b64 s[6:7], 0
v_mov_b32 v4, v2
s_waitcnt lgkmcnt(0)
BB24_39:
s_mov_b32 m0, -1
ds_read_b32 v5, v4 offset:12
s_waitcnt lgkmcnt(0)
v_cmp_eq_i32_e32 vcc, v5, v3
s_and_saveexec_b64 s[14:15], vcc
s_xor_b64 s[14:15], exec, s[14:15]
v_mov_b32 v5, 1
v_mov_b32 v6, 0
s_mov_b32 m0, -1
ds_add_u32 v6, v5 offset:2048
s_waitcnt lgkmcnt(0)
BB24_41:
s_or_b64 exec, exec, s[14:15]
v_add_i32 v1, vcc, 0x100, v1
v_add_i32 v4, vcc, 0x400, v4
v_mov_b32 v5, 0x1fd
v_cmp_lt_u32_e32 vcc, v5, v1
s_or_b64 s[6:7], vcc, s[6:7]
s_andn2_b64 exec, exec, s[6:7]
s_cbranch_execnz BB24_39
s_or_b64 exec, exec, s[6:7]
BB24_37:
s_or_b64 exec, exec, s[4:5]
s_barrier
v_mov_b32 v1, 0
s_mov_b32 m0, -1
ds_read_b32 v1, v1 offset:2048
s_waitcnt lgkmcnt(0)
v_or_b32 v1, v1, v0
v_cmp_ne_i32_e32 vcc, 0, v1
s_and_saveexec_b64 s[4:5], vcc
s_xor_b64 s[4:5], exec, s[4:5]
v_mov_b32 v1, 0
s_mov_b32 m0, -1
ds_read_b32 v3, v1 offset:3076
s_waitcnt lgkmcnt(0)
BB24_43:
s_or_saveexec_b64 s[4:5], s[4:5]
s_and_b64 s[4:5], exec, s[4:5]
s_xor_b64 exec, exec, s[4:5]
v_mov_b32 v3, s8
v_mov_b32 v1, 1
v_mov_b32 v4, s9
flat_atomic_add v3, v[3:4], v1 glc
s_waitcnt vmcnt(0) lgkmcnt(0)
v_mov_b32 v1, 0
s_mov_b32 m0, -1
ds_write_b32 v1, v3 offset:3076
s_waitcnt lgkmcnt(0)
BB24_45:
s_or_b64 exec, exec, s[4:5]
s_barrier
v_mov_b32 v1, 0
s_mov_b32 m0, -1
ds_read_b32 v1, v1 offset:2048
v_cmp_gt_u32_e32 vcc, 11, v3
s_waitcnt lgkmcnt(0)
v_cmp_eq_i32 s[4:5], 0, v1
s_and_b64 s[4:5], vcc, s[4:5]
s_and_saveexec_b64 s[6:7], s[4:5]
s_xor_b64 s[6:7], exec, s[6:7]
s_cbranch_execz BB24_55
v_mov_b32 v1, 0x1ff
v_cmp_lt_u32_e32 vcc, v1, v0
s_and_saveexec_b64 s[14:15], vcc
s_xor_b64 s[14:15], exec, s[14:15]
v_ashrrev_i32 v4, 31, v3
BB24_48:
s_or_saveexec_b64 s[14:15], s[14:15]
s_and_b64 s[14:15], exec, s[14:15]
s_xor_b64 exec, exec, s[14:15]
s_cbranch_execz BB24_50
v_ashrrev_i32 v4, 31, v3
v_mov_b32 v1, 0
v_lshlrev_b64 v[5:6], 11, v[3:4]
v_lshlrev_b64 v[7:8], 2, v[0:1]
v_add_i32 v1, vcc, v5, v7
v_addc_u32 v5, vcc, v6, v8, vcc
v_add_i32 v1, vcc, s8, v1
v_mov_b32 v6, s9
v_addc_u32 v6, vcc, v5, v6, vcc
v_add_i32 v5, vcc, 20, v1
v_addc_u32 v6, vcc, 0, v6, vcc
s_mov_b64 s[16:17], 0
s_movk_i32 s12, 0x400
v_mov_b32 v1, v0
s_mov_b32 m0, -1
BB24_52:
ds_read_b32 v7, v2
v_add_i32 v1, vcc, 0x100, v1
s_mov_b32 s18, s12
v_add_i32 v2, vcc, s12, v2
v_mov_b32 v8, 0x1ff
s_waitcnt lgkmcnt(0)
flat_store_dword v[5:6], v7
s_waitcnt vmcnt(0) lgkmcnt(0)
v_add_i32 v5, vcc, s18, v5
v_addc_u32 v6, vcc, 0, v6, vcc
v_cmp_lt_u32 s[4:5], v8, v1
s_or_b64 s[16:17], s[4:5], s[16:17]
s_andn2_b64 exec, exec, s[16:17]
s_cbranch_execnz BB24_52
s_or_b64 exec, exec, s[16:17]
BB24_50:
s_or_b64 exec, exec, s[14:15]
v_cmp_eq_i32_e32 vcc, 0, v0
s_and_saveexec_b64 s[4:5], vcc
s_xor_b64 s[4:5], exec, s[4:5]
v_add_i32 v0, vcc, s8, v3
v_mov_b32 v1, s9
v_addc_u32 v1, vcc, v4, v1, vcc
v_add_i32 v0, vcc, 8, v0
v_addc_u32 v1, vcc, 0, v1, vcc
v_mov_b32 v2, 1
flat_store_byte v[0:1], v2
s_waitcnt vmcnt(0) lgkmcnt(0)
BB24_54:
s_or_b64 exec, exec, s[4:5]
BB24_55:
s_or_b64 exec, exec, s[6:7]
s_barrier
BB24_56:
s_or_b64 exec, exec, s[10:11]
s_endpgm
.section .AMDGPU.csdata
.section .AMDGPU.runtime_metadata
.byte 4
.byte 6
.long 11
.ascii "kernel_sols"
.byte 7
.byte 9
.long 8
.byte 10
.long 8
.byte 11
.long 5
.ascii "char*"
.byte 13
.byte 1
.byte 14
.short 1
.byte 16
.byte 0
.byte 15
.byte 1
.byte 8
.byte 7
.byte 9
.long 8
.byte 10
.long 8
.byte 11
.long 5
.ascii "char*"
.byte 13
.byte 1
.byte 14
.short 1
.byte 16
.byte 0
.byte 15
.byte 1
.byte 8
.byte 7
.byte 9
.long 8
.byte 10
.long 8
.byte 11
.long 7
.ascii "sols_t*"
.byte 13
.byte 1
.byte 14
.short 0
.byte 16
.byte 0
.byte 15
.byte 1
.byte 8
.byte 7
.byte 9
.long 8
.byte 10
.long 8
.byte 11
.long 5
.ascii "uint*"
.byte 13
.byte 1
.byte 14
.short 7
.byte 16
.byte 0
.byte 15
.byte 1
.byte 8
.byte 7
.byte 9
.long 8
.byte 10
.long 8
.byte 11
.long 5
.ascii "uint*"
.byte 13
.byte 1
.byte 14
.short 7
.byte 16
.byte 0
.byte 15
.byte 1
.byte 8
.byte 7
.byte 9
.long 8
.byte 10
.long 8
.byte 11
.long 5
.ascii "char*"
.byte 13
.byte 1
.byte 14
.short 1
.byte 16
.byte 0
.byte 15
.byte 1
.byte 8
.byte 7
.byte 9
.long 8
.byte 10
.long 8
.byte 11
.long 5
.ascii "char*"
.byte 13
.byte 1
.byte 14
.short 1
.byte 16
.byte 0
.byte 15
.byte 1
.byte 8
.byte 7
.byte 9
.long 8
.byte 10
.long 8
.byte 11
.long 5
.ascii "char*"
.byte 13
.byte 1
.byte 14
.short 1
.byte 16
.byte 0
.byte 15
.byte 1
.byte 8
.byte 7
.byte 9
.long 8
.byte 10
.long 8
.byte 11
.long 5
.ascii "char*"
.byte 13
.byte 1
.byte 14
.short 1
.byte 16
.byte 0
.byte 15
.byte 1
.byte 8
.byte 7
.byte 9
.long 8
.byte 10
.long 8
.byte 11
.long 5
.ascii "char*"
.byte 13
.byte 1
.byte 14
.short 1
.byte 16
.byte 0
.byte 15
.byte 1
.byte 8
.byte 7
.byte 9
.long 8
.byte 10
.long 8
.byte 11
.long 5
.ascii "char*"
.byte 13
.byte 1
.byte 14
.short 1
.byte 16
.byte 0
.byte 15
.byte 1
.byte 8
.byte 7
.byte 9
.long 8
.byte 10
.long 8
.byte 11
.long 5
.ascii "char*"
.byte 13
.byte 1
.byte 14
.short 1
.byte 16
.byte 0
.byte 15
.byte 1
.byte 8
.byte 7
.byte 9
.long 8
.byte 10
.long 8
.byte 11
.long 17
.ascii "potential_sols_t*"
.byte 13
.byte 1
.byte 14
.short 0
.byte 16
.byte 0
.byte 15
.byte 1
.byte 8
.byte 5
.section .AMDGPU.config
.text
.globl get_local_size
.p2align 8
.type get_local_size,@function
get_local_size:
.amd_kernel_code_t
max_scratch_backing_memory_byte_size = 0
.dx10clamp
enable_ordered_append_gds = 0
private_element_size = 1
workitem_private_segment_byte_size = 0
workgroup_group_segment_byte_size = 0
gds_segment_byte_size = 0
workgroup_fbarrier_count = 0
wavefront_sgpr_count = 10
workitem_vgpr_count = 1
group_segment_alignment = 4
private_segment_alignment = 4
.end_amd_kernel_code_t
s_load_dword s0, s[8:9], 0x30
s_waitcnt lgkmcnt(0)
s_cmp_lt_i32 s0, 1
s_cbranch_scc1 BB25_4
s_cmp_lt_i32 s0, 2
s_cbranch_scc0 BB25_2
s_endpgm
BB25_4:
s_cmp_lg_i32 s0, 0
s_cbranch_scc1 BB25_7
s_endpgm
BB25_2:
s_cmp_eq_i32 s0, 2
s_cbranch_scc0 BB25_7
s_endpgm
BB25_7:
s_endpgm
.section .AMDGPU.csdata
.type blake_iv,@object
.text
.globl blake_iv
.p2align 3
blake_iv:
.quad 7640891576956012808
.quad -4942790177534073029
.quad 4354685564936845355
.quad -6534734903238641935
.quad 5840696475078001361
.quad -7276294671716946913
.quad 2270897969802886507
.quad 6620516959819538809
